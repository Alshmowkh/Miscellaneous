<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<madamira_output xmlns="urn:edu.columbia.ccls.madamira.configuration:0.1">
    <out_doc id="Text_Document_01.txt">
        <out_seg id="SENT1">
            <segment_info>
                <preprocessed>دان مصدر مسؤول في المؤتمر الشعبي العام واستنكر بشدة الجريمة التي ارتكبها طيران العدوان السعودي باستهدافه مجلس عزاء نسائي يوم الأربعاء في مديرية ارحب بمحافظة صنعاء ما ادى الى سقوط 6 شهيدات و 10 جريحات في حصيلة اولية</preprocessed>
                <bpc>
                    <chunk id="0" type="VP">
                        <tok id="0" form0="دان"/>
                    </chunk>
                    <chunk id="1" type="NP">
                        <tok id="0" form0="مصدر"/>
                        <tok id="1" form0="مسؤول"/>
                    </chunk>
                    <chunk id="2" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤتمر"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="شعبي"/>
                        <tok id="4" form0="ال+"/>
                        <tok id="5" form0="عام"/>
                    </chunk>
                    <chunk id="4" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="5" type="VP">
                        <tok id="0" form0="استنكر"/>
                    </chunk>
                    <chunk id="6" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="شدة"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جريمة"/>
                    </chunk>
                    <chunk id="9" type="WHNP">
                        <tok id="0" form0="التي"/>
                    </chunk>
                    <chunk id="10" type="VP">
                        <tok id="0" form0="ارتكب"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="طيران"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="سعودي"/>
                    </chunk>
                    <chunk id="14" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="استهداف"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="مجلس"/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="عزاء"/>
                        <tok id="1" form0="نسائي"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="يوم"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اربعاء"/>
                    </chunk>
                    <chunk id="21" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="22" type="NP">
                        <tok id="0" form0="مديرية"/>
                    </chunk>
                    <chunk id="23" type="VP">
                        <tok id="0" form0="ارحب"/>
                    </chunk>
                    <chunk id="24" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="محافظة"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="صنعاء"/>
                    </chunk>
                    <chunk id="27" type="WHNP">
                        <tok id="0" form0="ما"/>
                    </chunk>
                    <chunk id="28" type="VP">
                        <tok id="0" form0="ادي"/>
                    </chunk>
                    <chunk id="29" type="PP">
                        <tok id="0" form0="الي"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="سقوط"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="6"/>
                    </chunk>
                    <chunk id="32" type="NP">
                        <tok id="0" form0="شهيدات"/>
                    </chunk>
                    <chunk id="33" type="">
                        <tok id="0" form0="و"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="10"/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="جريحات"/>
                    </chunk>
                    <chunk id="36" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="37" type="NP">
                        <tok id="0" form0="حصيلة"/>
                        <tok id="1" form0="اولية"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="دان"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="مصدر"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="مسؤول"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="في"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="ال+"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="مؤتمر"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="ال+"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="شعبي"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="ال+"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="عام"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="و+"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="استنكر"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="ب+"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="شدة"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="ال+"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="جريمة"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="التي"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="ارتكب"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="+ها"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="طيران"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ال+"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="عدوان"/>
                    </ne>
                    <ne id="22" type="LOC">
                        <tok id="22" form0="ال+"/>
                        <tok id="22" form0="سعودي"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="ب+"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="استهداف"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="+ه"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="مجلس"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="عزاء"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="نسائي"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="يوم"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="ال+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="اربعاء"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="في"/>
                    </ne>
                    <ne id="33" type="ORG">
                        <tok id="33" form0="مديرية"/>
                        <tok id="33" form0="ارحب"/>
                    </ne>
                    <ne id="34" type="LOC">
                        <tok id="34" form0="ب+"/>
                        <tok id="34" form0="محافظة"/>
                    </ne>
                    <ne id="35" type="LOC">
                        <tok id="35" form0="صنعاء"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="ما"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="ادي"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="الي"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="سقوط"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="6"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="شهيدات"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="و"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="10"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="جريحات"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="في"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="حصيلة"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="اولية"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="دان">
                    <svm_prediction>
                        <morph_feature_set diac="دانَ" lemma="دانdAn" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="دانَ" lemma="دان-ِ_1" gloss="condemn;borrow;profess" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="دان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dAn" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دان" form1="دان" form2="دان" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دان"/>
                    </tokenized>
                </word>
                <word id="1" word="مصدر">
                    <svm_prediction>
                        <morph_feature_set diac="مَصْدَرٌ" lemma="مَصْدَرmaSodar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943055299704714">
                        <morph_feature_set diac="مَصْدَرٌ" lemma="مَصْدَر_1" gloss="source" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="مَصْدَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مصدر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mSdr" form1="NOUN+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مصدر" form1="مصدر" form2="مَصْدَر" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مصدر"/>
                    </tokenized>
                </word>
                <word id="2" word="مسؤول">
                    <svm_prediction>
                        <morph_feature_set diac="مَسْؤُولٌ" lemma="مَسْؤُولmaso&amp;uwl" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941605336878372">
                        <morph_feature_set diac="مَسْؤُولٌ" lemma="مَسْؤُول_2" gloss="responsible;dependable" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="مَسْؤُول"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مسؤول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ms&amp;wl" form1="ADJ+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مسؤول" form1="مسؤول" form2="مَسْؤُول" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مسؤول"/>
                    </tokenized>
                </word>
                <word id="3" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="4" word="المؤتمر">
                    <svm_prediction>
                        <morph_feature_set diac="المُؤْتَمَرِ" lemma="مُؤْتَمَرmu&amp;otamar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="المُؤْتَمَرِ" lemma="مُؤْتَمَر_1" gloss="conference;convention" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="مُؤْتَمَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المؤتمر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="m&amp;tmr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المؤتمر" form1="المؤتمر" form2="مُؤْتَمَر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤتمر"/>
                    </tokenized>
                </word>
                <word id="5" word="الشعبي">
                    <svm_prediction>
                        <morph_feature_set diac="الشَّعْبِيِّ" lemma="شَعْبِيّ$aEobiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="الشَّعْبِيِّ" lemma="شَعْبِيّ_1" gloss="popular;national;people's" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شَعْبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشعبي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$Eby" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشعبي" form1="الشعبي" form2="شَعْبِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعبي"/>
                    </tokenized>
                </word>
                <word id="6" word="العام">
                    <svm_prediction>
                        <morph_feature_set diac="العامِّ" lemma="عامّEAm~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="العامِّ" lemma="عامّ_1" gloss="general;common;public" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عامّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EAm" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العام" form1="العام" form2="عامّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عام"/>
                    </tokenized>
                </word>
                <word id="7" word="واستنكر">
                    <svm_prediction>
                        <morph_feature_set diac="وَاِسْتَنْكَرَ" lemma="ٱِسْتَنْكَر{isotanokar" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950153762285171">
                        <morph_feature_set diac="وَاِسْتَنْكَرَ" lemma="ٱِسْتَنْكَر_1" gloss="be_ignorant_of;have_no_knowledge_of;repudiate" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="ٱِسْتَنْكَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="استنكر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Astnkr" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="استنكر" form1="استنكر" form2="ٱِسْتَنْكَر" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="استنكر"/>
                    </tokenized>
                </word>
                <word id="8" word="بشدة">
                    <svm_prediction>
                        <morph_feature_set diac="بِشِدَّةٍ" lemma="شِدَّة$id~ap" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940186055051459">
                        <morph_feature_set diac="بِشِدَّةٍ" lemma="شِدَّة_1" gloss="intensity;forcefulness" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="شِدّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="شدة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="$dp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="شدة" form1="شدة" form2="شِدَّة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="شدة"/>
                    </tokenized>
                </word>
                <word id="9" word="الجريمة">
                    <svm_prediction>
                        <morph_feature_set diac="الجَرِيمَةَ" lemma="جَرِيمَةjariymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894310847530732">
                        <morph_feature_set diac="الجَرِيمَةَ" lemma="جَرِيمَة_1" gloss="crime" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0" stem="جَرِيم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجريمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jrymp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجريمة" form1="الجريمة" form2="جَرِيمَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جريمة"/>
                    </tokenized>
                </word>
                <word id="10" word="التي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8945079933398044">
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِي_1" gloss="which;who;whom_[fem.sg.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="الَّتِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alty" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التي" form1="التي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                </word>
                <word id="11" word="ارتكبها">
                    <svm_prediction>
                        <morph_feature_set diac="اِرْتَكَبَها" lemma="ٱِرْتَكَب{irotakab" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="3fs_dobj"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939856795833844">
                        <morph_feature_set diac="اِرْتَكَبَها" lemma="ٱِرْتَكَب_1" gloss="commit;perpetrate" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="3fs_dobj" stem="ٱِرْتَكَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ارتكب"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Artkb" form1="PV+PVSUFF_SUBJ:3MS"/>
                        <tok id="1" form0="+hA" form1="+PVSUFF_DO:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ارتكب" form1="ارتكب" form2="ٱِرْتَكَب" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PVSUFF_DO:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ارتكب"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="12" word="طيران">
                    <svm_prediction>
                        <morph_feature_set diac="طَيَرانِ" lemma="طَيَرانTayarAn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="طَيَرانِ" lemma="طَيَران_1" gloss="airline;aviation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="طَيَران"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="طيران"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="TyrAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="طيران" form1="طيران" form2="طَيَران" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="طيران"/>
                    </tokenized>
                </word>
                <word id="13" word="العدوان">
                    <svm_prediction>
                        <morph_feature_set diac="العُدْوانِ" lemma="عَدُوّEaduw~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8830781083175002">
                        <morph_feature_set diac="العُدْوانِ" lemma="عُدْوان_1" gloss="aggression;hostility;enmity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عُدْوان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العدوان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EdwAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العدوان" form1="العدوان" form2="عُدْوان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </tokenized>
                </word>
                <word id="14" word="السعودي">
                    <svm_prediction>
                        <morph_feature_set diac="السَّعُودِيُّ" lemma="سَعُودِيّsaEuwdiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="السَّعُودِيِّ" lemma="سَعُودِيّ_1" gloss="Saudi" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="سَعُودِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السعودي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="sEwdy" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السعودي" form1="السعودي" form2="سَعُودِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سعودي"/>
                    </tokenized>
                </word>
                <word id="15" word="باستهدافه">
                    <svm_prediction>
                        <morph_feature_set diac="بِاِسْتِهْدافِهِ" lemma="ٱِسْتِهْداف{isotihodAf" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939533673902794">
                        <morph_feature_set diac="بِاِسْتِهْدافِهِ" lemma="ٱِسْتِهْداف_1" gloss="targeting;aiming_at" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="ٱِسْتِهْداف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="استهداف"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="AsthdAf" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="استهداف" form1="استهداف" form2="ٱِسْتِهْداف" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="استهداف"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="16" word="مجلس">
                    <svm_prediction>
                        <morph_feature_set diac="مَجْلِسِ" lemma="مَجْلِسmajolis" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="مَجْلِسِ" lemma="مَجْلِس_1" gloss="council;board;Majlis" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مَجْلِس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مجلس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mjls" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مجلس" form1="مجلس" form2="مَجْلِس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مجلس"/>
                    </tokenized>
                </word>
                <word id="17" word="عزاء">
                    <svm_prediction>
                        <morph_feature_set diac="عَزاءَ" lemma="عَزاءEazA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8458758161439461">
                        <morph_feature_set diac="عَزاءَ" lemma="عَزاء_1" gloss="consolation;mourning" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="عَزاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عزاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EzA'" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عزاء" form1="عزاء" form2="عَزاء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عزاء"/>
                    </tokenized>
                </word>
                <word id="18" word="نسائي">
                    <svm_prediction>
                        <morph_feature_set diac="نِسائِيٍّ" lemma="نِساءnisA'" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8783036695082628">
                        <morph_feature_set diac="نِسائِيٍّ" lemma="نِسائِيّ_1" gloss="women's;feminist;feminine" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="نِسائِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نسائي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nsA}y" form1="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نسائي" form1="نسائي" form2="نِسائِيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نسائي"/>
                    </tokenized>
                </word>
                <word id="19" word="يوم">
                    <svm_prediction>
                        <morph_feature_set diac="يَوْمَ" lemma="يَوْمyawom" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8873965659541032">
                        <morph_feature_set diac="يَوْمِ" lemma="يَوْم_1" gloss="day" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="يَوْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يوم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ywm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يوم" form1="يوم" form2="يَوْم" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يوم"/>
                    </tokenized>
                </word>
                <word id="20" word="الأربعاء">
                    <svm_prediction>
                        <morph_feature_set diac="الأَرْبِعاءِ" lemma="أَرْبِعاء&gt;arobiEA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8247916443084916">
                        <morph_feature_set diac="الأَرْبِعاءِ" lemma="أَرْبِعاء_1" gloss="Wednesday" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَرْبِعاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاربعاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="ArbEA'" form1="NOUN_PROP+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأربعاء" form1="الاربعاء" form2="أَرْبِعاء" form3="PROP" form4="DT+NNP" form5="DET+NOUN_PROP+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اربعاء"/>
                    </tokenized>
                </word>
                <word id="21" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="22" word="مديرية">
                    <svm_prediction>
                        <morph_feature_set diac="مُدِيرِيَّةِ" lemma="مُدِيرِيَّةmudiyriy~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="مُدِيرِيَّةِ" lemma="مُدِيرِيَّة_1" gloss="administration;management" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="مُدِيرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مديرية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mdyryp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مديرية" form1="مديرية" form2="مُدِيرِيَّة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مديرية"/>
                    </tokenized>
                </word>
                <word id="23" word="ارحب">
                    <svm_prediction>
                        <morph_feature_set diac="أُرَحِّب" lemma="رَحَّبraH~ab" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8246479616008978">
                        <morph_feature_set diac="أُرَحِّب" lemma="رَحَّب_1" gloss="welcome;receive" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="رَحِّب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ارحب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ArHb" form1="IV1S+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أرحب" form1="ارحب" form2="رَحَّب" form3="VRB" form4="VBP" form5="IV1S+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ارحب"/>
                    </tokenized>
                </word>
                <word id="24" word="بمحافظة">
                    <svm_prediction>
                        <morph_feature_set diac="بِمُحافَظَةِ" lemma="مُحافِظmuHAfiZ" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.883798458842735">
                        <morph_feature_set diac="بِمُحافِظَةِ" lemma="مُحافِظ_1" gloss="governor;conservative" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="مُحافِظ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="محافظة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="mHAfZp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="محافظة" form1="محافظة" form2="مُحافِظ" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="محافظة"/>
                    </tokenized>
                </word>
                <word id="25" word="صنعاء">
                    <svm_prediction>
                        <morph_feature_set diac="صَنْعاء" lemma="صَنْعاءSanoEA'" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="صَنْعاء" lemma="صَنْعاء_1" gloss="Sana;Sanaa" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="صَنْعاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="صنعاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="SnEA'" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="صنعاء" form1="صنعاء" form2="صَنْعاء" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="صنعاء"/>
                    </tokenized>
                </word>
                <word id="26" word="ما">
                    <svm_prediction>
                        <morph_feature_set diac="ما" lemma="ماmA" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="ما" lemma="ما_1" gloss="what" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ما"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mA" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ما" form1="ما" form2="ما" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                </word>
                <word id="27" word="ادى">
                    <svm_prediction>
                        <morph_feature_set diac="أَدَّى" lemma="أَدَّى&gt;ad~aY" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.825737969239259">
                        <morph_feature_set diac="أَدَّى" lemma="أَدَّى_1" gloss="direct;guide;lead" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="أَدَّى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ادي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ady" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أدى" form1="ادي" form2="أَدَّى" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ادي"/>
                    </tokenized>
                </word>
                <word id="28" word="الى">
                    <svm_prediction>
                        <morph_feature_set diac="إِلَى" lemma="إِلَى&lt;ilaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8331090354286067">
                        <morph_feature_set diac="إِلَى" lemma="إِلَى_1" gloss="to;towards" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aly" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلى" form1="الي" form2="إِلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                </word>
                <word id="29" word="سقوط">
                    <svm_prediction>
                        <morph_feature_set diac="سُقُوطِ" lemma="سُقُوطsuquwT" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="سُقُوطِ" lemma="سُقُوط_1" gloss="fall;collapse;crash_(aircraft)" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="سُقُوط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سقوط"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sqwT" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سقوط" form1="سقوط" form2="سُقُوط" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سقوط"/>
                    </tokenized>
                </word>
                <word id="30" word="6">
                    <svm_prediction>
                        <morph_feature_set diac="8" lemma="88" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="6" lemma="6_0" gloss="6" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="6"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="6" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="6" form1="6" form2="6" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="6"/>
                    </tokenized>
                </word>
                <word id="31" word="شهيدات">
                    <svm_prediction>
                        <morph_feature_set diac="شهيدات" lemma="شهيدات$hydAt" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="3d_poss"/>
                    </svm_prediction>
					<analysis>
                        <morph_feature_set diac="شهيدات" lemma="شهيدات$hydAt" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="3d_poss" stem="شهيد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="شهيدات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="$hydAt" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="شهيدات" form1="شهيدات" form2="شهيدات" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="شهيدات"/>
                    </tokenized>
                </word>
                <word id="32" word="و">
                    <svm_prediction>
                        <morph_feature_set diac="وَ" lemma="وَwa" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944861109203527">
                        <morph_feature_set diac="وَ" lemma="وَ_1" gloss="and" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="وَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و" form1="و" form2="وَ" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و"/>
                    </tokenized>
                </word>
                <word id="33" word="10">
                    <svm_prediction>
                        <morph_feature_set diac="88" lemma="8888" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="10" lemma="10_0" gloss="10" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="10"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="10" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="10" form1="10" form2="10" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="10"/>
                    </tokenized>
                </word>
                <word id="34" word="جريحات">
                    <svm_prediction>
                        <morph_feature_set diac="جَرِيحات" lemma="جَرِيحjariyH" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839166646816445">
                        <morph_feature_set diac="جَرِيحاتٍ" lemma="جَرِيح_1" gloss="wounded;injured" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0" stem="جَرِيح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جريحات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jryHAt" form1="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جريحات" form1="جريحات" form2="جَرِيح" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جريحات"/>
                    </tokenized>
                </word>
                <word id="35" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="36" word="حصيلة">
                    <svm_prediction>
                        <morph_feature_set diac="حَصِيلَةُ" lemma="حَصِيلَةHaSiylap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8841970447888736">
                        <morph_feature_set diac="حَصِيلَةٍ" lemma="حَصِيلَة_1" gloss="result;revenue" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="حَصِيل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حصيلة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="HSylp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حصيلة" form1="حصيلة" form2="حَصِيلَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حصيلة"/>
                    </tokenized>
                </word>
                <word id="37" word="اولية">
                    <svm_prediction>
                        <morph_feature_set diac="أَوَّلِيَّةً" lemma="أَوَّل&gt;aw~al" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8145717701412889">
                        <morph_feature_set diac="أَوَّلِيَّةٍ" lemma="أَوَّل_2" gloss="first;foremost" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="أَوَّلِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اولية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Awlyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أولية" form1="اولية" form2="أَوَّل" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اولية"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
       
        <out_seg id="SENT2">
            <segment_info>
                <preprocessed>واكد المصدر ان ارتكاب جرائم قتل النساء واستهداف مجالس وقاعات العزاء والافراح ليس بجديد على هذا العدوان الهمجي البربري حيث سبق وارتكب جرائم عديدة استهدف خلالها مجالس عزاء وافراح في عدد من محافظات الجمهورية كان اخرها مذبحة القاعة الكبرى اثناء عزاء ال الرويشان الى الدرجة التي بات فيها هذا العدوان يتلذذ بقتل اليمنيين اطفالا ونساء وشيوخا وشبابا على مرأى ومسمع العالم الذي يشاهد كل هذا الاجرام من قبل تحالف العدوان الذي تقوده السعودية دون ان يحرك ساكنا</preprocessed>
                <bpc>
                    <chunk id="0" type="S">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="1" type="VP">
                        <tok id="0" form0="اكد"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </chunk>
                    <chunk id="3" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="ارتكاب"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="جرائم"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="قتل"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نساء"/>
                    </chunk>
                    <chunk id="8" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="استهداف"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="مجالس"/>
                    </chunk>
                    <chunk id="11" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="قاعات"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عزاء"/>
                        <tok id="2" form0="و+"/>
                        <tok id="3" form0="ال+"/>
                        <tok id="4" form0="افراح"/>
                    </chunk>
                    <chunk id="14" type="VP">
                        <tok id="0" form0="ليس"/>
                    </chunk>
                    <chunk id="15" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="جديد"/>
                    </chunk>
                    <chunk id="17" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="هذا"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="همجي"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="بربري"/>
                    </chunk>
                    <chunk id="21" type="WHADVP">
                        <tok id="0" form0="حيث"/>
                    </chunk>
                    <chunk id="22" type="VP">
                        <tok id="0" form0="سبق"/>
                    </chunk>
                    <chunk id="23" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="24" type="VP">
                        <tok id="0" form0="ارتكب"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="جرائم"/>
                        <tok id="1" form0="عديدة"/>
                    </chunk>
                    <chunk id="26" type="VP">
                        <tok id="0" form0="استهدف"/>
                    </chunk>
                    <chunk id="27" type="NP">
                        <tok id="0" form0="خلال"/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="مجالس"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="عزاء"/>
                    </chunk>
                    <chunk id="31" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="32" type="NP">
                        <tok id="0" form0="افراح"/>
                    </chunk>
                    <chunk id="33" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="عدد"/>
                    </chunk>
                    <chunk id="35" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="محافظات"/>
                    </chunk>
                    <chunk id="37" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جمهورية"/>
                    </chunk>
                    <chunk id="38" type="VP">
                        <tok id="0" form0="كان"/>
                    </chunk>
                    <chunk id="39" type="ADJP">
                        <tok id="0" form0="اخر"/>
                    </chunk>
                    <chunk id="40" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="41" type="NP">
                        <tok id="0" form0="مذبحة"/>
                    </chunk>
                    <chunk id="42" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قاعة"/>
                    </chunk>
                    <chunk id="43" type="NP">
                        <tok id="0" form0="ال+"/>
                    </chunk>
                    <chunk id="44" type="VP">
                        <tok id="0" form0="كبري"/>
                    </chunk>
                    <chunk id="45" type="NP">
                        <tok id="0" form0="اثناء"/>
                    </chunk>
                    <chunk id="46" type="NP">
                        <tok id="0" form0="عزاء"/>
                    </chunk>
                    <chunk id="47" type="NP">
                        <tok id="0" form0="ال"/>
                        <tok id="1" form0="الرويشان"/>
                    </chunk>
                    <chunk id="48" type="PP">
                        <tok id="0" form0="الي"/>
                    </chunk>
                    <chunk id="49" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="درجة"/>
                    </chunk>
                    <chunk id="50" type="WHNP">
                        <tok id="0" form0="التي"/>
                    </chunk>
                    <chunk id="51" type="VP">
                        <tok id="0" form0="بات"/>
                    </chunk>
                    <chunk id="52" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="53" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="54" type="NP">
                        <tok id="0" form0="هذا"/>
                    </chunk>
                    <chunk id="55" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </chunk>
                    <chunk id="56" type="VP">
                        <tok id="0" form0="يتلذذ"/>
                    </chunk>
                    <chunk id="57" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="58" type="NP">
                        <tok id="0" form0="قتل"/>
                    </chunk>
                    <chunk id="59" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="يمنيين"/>
                    </chunk>
                    <chunk id="60" type="NP">
                        <tok id="0" form0="اطفالا"/>
                        <tok id="1" form0="و+"/>
                        <tok id="2" form0="نساء"/>
                        <tok id="3" form0="و+"/>
                        <tok id="4" form0="شيوخا"/>
                        <tok id="5" form0="و+"/>
                        <tok id="6" form0="شبابا"/>
                    </chunk>
                    <chunk id="61" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="62" type="NP">
                        <tok id="0" form0="مراي"/>
                    </chunk>
                    <chunk id="63" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="64" type="NP">
                        <tok id="0" form0="مسمع"/>
                    </chunk>
                    <chunk id="65" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عالم"/>
                    </chunk>
                    <chunk id="66" type="WHNP">
                        <tok id="0" form0="الذي"/>
                    </chunk>
                    <chunk id="67" type="VP">
                        <tok id="0" form0="يشاهد"/>
                    </chunk>
                    <chunk id="68" type="NP">
                        <tok id="0" form0="كل"/>
                    </chunk>
                    <chunk id="69" type="NP">
                        <tok id="0" form0="هذا"/>
                    </chunk>
                    <chunk id="70" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اجرام"/>
                    </chunk>
                    <chunk id="71" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="72" type="NP">
                        <tok id="0" form0="قبل"/>
                    </chunk>
                    <chunk id="73" type="NP">
                        <tok id="0" form0="تحالف"/>
                    </chunk>
                    <chunk id="74" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </chunk>
                    <chunk id="75" type="WHNP">
                        <tok id="0" form0="الذي"/>
                    </chunk>
                    <chunk id="76" type="VP">
                        <tok id="0" form0="تقود"/>
                    </chunk>
                    <chunk id="77" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="78" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سعودية"/>
                    </chunk>
                    <chunk id="79" type="NP">
                        <tok id="0" form0="دون"/>
                    </chunk>
                    <chunk id="80" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="81" type="VP">
                        <tok id="0" form0="يحرك"/>
                    </chunk>
                    <chunk id="82" type="NP">
                        <tok id="0" form0="ساكنا"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="و+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="اكد"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ال+"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="مصدر"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="ان"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="ارتكاب"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="جرائم"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="قتل"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="ال+"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="نساء"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="و+"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="استهداف"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="مجالس"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="و+"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="قاعات"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="ال+"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="عزاء"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="و+"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="ال+"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="افراح"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ليس"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="ب+"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="جديد"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="علي"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="هذا"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="ال+"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="عدوان"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ال+"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="همجي"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="ال+"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="بربري"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="حيث"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="سبق"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="و+"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="ارتكب"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="جرائم"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="عديدة"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="استهدف"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="خلال"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="+ها"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="مجالس"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="عزاء"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="و+"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="افراح"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="في"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="عدد"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="من"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="محافظات"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="ال+"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="جمهورية"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="كان"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="اخر"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="+ها"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="مذبحة"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="ال+"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="قاعة"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="ال+"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="كبري"/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="اثناء"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="عزاء"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="ال"/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0="الرويشان"/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="الي"/>
                    </ne>
                    <ne id="63" type="">
                        <tok id="63" form0="ال+"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0="درجة"/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0="التي"/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="بات"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0="في"/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="+ها"/>
                    </ne>
                    <ne id="69" type="">
                        <tok id="69" form0="هذا"/>
                    </ne>
                    <ne id="70" type="">
                        <tok id="70" form0="ال+"/>
                    </ne>
                    <ne id="71" type="">
                        <tok id="71" form0="عدوان"/>
                    </ne>
                    <ne id="72" type="">
                        <tok id="72" form0="يتلذذ"/>
                    </ne>
                    <ne id="73" type="">
                        <tok id="73" form0="ب+"/>
                    </ne>
                    <ne id="74" type="">
                        <tok id="74" form0="قتل"/>
                    </ne>
                    <ne id="75" type="">
                        <tok id="75" form0="ال+"/>
                    </ne>
                    <ne id="76" type="">
                        <tok id="76" form0="يمنيين"/>
                    </ne>
                    <ne id="77" type="">
                        <tok id="77" form0="اطفالا"/>
                    </ne>
                    <ne id="78" type="">
                        <tok id="78" form0="و+"/>
                    </ne>
                    <ne id="79" type="">
                        <tok id="79" form0="نساء"/>
                    </ne>
                    <ne id="80" type="">
                        <tok id="80" form0="و+"/>
                    </ne>
                    <ne id="81" type="">
                        <tok id="81" form0="شيوخا"/>
                    </ne>
                    <ne id="82" type="">
                        <tok id="82" form0="و+"/>
                    </ne>
                    <ne id="83" type="">
                        <tok id="83" form0="شبابا"/>
                    </ne>
                    <ne id="84" type="">
                        <tok id="84" form0="علي"/>
                    </ne>
                    <ne id="85" type="">
                        <tok id="85" form0="مراي"/>
                    </ne>
                    <ne id="86" type="">
                        <tok id="86" form0="و+"/>
                    </ne>
                    <ne id="87" type="">
                        <tok id="87" form0="مسمع"/>
                    </ne>
                    <ne id="88" type="">
                        <tok id="88" form0="ال+"/>
                    </ne>
                    <ne id="89" type="">
                        <tok id="89" form0="عالم"/>
                    </ne>
                    <ne id="90" type="">
                        <tok id="90" form0="الذي"/>
                    </ne>
                    <ne id="91" type="">
                        <tok id="91" form0="يشاهد"/>
                    </ne>
                    <ne id="92" type="">
                        <tok id="92" form0="كل"/>
                    </ne>
                    <ne id="93" type="">
                        <tok id="93" form0="هذا"/>
                    </ne>
                    <ne id="94" type="">
                        <tok id="94" form0="ال+"/>
                    </ne>
                    <ne id="95" type="">
                        <tok id="95" form0="اجرام"/>
                    </ne>
                    <ne id="96" type="">
                        <tok id="96" form0="من"/>
                    </ne>
                    <ne id="97" type="">
                        <tok id="97" form0="قبل"/>
                    </ne>
                    <ne id="98" type="">
                        <tok id="98" form0="تحالف"/>
                    </ne>
                    <ne id="99" type="">
                        <tok id="99" form0="ال+"/>
                    </ne>
                    <ne id="100" type="">
                        <tok id="100" form0="عدوان"/>
                    </ne>
                    <ne id="101" type="">
                        <tok id="101" form0="الذي"/>
                    </ne>
                    <ne id="102" type="">
                        <tok id="102" form0="تقود"/>
                    </ne>
                    <ne id="103" type="">
                        <tok id="103" form0="+ه"/>
                    </ne>
                    <ne id="104" type="LOC">
                        <tok id="104" form0="ال+"/>
                        <tok id="104" form0="سعودية"/>
                    </ne>
                    <ne id="105" type="">
                        <tok id="105" form0="دون"/>
                    </ne>
                    <ne id="106" type="">
                        <tok id="106" form0="ان"/>
                    </ne>
                    <ne id="107" type="">
                        <tok id="107" form0="يحرك"/>
                    </ne>
                    <ne id="108" type="">
                        <tok id="108" form0="ساكنا"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="واكد">
                    <svm_prediction>
                        <morph_feature_set diac="وَأَكَّدَ" lemma="أَكَّد&gt;ak~ad" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8252356976070483">
                        <morph_feature_set diac="وَأَكَّدَ" lemma="أَكَّد_1" gloss="affirm;assure;confirm;guarantee" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="أَكَّد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اكد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Akd" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="أكد" form1="اكد" form2="أَكَّد" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اكد"/>
                    </tokenized>
                </word>
                <word id="1" word="المصدر">
                    <svm_prediction>
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَرmaSodar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950630275921179">
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَر_1" gloss="source" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="مَصْدَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المصدر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mSdr" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المصدر" form1="المصدر" form2="مَصْدَر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </tokenized>
                </word>
                <word id="2" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8258625130148115">
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ_1" gloss="that" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="3" word="ارتكاب">
                    <svm_prediction>
                        <morph_feature_set diac="اِرْتِكابِ" lemma="ٱِرْتِكاب{irotikAb" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8866756788017508">
                        <morph_feature_set diac="اِرْتِكابَ" lemma="ٱِرْتِكاب_1" gloss="perpetration;commission" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="ٱِرْتِكاب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ارتكاب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ArtkAb" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ارتكاب" form1="ارتكاب" form2="ٱِرْتِكاب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ارتكاب"/>
                    </tokenized>
                </word>
                <word id="4" word="جرائم">
                    <svm_prediction>
                        <morph_feature_set diac="جَرائِمَ" lemma="جَرِيمَةjariymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8969741517107328">
                        <morph_feature_set diac="جَرائِمَ" lemma="جَرِيمَة_1" gloss="crimes" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="جَرائِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jrA}m" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جرائم" form1="جرائم" form2="جَرِيمَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                </word>
                <word id="5" word="قتل">
                    <svm_prediction>
                        <morph_feature_set diac="قَتْلُ" lemma="قَتْلqatol" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8866756788017508">
                        <morph_feature_set diac="قَتْلَ" lemma="قَتْل_1" gloss="murder;killing" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="قَتْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قتل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qtl" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قتل" form1="قتل" form2="قَتْل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قتل"/>
                    </tokenized>
                </word>
                <word id="6" word="النساء">
                    <svm_prediction>
                        <morph_feature_set diac="النِّساءِ" lemma="نِساءnisA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="النِّساءِ" lemma="نِساء_1" gloss="women" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="نِساء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="النساء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="nsA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="النساء" form1="النساء" form2="نِساء" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نساء"/>
                    </tokenized>
                </word>
                <word id="7" word="واستهداف">
                    <svm_prediction>
                        <morph_feature_set diac="وَاِسْتِهْدافِ" lemma="ٱِسْتِهْداف{isotihodAf" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942026627925052">
                        <morph_feature_set diac="وَاِسْتِهْدافِ" lemma="ٱِسْتِهْداف_1" gloss="targeting;aiming_at" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِسْتِهْداف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="استهداف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AsthdAf" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="استهداف" form1="استهداف" form2="ٱِسْتِهْداف" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="استهداف"/>
                    </tokenized>
                </word>
                <word id="8" word="مجالس">
                    <svm_prediction>
                        <morph_feature_set diac="مَجالِسِ" lemma="مَجْلِسmajolis" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="مَجالِسِ" lemma="مَجْلِس_1" gloss="councils;boards" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مَجالِس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مجالس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mjAls" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مجالس" form1="مجالس" form2="مَجْلِس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مجالس"/>
                    </tokenized>
                </word>
                <word id="9" word="وقاعات">
                    <svm_prediction>
                        <morph_feature_set diac="وَقاعاتِ" lemma="قاعَةqAEap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939196235971633">
                        <morph_feature_set diac="وَقاعاتِ" lemma="قاعَة_1" gloss="halls;corridors;large_rooms" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="0" stem="قاع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="قاعات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="qAEAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="قاعات" form1="قاعات" form2="قاعَة" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="قاعات"/>
                    </tokenized>
                </word>
                <word id="10" word="العزاء">
                    <svm_prediction>
                        <morph_feature_set diac="العَزاءِ" lemma="عَزاءEazA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="العَزاءِ" lemma="عَزاء_1" gloss="consolation;mourning" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عَزاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العزاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EzA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العزاء" form1="العزاء" form2="عَزاء" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عزاء"/>
                    </tokenized>
                </word>
                <word id="11" word="والافراح">
                    <svm_prediction>
                        <morph_feature_set diac="وَالأَفْراح" lemma="فَرَحfaraH" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8142580542635788">
                        <morph_feature_set diac="وَالأَفْراحِ" lemma="فَرَح_1" gloss="joys;festivities" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَفْراح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الافراح"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="AfrAH" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الأفراح" form1="الافراح" form2="فَرَح" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="افراح"/>
                    </tokenized>
                </word>
                <word id="12" word="ليس">
                    <svm_prediction>
                        <morph_feature_set diac="لَيْسَ" lemma="لَيْسَlayosa" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="لَيْسَ" lemma="لَيْسَ_1" gloss="not_+_he;it_(he;it_is_not)" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="لَيْسَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ليس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="lys" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ليس" form1="ليس" form2="لَيْسَ" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ليس"/>
                    </tokenized>
                </word>
                <word id="13" word="بجديد">
                    <svm_prediction>
                        <morph_feature_set diac="بِجَدِيدِ" lemma="جَدِيدjadiyd" pos="adj" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836056081130186">
                        <morph_feature_set diac="بِجَدِيدٍ" lemma="جَدِيد_1" gloss="new;modern" pos="adj" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="جَدِيد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="جديد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="jdyd" form1="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="جديد" form1="جديد" form2="جَدِيد" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="جديد"/>
                    </tokenized>
                </word>
                <word id="14" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="15" word="هذا">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذا" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذا" lemma="هٰذا_1" gloss="this" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="هٰذا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*A" form1="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذا" form1="هذا" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                </word>
                <word id="16" word="العدوان">
                    <svm_prediction>
                        <morph_feature_set diac="العُدْوانَ" lemma="عَدُوّEaduw~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8727796354085182">
                        <morph_feature_set diac="العُدْوانِ" lemma="عُدْوان_1" gloss="aggression;hostility;enmity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عُدْوان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العدوان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EdwAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العدوان" form1="العدوان" form2="عُدْوان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </tokenized>
                </word>
                <word id="17" word="الهمجي">
                    <svm_prediction>
                        <morph_feature_set diac="الهَمَجِيَّ" lemma="هَمَجِيّhamajiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="الهَمَجِيِّ" lemma="هَمَجِيّ_1" gloss="rude;uncivilized;barbaric" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="هَمَجِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الهمجي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="hmjy" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الهمجي" form1="الهمجي" form2="هَمَجِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="همجي"/>
                    </tokenized>
                </word>
                <word id="18" word="البربري">
                    <svm_prediction>
                        <morph_feature_set diac="البَرْبَرِيّ" lemma="بَرْبَرِيّbarobariy~" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8249180295618601">
                        <morph_feature_set diac="البَرْبَرِيّ" lemma="بَرْبَرِيّ_1" gloss="Berber" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="بَرْبَرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="البربري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="brbry" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="البربري" form1="البربري" form2="بَرْبَرِيّ" form3="NOM" form4="DT+NN" form5="DET+NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="بربري"/>
                    </tokenized>
                </word>
                <word id="19" word="حيث">
                    <svm_prediction>
                        <morph_feature_set diac="حَيْثُ" lemma="حَيْثُHayovu" pos="adv_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="حَيْثُ" lemma="حَيْثُ_1" gloss="where;whereby;since;given_that" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="حَيْثُ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حيث"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Hyv" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حيث" form1="حيث" form2="حَيْثُ" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حيث"/>
                    </tokenized>
                </word>
                <word id="20" word="سبق">
                    <svm_prediction>
                        <morph_feature_set diac="سَبَقَ" lemma="سَبَقsabaq" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="سَبَقَ" lemma="سَبَق-ُِ_1" gloss="precede;antecede;anticipate" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="سَبَق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سبق"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sbq" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سبق" form1="سبق" form2="سَبَق" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سبق"/>
                    </tokenized>
                </word>
                <word id="21" word="وارتكب">
                    <svm_prediction>
                        <morph_feature_set diac="وَأُرْتَكَب" lemma="ٱِرْتَكَب{irotakab" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8847169033195351">
                        <morph_feature_set diac="وَاِرْتَكَبَ" lemma="ٱِرْتَكَب_1" gloss="commit;perpetrate" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="ٱِرْتَكَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ارتكب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Artkb" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="ارتكب" form1="ارتكب" form2="ٱِرْتَكَب" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ارتكب"/>
                    </tokenized>
                </word>
                <word id="22" word="جرائم">
                    <svm_prediction>
                        <morph_feature_set diac="جَرائِمَ" lemma="جَرِيمَةjariymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8458758161439461">
                        <morph_feature_set diac="جَرائِمَ" lemma="جَرِيمَة_1" gloss="crimes" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="جَرائِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jrA}m" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جرائم" form1="جرائم" form2="جَرِيمَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                </word>
                <word id="23" word="عديدة">
                    <svm_prediction>
                        <morph_feature_set diac="عَدِيدَةٍ" lemma="عَدِيدEadiyd" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946499216717394">
                        <morph_feature_set diac="عَدِيدَةٍ" lemma="عَدِيد_1" gloss="numerous;many" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="عَدِيد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عديدة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Edydp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عديدة" form1="عديدة" form2="عَدِيد" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عديدة"/>
                    </tokenized>
                </word>
                <word id="24" word="استهدف">
                    <svm_prediction>
                        <morph_feature_set diac="اِسْتَهْدَفَ" lemma="ٱِسْتَهْدَف{isotahodaf" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="اِسْتَهْدَفَ" lemma="ٱِسْتَهْدَف_1" gloss="target;aim_at" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="ٱِسْتَهْدَف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="استهدف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Asthdf" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="استهدف" form1="استهدف" form2="ٱِسْتَهْدَف" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="استهدف"/>
                    </tokenized>
                </word>
                <word id="25" word="خلالها">
                    <svm_prediction>
                        <morph_feature_set diac="خِلالَها" lemma="خِلالَxilAla" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3fs_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.609297606597056">
                        <morph_feature_set diac="خِلالَها" lemma="خِلالَ_1" gloss="during;through" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="خِلالَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="خلال"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="xlAl" form1="PREP"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="خلال" form1="خلال" form2="خِلالَ" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="خلال"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="26" word="مجالس">
                    <svm_prediction>
                        <morph_feature_set diac="مَجالِسِ" lemma="مَجْلِسmajolis" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8845614767239923">
                        <morph_feature_set diac="مَجالِسُ" lemma="مَجْلِس_1" gloss="councils;boards" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="مَجالِس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مجالس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mjAls" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مجالس" form1="مجالس" form2="مَجْلِس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مجالس"/>
                    </tokenized>
                </word>
                <word id="27" word="عزاء">
                    <svm_prediction>
                        <morph_feature_set diac="عَزاءَ" lemma="عَزاءEazA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8458758161439461">
                        <morph_feature_set diac="عَزاءَ" lemma="عَزاء_1" gloss="consolation;mourning" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="عَزاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عزاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EzA'" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عزاء" form1="عزاء" form2="عَزاء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عزاء"/>
                    </tokenized>
                </word>
                <word id="28" word="وافراح">
                    <svm_prediction>
                        <morph_feature_set diac="وَأَفْراحِ" lemma="فَرَحfaraH" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8138905539379415">
                        <morph_feature_set diac="وَأَفْراحٍ" lemma="فَرَح_1" gloss="joys;festivities" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="أَفْراح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="افراح"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AfrAH" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="أفراح" form1="افراح" form2="فَرَح" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="افراح"/>
                    </tokenized>
                </word>
                <word id="29" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="30" word="عدد">
                    <svm_prediction>
                        <morph_feature_set diac="عَدَدٍ" lemma="عَدَدEadad" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895576339810859">
                        <morph_feature_set diac="عَدَدٍ" lemma="عَدَد_1" gloss="number;quantity;issue" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="عَدَد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عدد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Edd" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عدد" form1="عدد" form2="عَدَد" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عدد"/>
                    </tokenized>
                </word>
                <word id="31" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="32" word="محافظات">
                    <svm_prediction>
                        <morph_feature_set diac="مُحافَظاتٍ" lemma="مُحافَظَةmuHAfaZap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8838679916169998">
                        <morph_feature_set diac="مُحافَظاتِ" lemma="مُحافَظَة_1" gloss="protection" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="0" stem="مُحافَظ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="محافظات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mHAfZAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="محافظات" form1="محافظات" form2="مُحافَظَة" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="محافظات"/>
                    </tokenized>
                </word>
                <word id="33" word="الجمهورية">
                    <svm_prediction>
                        <morph_feature_set diac="الجُمْهُورِيَّةِ" lemma="جُمْهُورِيّjumohuwriy~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الجُمْهُورِيَّةِ" lemma="جُمْهُورِيّ_1" gloss="republic" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="جُمْهُورِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجمهورية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jmhwryp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجمهورية" form1="الجمهورية" form2="جُمْهُورِيّ" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جمهورية"/>
                    </tokenized>
                </word>
                <word id="34" word="كان">
                    <svm_prediction>
                        <morph_feature_set diac="كانَ" lemma="كانkAn" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="كانَ" lemma="كان_1" gloss="was;were" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="كان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="kAn" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كان" form1="كان" form2="كان" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كان"/>
                    </tokenized>
                </word>
                <word id="35" word="اخرها">
                    <svm_prediction>
                        <morph_feature_set diac="آخِرَها" lemma="آخِر|xir" pos="adj_comp" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3fs_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.754829544504635">
                        <morph_feature_set diac="آخِرَها" lemma="آخِر_1" gloss="last;end" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3fs_poss" stem="آخِر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اخر"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Axr" form1="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+hA" form1="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="آخر" form1="اخر" form2="آخِر" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اخر"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="36" word="مذبحة">
                    <svm_prediction>
                        <morph_feature_set diac="مَذْبَحَةِ" lemma="مَذْبَحَةma*obaHap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="مَذْبَحَةِ" lemma="مَذْبَحَة_1" gloss="massacre;slaughter" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="مَذْبَح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مذبحة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="m*bHp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مذبحة" form1="مذبحة" form2="مَذْبَحَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مذبحة"/>
                    </tokenized>
                </word>
                <word id="37" word="القاعة">
                    <svm_prediction>
                        <morph_feature_set diac="القاعَةِ" lemma="قاعَةqAEap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="القاعَةِ" lemma="قاعَة_1" gloss="hall;corridor;large_room" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="قاع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القاعة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qAEp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القاعة" form1="القاعة" form2="قاعَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قاعة"/>
                    </tokenized>
                </word>
                <word id="38" word="الكبرى">
                    <svm_prediction>
                        <morph_feature_set diac="الكُبْرَى" lemma="كُبْرِيkuboriy" pos="adj_comp" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8146195566528782">
                        <morph_feature_set diac="الكُبْرِي" lemma="كُبْرِي_1" gloss="bridge;overpass" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="كُبْرِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الكبري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="kbry" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الكبري" form1="الكبري" form2="كُبْرِي" form3="NOM" form4="DT+NN" form5="DET+NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="كبري"/>
                    </tokenized>
                </word>
                <word id="39" word="اثناء">
                    <svm_prediction>
                        <morph_feature_set diac="أَثْناءَ" lemma="أَثْناءَ&gt;avonA'a" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8110557969179146">
                        <morph_feature_set diac="أَثْناءَ" lemma="ثِنْي_1" gloss="folds;bends" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="أَثْناء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اثناء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AvnA'" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أثناء" form1="اثناء" form2="ثِنْي" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اثناء"/>
                    </tokenized>
                </word>
                <word id="40" word="عزاء">
                    <svm_prediction>
                        <morph_feature_set diac="عَزاءَ" lemma="عَزاءEazA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8458758161439461">
                        <morph_feature_set diac="عَزاءَ" lemma="عَزاء_1" gloss="consolation;mourning" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="عَزاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عزاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EzA'" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عزاء" form1="عزاء" form2="عَزاء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عزاء"/>
                    </tokenized>
                </word>
                <word id="41" word="ال">
                    <svm_prediction>
                        <morph_feature_set diac="ال" lemma="وَلِيwaliy" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7882090643390447">
                        <morph_feature_set diac="ال" lemma="ال_1" gloss="the" pos="part_det" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="ال"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ال"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al" form1="DET"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ال" form1="ال" form2="ال" form3="PRT" form4="DT" form5="DET"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال"/>
                    </tokenized>
                </word>
                <word id="42" word="الرويشان">
                    <svm_prediction>
                        <morph_feature_set diac="الرويشان" lemma="الرويشانAlrwy$An" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الرويشان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alrwy$An" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الرويشان" form1="الرويشان" form2="الرويشان" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الرويشان"/>
                    </tokenized>
                </word>
                <word id="43" word="الى">
                    <svm_prediction>
                        <morph_feature_set diac="إِلَى" lemma="إِلَى&lt;ilaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8331090354286067">
                        <morph_feature_set diac="إِلَى" lemma="إِلَى_1" gloss="to;towards" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aly" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلى" form1="الي" form2="إِلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                </word>
                <word id="44" word="الدرجة">
                    <svm_prediction>
                        <morph_feature_set diac="الدَّرَجَةِ" lemma="دَرَجَةdarajap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الدَّرَجَةِ" lemma="دَرَجَة_1" gloss="degree;class;rank;grade;level" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="دَرَج"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدرجة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="drjp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدرجة" form1="الدرجة" form2="دَرَجَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="درجة"/>
                    </tokenized>
                </word>
                <word id="45" word="التي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8945079933398044">
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِي_1" gloss="which;who;whom_[fem.sg.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="الَّتِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alty" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التي" form1="التي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                </word>
                <word id="46" word="بات">
                    <svm_prediction>
                        <morph_feature_set diac="باتَ" lemma="باتbAt" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="باتَ" lemma="بات-ِ_1" gloss="become;remain" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="بات"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bAt" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بات" form1="بات" form2="بات" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بات"/>
                    </tokenized>
                </word>
                <word id="47" word="فيها">
                    <svm_prediction>
                        <morph_feature_set diac="فِيها" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="فِيها" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="48" word="هذا">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذا" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذا" lemma="هٰذا_1" gloss="this" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="هٰذا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*A" form1="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذا" form1="هذا" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                </word>
                <word id="49" word="العدوان">
                    <svm_prediction>
                        <morph_feature_set diac="العُدْوانَ" lemma="عَدُوّEaduw~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8727796354085182">
                        <morph_feature_set diac="العُدْوانِ" lemma="عُدْوان_1" gloss="aggression;hostility;enmity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عُدْوان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العدوان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EdwAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العدوان" form1="العدوان" form2="عُدْوان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </tokenized>
                </word>
                <word id="50" word="يتلذذ">
                    <svm_prediction>
                        <morph_feature_set diac="يَتَلَذَّذ" lemma="تَلَذَّذtala*~a*" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="يَتَلَذَّذ" lemma="تَلَذَّذ_1" gloss="be_pleased;be_delighted" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="تَلَذَّذ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يتلذذ"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ytl**" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يتلذذ" form1="يتلذذ" form2="تَلَذَّذ" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يتلذذ"/>
                    </tokenized>
                </word>
                <word id="51" word="بقتل">
                    <svm_prediction>
                        <morph_feature_set diac="بِقَتْلِ" lemma="قَتْلqatol" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِقَتْلِ" lemma="قَتْل_1" gloss="murder;killing" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قَتْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="قتل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="qtl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="قتل" form1="قتل" form2="قَتْل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="قتل"/>
                    </tokenized>
                </word>
                <word id="52" word="اليمنيين">
                    <svm_prediction>
                        <morph_feature_set diac="اليَمَنِيِّينَ" lemma="يَمَنِيّyamaniy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940601206287706">
                        <morph_feature_set diac="اليَمَنِيِّينَ" lemma="يَمَنِيّ_1" gloss="Yemeni" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0" stem="يَمَنِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اليمنيين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="ymnyyn" form1="ADJ+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="اليمنيين" form1="اليمنيين" form2="يَمَنِيّ" form3="NOM" form4="DT+JJ+#S" form5="DET+ADJ+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="يمنيين"/>
                    </tokenized>
                </word>
                <word id="53" word="اطفالا">
                    <svm_prediction>
                        <morph_feature_set diac="أَطْفالاً" lemma="طِفْلTifol" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="أَطْفالاً" lemma="طِفْل_1" gloss="children;infants" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="أَطْفال"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اطفالا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ATfAlA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أطفالا" form1="اطفالا" form2="طِفْل" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اطفالا"/>
                    </tokenized>
                </word>
                <word id="54" word="ونساء">
                    <svm_prediction>
                        <morph_feature_set diac="وَنَساءِ" lemma="نَساءnasA'" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8431043272257185">
                        <morph_feature_set diac="وَنَساءِ" lemma="نَساء_1" gloss="longevity" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="نَساء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="نساء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="nsA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="نساء" form1="نساء" form2="نَساء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="نساء"/>
                    </tokenized>
                </word>
                <word id="55" word="وشيوخا">
                    <svm_prediction>
                        <morph_feature_set diac="وَشُيُوخاً" lemma="شَيْخ$ayox" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894013697281388">
                        <morph_feature_set diac="وَشُيُوخاً" lemma="شَيْخ_2" gloss="sheikhs;chieftains;senators" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="شُيُوخ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="شيوخا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="$ywxA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="شيوخا" form1="شيوخا" form2="شَيْخ" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="شيوخا"/>
                    </tokenized>
                </word>
                <word id="56" word="وشبابا">
                    <svm_prediction>
                        <morph_feature_set diac="وَشَباباً" lemma="شَبّ$ab~" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894013697281388">
                        <morph_feature_set diac="وَشَباباً" lemma="شَبّ_1" gloss="youth;youths" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="شَباب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="شبابا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="$bAbA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="شبابا" form1="شبابا" form2="شَبّ" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="شبابا"/>
                    </tokenized>
                </word>
                <word id="57" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="58" word="مرأى">
                    <svm_prediction>
                        <morph_feature_set diac="مَرْأَى" lemma="مَرْأَىmaro&gt;aY" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8459330756272011">
                        <morph_feature_set diac="مَرْأَى" lemma="مَرْأَى_1" gloss="sight;view;apparition" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="مَرْأَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مراي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mrAy" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مرأى" form1="مراي" form2="مَرْأَى" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مراي"/>
                    </tokenized>
                </word>
                <word id="59" word="ومسمع">
                    <svm_prediction>
                        <morph_feature_set diac="وَمَسْمَعِ" lemma="مَسْمَعmasomaE" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942026627925052">
                        <morph_feature_set diac="وَمَسْمَعِ" lemma="مَسْمَع_1" gloss="hearing_distance" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مَسْمَع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مسمع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="msmE" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="مسمع" form1="مسمع" form2="مَسْمَع" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مسمع"/>
                    </tokenized>
                </word>
                <word id="60" word="العالم">
                    <svm_prediction>
                        <morph_feature_set diac="العالَمِ" lemma="عالَمEAlam" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="العالَمِ" lemma="عالَم_1" gloss="world" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عالَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العالم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EAlm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العالم" form1="العالم" form2="عالَم" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عالم"/>
                    </tokenized>
                </word>
                <word id="61" word="الذي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِي_1" gloss="which;who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="الَّذِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*y" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذي" form1="الذي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                </word>
                <word id="62" word="يشاهد">
                    <svm_prediction>
                        <morph_feature_set diac="يُشاهَد" lemma="شاهَد$Ahad" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يُشاهِد" lemma="شاهَد_1" gloss="watch;observe;witness" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="شاهِد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يشاهد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="y$Ahd" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يشاهد" form1="يشاهد" form2="شاهَد" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يشاهد"/>
                    </tokenized>
                </word>
                <word id="63" word="كل">
                    <svm_prediction>
                        <morph_feature_set diac="كُلِّ" lemma="كُلّkul~" pos="noun_quant" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8172568891866696">
                        <morph_feature_set diac="كُلَّ" lemma="كُلّ_1" gloss="every;all" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="كُلّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="kl" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كل" form1="كل" form2="كُلّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كل"/>
                    </tokenized>
                </word>
                <word id="64" word="هذا">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذا" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذا" lemma="هٰذا_1" gloss="this" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="هٰذا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*A" form1="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذا" form1="هذا" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                </word>
                <word id="65" word="الاجرام">
                    <svm_prediction>
                        <morph_feature_set diac="الإِجْرامِ" lemma="إِجْرام&lt;ijorAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8294371058673811">
                        <morph_feature_set diac="الإِجْرامِ" lemma="إِجْرام_1" gloss="delinquency;criminality" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="إِجْرام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاجرام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AjrAm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الإجرام" form1="الاجرام" form2="إِجْرام" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اجرام"/>
                    </tokenized>
                </word>
                <word id="66" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="67" word="قبل">
                    <svm_prediction>
                        <morph_feature_set diac="قِبَلِ" lemma="قِبَلqibal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="قِبَلِ" lemma="قِبَل_1" gloss="(on_the)_part_of" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قِبَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قبل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qbl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قبل" form1="قبل" form2="قِبَل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قبل"/>
                    </tokenized>
                </word>
                <word id="68" word="تحالف">
                    <svm_prediction>
                        <morph_feature_set diac="تَحالُفٍ" lemma="تَحالُفtaHAluf" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8873965659541032">
                        <morph_feature_set diac="تَحالُفِ" lemma="تَحالُف_1" gloss="alliance" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="تَحالُف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تحالف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tHAlf" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تحالف" form1="تحالف" form2="تَحالُف" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تحالف"/>
                    </tokenized>
                </word>
                <word id="69" word="العدوان">
                    <svm_prediction>
                        <morph_feature_set diac="العُدْوانِ" lemma="عَدُوّEaduw~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8830781083175002">
                        <morph_feature_set diac="العُدْوانِ" lemma="عُدْوان_1" gloss="aggression;hostility;enmity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عُدْوان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العدوان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EdwAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العدوان" form1="العدوان" form2="عُدْوان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </tokenized>
                </word>
                <word id="70" word="الذي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِي_1" gloss="which;who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="الَّذِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*y" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذي" form1="الذي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                </word>
                <word id="71" word="تقوده">
                    <svm_prediction>
                        <morph_feature_set diac="تَقُوده" lemma="قادqAd" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="3ms_dobj"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="تَقُوده" lemma="قاد-ُ_1" gloss="lead;guide" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="f" num="s" stt="na" cas="na" enc0="3ms_dobj" stem="قُود"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تقود"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tqwd" form1="IV3FS+IV"/>
                        <tok id="1" form0="+h" form1="+IVSUFF_DO:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تقود" form1="تقود" form2="قاد" form3="VRB" form4="VBP" form5="IV3FS+IV"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP" form5="+IVSUFF_DO:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تقود"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="72" word="السعودية">
                    <svm_prediction>
                        <morph_feature_set diac="السَّعُودِيَّةِ" lemma="سَعُودِيّsaEuwdiy~" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8146197616407179">
                        <morph_feature_set diac="السَّعُودِيَّةُ" lemma="سَعُودِيّ_1" gloss="Saudi" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="n" enc0="0" stem="سَعُودِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السعودية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="sEwdyp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السعودية" form1="السعودية" form2="سَعُودِيّ" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سعودية"/>
                    </tokenized>
                </word>
                <word id="73" word="دون">
                    <svm_prediction>
                        <morph_feature_set diac="دُونِ" lemma="دُونduwn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8866756788017508">
                        <morph_feature_set diac="دُونَ" lemma="دُون_1" gloss="inferior;poor" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="دُون"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دون"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dwn" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دون" form1="دون" form2="دُون" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دون"/>
                    </tokenized>
                </word>
                <word id="74" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8155640401058297">
                        <morph_feature_set diac="أَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="75" word="يحرك">
                    <svm_prediction>
                        <morph_feature_set diac="يُحِركِ" lemma="حَرَّكHar~ak" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يُحَرِّك" lemma="حَرَّك_1" gloss="make_move;activate;stimulate" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="حَرِّك"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يحرك"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yHrk" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يحرك" form1="يحرك" form2="حَرَّك" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يحرك"/>
                    </tokenized>
                </word>
                <word id="76" word="ساكنا">
                    <svm_prediction>
                        <morph_feature_set diac="ساكِناً" lemma="ساكِنsAkin" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946349927825878">
                        <morph_feature_set diac="ساكِناً" lemma="ساكِن_1" gloss="residing" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="ساكِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ساكنا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sAknA" form1="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ساكنا" form1="ساكنا" form2="ساكِن" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ساكنا"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        
        <out_seg id="SENT3">
            <segment_info>
                <preprocessed>واوضح المصدر ان الصمت الدولي هو الذي يشجع العدوان السعودي على الاستمرار في ارتكاب جرائمه هذه , مؤكدا انها لن تسقط بالتقادم وسيتم محاسبة نظام ال سعود وكل المتحالفين معه والمتورطين بقتل الشعب اليمني سواء كانوا افرادا من المرتزقة او انظمة وقادة دول على هذه الجرائم ان عاجلا او اجلا</preprocessed>
                <bpc>
                    <chunk id="0" type="S">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="1" type="VP">
                        <tok id="0" form0="اوضح"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </chunk>
                    <chunk id="3" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="صمت"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="دولي"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="هو"/>
                    </chunk>
                    <chunk id="6" type="WHNP">
                        <tok id="0" form0="الذي"/>
                    </chunk>
                    <chunk id="7" type="VP">
                        <tok id="0" form0="يشجع"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="سعودي"/>
                    </chunk>
                    <chunk id="9" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="استمرار"/>
                    </chunk>
                    <chunk id="11" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="ارتكاب"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="جرائم"/>
                    </chunk>
                    <chunk id="14" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="هذه"/>
                    </chunk>
                    <chunk id="16" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="17" type="ADJP">
                        <tok id="0" form0="مؤكدا"/>
                    </chunk>
                    <chunk id="18" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="20" type="VP">
                        <tok id="0" form0="لن"/>
                        <tok id="1" form0="تسقط"/>
                    </chunk>
                    <chunk id="21" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="22" type="NP">
                        <tok id="0" form0="ال+"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="تقادم"/>
                    </chunk>
                    <chunk id="24" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="25" type="VP">
                        <tok id="0" form0="س+"/>
                        <tok id="1" form0="يتم"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="محاسبة"/>
                    </chunk>
                    <chunk id="27" type="NP">
                        <tok id="0" form0="نظام"/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="ال"/>
                        <tok id="1" form0="سعود"/>
                    </chunk>
                    <chunk id="29" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="كل"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="متحالفين"/>
                    </chunk>
                    <chunk id="32" type="PP">
                        <tok id="0" form0="مع"/>
                    </chunk>
                    <chunk id="33" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="34" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="متورطين"/>
                    </chunk>
                    <chunk id="36" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="37" type="NP">
                        <tok id="0" form0="قتل"/>
                    </chunk>
                    <chunk id="38" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعب"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="يمني"/>
                    </chunk>
                    <chunk id="39" type="NP">
                        <tok id="0" form0="سواء"/>
                    </chunk>
                    <chunk id="40" type="VP">
                        <tok id="0" form0="كانوا"/>
                    </chunk>
                    <chunk id="41" type="NP">
                        <tok id="0" form0="افرادا"/>
                    </chunk>
                    <chunk id="42" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="43" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مرتزقة"/>
                    </chunk>
                    <chunk id="44" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="45" type="NP">
                        <tok id="0" form0="انظمة"/>
                    </chunk>
                    <chunk id="46" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="47" type="NP">
                        <tok id="0" form0="قادة"/>
                    </chunk>
                    <chunk id="48" type="NP">
                        <tok id="0" form0="دول"/>
                    </chunk>
                    <chunk id="49" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="50" type="NP">
                        <tok id="0" form0="هذه"/>
                    </chunk>
                    <chunk id="51" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جرائم"/>
                    </chunk>
                    <chunk id="52" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="53" type="NP">
                        <tok id="0" form0="عاجلا"/>
                        <tok id="1" form0="او"/>
                        <tok id="2" form0="اجلا"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="و+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="اوضح"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ال+"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="مصدر"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="ان"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="ال+"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="صمت"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="ال+"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="دولي"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="هو"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="الذي"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="يشجع"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="ال+"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="عدوان"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="ال+"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="سعودي"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="علي"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="ال+"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="استمرار"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="في"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ارتكاب"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="جرائم"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="+ه"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="هذه"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0=","/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="مؤكدا"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="ان"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="+ها"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="لن"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="تسقط"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="ب+"/>
                    </ne>
                    <ne id="31" type="ORG">
                        <tok id="31" form0="ال+"/>
                        <tok id="31" form0="تقادم"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="و+"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="س+"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="يتم"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="محاسبة"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="نظام"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="ال"/>
                    </ne>
                    <ne id="38" type="PER">
                        <tok id="38" form0="سعود"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="و+"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="كل"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="ال+"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="متحالفين"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="مع"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="+ه"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="و+"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="ال+"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="متورطين"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="ب+"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="قتل"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="ال+"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="شعب"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="ال+"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="يمني"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="سواء"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="كانوا"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="افرادا"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="من"/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="ال+"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="مرتزقة"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="او"/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0="انظمة"/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="و+"/>
                    </ne>
                    <ne id="63" type="">
                        <tok id="63" form0="قادة"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0="دول"/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0="علي"/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="هذه"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0="ال+"/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="جرائم"/>
                    </ne>
                    <ne id="69" type="">
                        <tok id="69" form0="ان"/>
                    </ne>
                    <ne id="70" type="">
                        <tok id="70" form0="عاجلا"/>
                    </ne>
                    <ne id="71" type="">
                        <tok id="71" form0="او"/>
                    </ne>
                    <ne id="72" type="">
                        <tok id="72" form0="اجلا"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="واوضح">
                    <svm_prediction>
                        <morph_feature_set diac="وَأَوْضَحَ" lemma="أَوْضَح&gt;awoDaH" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8252356976070483">
                        <morph_feature_set diac="وَأَوْضَحَ" lemma="أَوْضَح_1" gloss="clarify;explain;indicate" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="أَوْضَح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اوضح"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AwDH" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="أوضح" form1="اوضح" form2="أَوْضَح" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اوضح"/>
                    </tokenized>
                </word>
                <word id="1" word="المصدر">
                    <svm_prediction>
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَرmaSodar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950630275921179">
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَر_1" gloss="source" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="مَصْدَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المصدر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mSdr" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المصدر" form1="المصدر" form2="مَصْدَر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </tokenized>
                </word>
                <word id="2" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8258625130148115">
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ_1" gloss="that" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="3" word="الصمت">
                    <svm_prediction>
                        <morph_feature_set diac="الصَّمْتَ" lemma="صَمْتSamot" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895212316960791">
                        <morph_feature_set diac="الصَّمْتَ" lemma="صَمْت_1" gloss="silence" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="صَمْت"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الصمت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Smt" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الصمت" form1="الصمت" form2="صَمْت" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="صمت"/>
                    </tokenized>
                </word>
                <word id="4" word="الدولي">
                    <svm_prediction>
                        <morph_feature_set diac="الدُّوَلِيَّ" lemma="دَوْلِيّdawoliy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943008256937558">
                        <morph_feature_set diac="الدُّوَلِيَّ" lemma="دَوْلِيّ_1" gloss="international;world" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="دُوَلِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدولي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwly" form1="ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدولي" form1="الدولي" form2="دَوْلِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دولي"/>
                    </tokenized>
                </word>
                <word id="5" word="هو">
                    <svm_prediction>
                        <morph_feature_set diac="هُوَ" lemma="هُوَhuwa" pos="pron" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940263767879477">
                        <morph_feature_set diac="هُوَ" lemma="هُوَ_1" gloss="it;he" pos="pron" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="هُوَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هو"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="hw" form1="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هو" form1="هو" form2="هُوَ" form3="NOM" form4="PRP" form5="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هو"/>
                    </tokenized>
                </word>
                <word id="6" word="الذي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِي_1" gloss="which;who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="الَّذِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*y" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذي" form1="الذي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                </word>
                <word id="7" word="يشجع">
                    <svm_prediction>
                        <morph_feature_set diac="يَشْجُع" lemma="شَجَّع$aj~aE" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يُشَجِّع" lemma="شَجَّع_1" gloss="encourage;promote;support" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="شَجِّع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يشجع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="y$jE" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يشجع" form1="يشجع" form2="شَجَّع" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يشجع"/>
                    </tokenized>
                </word>
                <word id="8" word="العدوان">
                    <svm_prediction>
                        <morph_feature_set diac="العُدْوانِ" lemma="عَدُوّEaduw~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8687751678804598">
                        <morph_feature_set diac="العُدْوانَ" lemma="عُدْوان_1" gloss="aggression;hostility;enmity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="عُدْوان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العدوان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EdwAn" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العدوان" form1="العدوان" form2="عُدْوان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </tokenized>
                </word>
                <word id="9" word="السعودي">
                    <svm_prediction>
                        <morph_feature_set diac="السَّعُودِيِّ" lemma="سَعُودِيّsaEuwdiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840023527847742">
                        <morph_feature_set diac="السَّعُودِيَّ" lemma="سَعُودِيّ_1" gloss="Saudi" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="سَعُودِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السعودي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="sEwdy" form1="ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السعودي" form1="السعودي" form2="سَعُودِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سعودي"/>
                    </tokenized>
                </word>
                <word id="10" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="11" word="الاستمرار">
                    <svm_prediction>
                        <morph_feature_set diac="الاِسْتِمْرارِ" lemma="ٱِسْتِمْرار{isotimorAr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الاِسْتِمْرارِ" lemma="ٱِسْتِمْرار_1" gloss="continuation;continuity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="ٱِسْتِمْرار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاستمرار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AstmrAr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الاستمرار" form1="الاستمرار" form2="ٱِسْتِمْرار" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="استمرار"/>
                    </tokenized>
                </word>
                <word id="12" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="13" word="ارتكاب">
                    <svm_prediction>
                        <morph_feature_set diac="اِرْتِكابِ" lemma="ٱِرْتِكاب{irotikAb" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="اِرْتِكابِ" lemma="ٱِرْتِكاب_1" gloss="perpetration;commission" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِرْتِكاب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ارتكاب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ArtkAb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ارتكاب" form1="ارتكاب" form2="ٱِرْتِكاب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ارتكاب"/>
                    </tokenized>
                </word>
                <word id="14" word="جرائمه">
                    <svm_prediction>
                        <morph_feature_set diac="جَرائِمِهِ" lemma="جَرِيمَةjariymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942773079888653">
                        <morph_feature_set diac="جَرائِمِهِ" lemma="جَرِيمَة_1" gloss="crimes" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="جَرائِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جرائم"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jrA}m" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جرائم" form1="جرائم" form2="جَرِيمَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جرائم"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="15" word="هذه">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذا_1" gloss="this;these" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="هٰذِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*h" form1="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذه" form1="هذه" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                </word>
                <word id="16" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="17" word="مؤكدا">
                    <svm_prediction>
                        <morph_feature_set diac="مُؤَكِّداً" lemma="مُؤَكِّدmu&amp;ak~id" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8681978437022567">
                        <morph_feature_set diac="مُؤَكَّداً" lemma="مُؤَكَّد_1" gloss="certain;guaranteed" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="مُؤَكَّد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مؤكدا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="m&amp;kdA" form1="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مؤكدا" form1="مؤكدا" form2="مُؤَكَّد" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مؤكدا"/>
                    </tokenized>
                </word>
                <word id="18" word="انها">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّها" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8241706212372776">
                        <morph_feature_set diac="أَنَّها" lemma="أَنَّ_1" gloss="that" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="أَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="19" word="لن">
                    <svm_prediction>
                        <morph_feature_set diac="لَن" lemma="لَنlan" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="لَن" lemma="لَن_1" gloss="(will)_not" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="لن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ln" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="لن" form1="لن" form2="لَن" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="لن"/>
                    </tokenized>
                </word>
                <word id="20" word="تسقط">
                    <svm_prediction>
                        <morph_feature_set diac="تُسْقَط" lemma="سَقَطsaqaT" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="s" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="تَسْقُط" lemma="سَقَط-ُ_1" gloss="fall;drop" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="f" num="s" stt="na" cas="na" enc0="0" stem="سْقُط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تسقط"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tsqT" form1="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تسقط" form1="تسقط" form2="سَقَط" form3="VRB" form4="VBP" form5="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تسقط"/>
                    </tokenized>
                </word>
                <word id="21" word="بالتقادم">
                    <svm_prediction>
                        <morph_feature_set diac="بِالتَّقادِم" lemma="تَقْدِمَةtaqodimap" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8838712637762707">
                        <morph_feature_set diac="بِالتَّقادِمِ" lemma="تَقْدِمَة_2" gloss="gifts" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="تَقادِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="التقادم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="tqAdm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="التقادم" form1="التقادم" form2="تَقْدِمَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="تقادم"/>
                    </tokenized>
                </word>
                <word id="22" word="وسيتم">
                    <svm_prediction>
                        <morph_feature_set diac="وَسَيَتِم" lemma="تَمّtam~" pos="verb" prc3="0" prc2="wa_conj" prc1="sa_fut" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836278994615842">
                        <morph_feature_set diac="وَسَيَتِمّ" lemma="تَمّ-ِ_1" gloss="conclude;take_place" pos="verb" prc3="0" prc2="wa_conj" prc1="sa_fut" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="تِمّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="س+"/>
                        <tok id="2" form0="يتم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="s+" form1="FUT_PART+"/>
                        <tok id="2" form0="ytm" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="س+" form1="س+" form2="سَ+" form3="PRT+" form4="RP+" form5="FUT_PART+"/>
                        <tok id="2" form0="يتم" form1="يتم" form2="تَمّ" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="س+"/>
                        <tok id="2" form0="يتم"/>
                    </tokenized>
                </word>
                <word id="23" word="محاسبة">
                    <svm_prediction>
                        <morph_feature_set diac="مُحاسَبَةِ" lemma="مُحاسَبَةmuHAsabap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="مُحاسَبَةِ" lemma="مُحاسَبَة_1" gloss="accounting;examination" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="مُحاسَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="محاسبة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mHAsbp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="محاسبة" form1="محاسبة" form2="مُحاسَبَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="محاسبة"/>
                    </tokenized>
                </word>
                <word id="24" word="نظام">
                    <svm_prediction>
                        <morph_feature_set diac="نِظامِ" lemma="نِظامniZAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="نِظامِ" lemma="نِظام_1" gloss="regime;government" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="نِظام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نظام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nZAm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نظام" form1="نظام" form2="نِظام" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نظام"/>
                    </tokenized>
                </word>
                <word id="25" word="ال">
                    <svm_prediction>
                        <morph_feature_set diac="آل" lemma="آل|l" pos="part_det" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="na" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7236086932576739">
                        <morph_feature_set diac="ال" lemma="ال_1" gloss="the" pos="part_det" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="ال"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ال"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al" form1="DET"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ال" form1="ال" form2="ال" form3="PRT" form4="DT" form5="DET"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال"/>
                    </tokenized>
                </word>
                <word id="26" word="سعود">
                    <svm_prediction>
                        <morph_feature_set diac="سُعُود" lemma="سُعُودsuEuwd" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8998215129572901">
                        <morph_feature_set diac="سُعُود" lemma="سُعُود_1" gloss="Saud" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="سُعُود"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سعود"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sEwd" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سعود" form1="سعود" form2="سُعُود" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سعود"/>
                    </tokenized>
                </word>
                <word id="27" word="وكل">
                    <svm_prediction>
                        <morph_feature_set diac="وَكُلُّ" lemma="كُلّkul~" pos="noun_quant" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.814485400268442">
                        <morph_feature_set diac="وَكُلِّ" lemma="كُلّ_1" gloss="every;all" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="كُلّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="كل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="kl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="كل" form1="كل" form2="كُلّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="كل"/>
                    </tokenized>
                </word>
                <word id="28" word="المتحالفين">
                    <svm_prediction>
                        <morph_feature_set diac="المُتَحالِفَيْنِ" lemma="مُتَحالِفmutaHAlif" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839320028652962">
                        <morph_feature_set diac="المُتَحالِفِينَ" lemma="مُتَحالِف_1" gloss="allied" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0" stem="مُتَحالِف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المتحالفين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mtHAlfyn" form1="NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المتحالفين" form1="المتحالفين" form2="مُتَحالِف" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="متحالفين"/>
                    </tokenized>
                </word>
                <word id="29" word="معه">
                    <svm_prediction>
                        <morph_feature_set diac="مَعَهُ" lemma="مَعmaE" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مَعَهُ" lemma="مَع_1" gloss="with" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3ms_pron" stem="مَعَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مع"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mE" form1="PREP"/>
                        <tok id="1" form0="+h" form1="+PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مع" form1="مع" form2="مَع" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP" form5="+PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مع"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="30" word="والمتورطين">
                    <svm_prediction>
                        <morph_feature_set diac="وَالمُتَوَرِّطَيْنِ" lemma="مُتَوَرِّطmutawar~iT" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.883610311801767">
                        <morph_feature_set diac="وَالمُتَوَرِّطِينَ" lemma="مُتَوَرِّط_1" gloss="involved;implicated;entangled" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0" stem="مُتَوَرِّط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="المتورطين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="mtwrTyn" form1="ADJ+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="المتورطين" form1="المتورطين" form2="مُتَوَرِّط" form3="NOM" form4="DT+JJ+#S" form5="DET+ADJ+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="متورطين"/>
                    </tokenized>
                </word>
                <word id="31" word="بقتل">
                    <svm_prediction>
                        <morph_feature_set diac="بِقَتْلِ" lemma="قَتْلqatol" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِقَتْلِ" lemma="قَتْل_1" gloss="murder;killing" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قَتْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="قتل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="qtl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="قتل" form1="قتل" form2="قَتْل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="قتل"/>
                    </tokenized>
                </word>
                <word id="32" word="الشعب">
                    <svm_prediction>
                        <morph_feature_set diac="الشَّعْبِ" lemma="شَعْب$aEob" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الشَّعْبِ" lemma="شَعْب_1" gloss="people;nation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شَعْب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشعب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$Eb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشعب" form1="الشعب" form2="شَعْب" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعب"/>
                    </tokenized>
                </word>
                <word id="33" word="اليمني">
                    <svm_prediction>
                        <morph_feature_set diac="اليُمْنَى" lemma="يَمَنِيّyamaniy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="اليَمَنِيِّ" lemma="يَمَنِيّ_1" gloss="Yemeni" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="يَمَنِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اليمني"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="ymny" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="اليمني" form1="اليمني" form2="يَمَنِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="يمني"/>
                    </tokenized>
                </word>
                <word id="34" word="سواء">
                    <svm_prediction>
                        <morph_feature_set diac="سَواء" lemma="سَواءsawA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8459330756272011">
                        <morph_feature_set diac="سَواء" lemma="سَواء_1" gloss="except;whether" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="سَواء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سواء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="swA'" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سواء" form1="سواء" form2="سَواء" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سواء"/>
                    </tokenized>
                </word>
                <word id="35" word="كانوا">
                    <svm_prediction>
                        <morph_feature_set diac="كانُوا" lemma="كانkAn" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="كانُوا" lemma="كان_1" gloss="was;were" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="كان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كانوا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="kAnwA" form1="PV+PVSUFF_SUBJ:3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كانوا" form1="كانوا" form2="كان" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كانوا"/>
                    </tokenized>
                </word>
                <word id="36" word="افرادا">
                    <svm_prediction>
                        <morph_feature_set diac="أَفْراداً" lemma="فَرْدfarod" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8253275231182895">
                        <morph_feature_set diac="أَفْراداً" lemma="فَرْد_1" gloss="individuals" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="أَفْراد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="افرادا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AfrAdA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أفرادا" form1="افرادا" form2="فَرْد" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="افرادا"/>
                    </tokenized>
                </word>
                <word id="37" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="38" word="المرتزقة">
                    <svm_prediction>
                        <morph_feature_set diac="المُرْتَزِقَةِ" lemma="مُرْتَزِقmurotaziq" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="المُرْتَزِقَةِ" lemma="مُرْتَزِق_1" gloss="mercenary" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مُرْتَزِق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المرتزقة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mrtzqp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المرتزقة" form1="المرتزقة" form2="مُرْتَزِق" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مرتزقة"/>
                    </tokenized>
                </word>
                <word id="39" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="40" word="انظمة">
                    <svm_prediction>
                        <morph_feature_set diac="أَنْظِمَةِ" lemma="نِظامniZAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8254727227368243">
                        <morph_feature_set diac="أَنْظِمَةِ" lemma="نِظام_1" gloss="regimes;governments;systems" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="أَنْظِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="انظمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AnZmp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أنظمة" form1="انظمة" form2="نِظام" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="انظمة"/>
                    </tokenized>
                </word>
                <word id="41" word="وقادة">
                    <svm_prediction>
                        <morph_feature_set diac="وَقادَةِ" lemma="قائِدqA}id" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939877247273975">
                        <morph_feature_set diac="وَقادَةِ" lemma="قائِد_1" gloss="leaders;commanders" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="قاد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="قادة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="qAdp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="قادة" form1="قادة" form2="قائِد" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="قادة"/>
                    </tokenized>
                </word>
                <word id="42" word="دول">
                    <svm_prediction>
                        <morph_feature_set diac="دُوَلٍ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895576339810859">
                        <morph_feature_set diac="دُوَلٍ" lemma="دَوْلَة_1" gloss="states;countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="دُوَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dwl" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دول" form1="دول" form2="دَوْلَة" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دول"/>
                    </tokenized>
                </word>
                <word id="43" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="44" word="هذه">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذا_1" gloss="this;these" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="هٰذِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*h" form1="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذه" form1="هذه" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                </word>
                <word id="45" word="الجرائم">
                    <svm_prediction>
                        <morph_feature_set diac="الجَرائِمِ" lemma="جَرِيمَةjariymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الجَرائِمِ" lemma="جَرِيمَة_1" gloss="crimes" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="جَرائِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجرائم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jrA}m" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجرائم" form1="الجرائم" form2="جَرِيمَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جرائم"/>
                    </tokenized>
                </word>
                <word id="46" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8258625130148115">
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ_1" gloss="that" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="47" word="عاجلا">
                    <svm_prediction>
                        <morph_feature_set diac="عاجِلاً" lemma="عاجِلEAjil" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8256884121246769">
                        <morph_feature_set diac="عاجِلاً" lemma="عاجِل_1" gloss="urgent;speedy" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="عاجِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عاجلا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EAjlA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عاجلا" form1="عاجلا" form2="عاجِل" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عاجلا"/>
                    </tokenized>
                </word>
                <word id="48" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="49" word="اجلا">
                    <svm_prediction>
                        <morph_feature_set diac="آجِلاً" lemma="أَجْل&gt;ajol" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8150290502093077">
                        <morph_feature_set diac="أَجْلاً" lemma="أَجْل_1" gloss="for_sake_of;because_of" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="أَجْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اجلا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AjlA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أجلا" form1="اجلا" form2="أَجْل" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اجلا"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
       
        <out_seg id="SENT4">
            <segment_info>
                <preprocessed>وطالب المصدر المجتمع الدولي وفي المقدمة مجلس الامن والمدافعين عن حقوق الانسان الى تحمل مسؤولياتهم والخروج عن حالة الصمت المخزي التي باتت وصمة عار تلطخ سمعة المجتمع الدولي وهو يشاهد ما يرتكب من جرائم ابادة ممنهجة بحق الشعب اليمني من قبل تحالف العدوان السعودي</preprocessed>
                <bpc>
                    <chunk id="0" type="S">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="1" type="VP">
                        <tok id="0" form0="طالب"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مجتمع"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="دولي"/>
                    </chunk>
                    <chunk id="4" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="5" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مقدمة"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="مجلس"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امن"/>
                        <tok id="2" form0="و+"/>
                        <tok id="3" form0="ال+"/>
                        <tok id="4" form0="مدافعين"/>
                    </chunk>
                    <chunk id="9" type="PP">
                        <tok id="0" form0="عن"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="حقوق"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="انسان"/>
                    </chunk>
                    <chunk id="12" type="PP">
                        <tok id="0" form0="الي"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="تحمل"/>
                    </chunk>
                    <chunk id="14" type="NP">
                        <tok id="0" form0="مسؤوليات"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="16" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="خروج"/>
                    </chunk>
                    <chunk id="18" type="PP">
                        <tok id="0" form0="عن"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="حالة"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="صمت"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="مخزي"/>
                    </chunk>
                    <chunk id="21" type="WHNP">
                        <tok id="0" form0="التي"/>
                    </chunk>
                    <chunk id="22" type="VP">
                        <tok id="0" form0="باتت"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="وصمة"/>
                    </chunk>
                    <chunk id="24" type="NP">
                        <tok id="0" form0="عار"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="تلطخ"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="سمعة"/>
                    </chunk>
                    <chunk id="27" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مجتمع"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="دولي"/>
                    </chunk>
                    <chunk id="28" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="هو"/>
                    </chunk>
                    <chunk id="30" type="VP">
                        <tok id="0" form0="يشاهد"/>
                    </chunk>
                    <chunk id="31" type="WHNP">
                        <tok id="0" form0="ما"/>
                    </chunk>
                    <chunk id="32" type="VP">
                        <tok id="0" form0="يرتكب"/>
                    </chunk>
                    <chunk id="33" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="جرائم"/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="ابادة"/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="ممنهجة"/>
                    </chunk>
                    <chunk id="37" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="38" type="NP">
                        <tok id="0" form0="حق"/>
                    </chunk>
                    <chunk id="39" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعب"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="يمني"/>
                    </chunk>
                    <chunk id="40" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="41" type="NP">
                        <tok id="0" form0="قبل"/>
                    </chunk>
                    <chunk id="42" type="NP">
                        <tok id="0" form0="تحالف"/>
                    </chunk>
                    <chunk id="43" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="سعودي"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="و+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="طالب"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ال+"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="مصدر"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="ال+"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="مجتمع"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="ال+"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="دولي"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="و+"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="في"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="ال+"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="مقدمة"/>
                    </ne>
                    <ne id="12" type="ORG">
                        <tok id="12" form0="مجلس"/>
                        <tok id="12" form0="ال+"/>
                    </ne>
                    <ne id="13" type="ORG">
                        <tok id="13" form0="امن"/>
                    </ne>
                    <ne id="14" type="LOC">
                        <tok id="14" form0="و+"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="ال+"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="مدافعين"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="عن"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="حقوق"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="ال+"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="انسان"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="الي"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="تحمل"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="مسؤوليات"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="+هم"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="و+"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="ال+"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="خروج"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="عن"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="حالة"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="ال+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="صمت"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="ال+"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="مخزي"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="التي"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="باتت"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="وصمة"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="عار"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="تلطخ"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="سمعة"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="ال+"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="مجتمع"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="ال+"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="دولي"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="و+"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="هو"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="يشاهد"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="ما"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="يرتكب"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="من"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="جرائم"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="ابادة"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="ممنهجة"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="ب+"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="حق"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="ال+"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="شعب"/>
                    </ne>
                    <ne id="57" type="LOC">
                        <tok id="57" form0="ال+"/>
                        <tok id="57" form0="يمني"/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="من"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="قبل"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="تحالف"/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0="ال+"/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="عدوان"/>
                    </ne>
                    <ne id="63" type="LOC">
                        <tok id="63" form0="ال+"/>
                        <tok id="63" form0="سعودي"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="وطالب">
                    <svm_prediction>
                        <morph_feature_set diac="وَطالَبَ" lemma="طالَبTAlab" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950153762285171">
                        <morph_feature_set diac="وَطالَبَ" lemma="طالَب_1" gloss="demand;require" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="طالَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="طالب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="TAlb" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="طالب" form1="طالب" form2="طالَب" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="طالب"/>
                    </tokenized>
                </word>
                <word id="1" word="المصدر">
                    <svm_prediction>
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَرmaSodar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950630275921179">
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَر_1" gloss="source" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="مَصْدَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المصدر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mSdr" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المصدر" form1="المصدر" form2="مَصْدَر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </tokenized>
                </word>
                <word id="2" word="المجتمع">
                    <svm_prediction>
                        <morph_feature_set diac="المُجْتَمَعِ" lemma="مُجْتَمَعmujotamaE" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8847645546831359">
                        <morph_feature_set diac="المُجْتَمَعُ" lemma="مُجْتَمَع_1" gloss="society" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="مُجْتَمَع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المجتمع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mjtmE" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المجتمع" form1="المجتمع" form2="مُجْتَمَع" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مجتمع"/>
                    </tokenized>
                </word>
                <word id="3" word="الدولي">
                    <svm_prediction>
                        <morph_feature_set diac="الدُّوَلِيِّ" lemma="دَوْلِيّdawoliy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8841579839889926">
                        <morph_feature_set diac="الدَّوْلِيُّ" lemma="دَوْلِيّ_1" gloss="international;state" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="دَوْلِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدولي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwly" form1="ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدولي" form1="الدولي" form2="دَوْلِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دولي"/>
                    </tokenized>
                </word>
                <word id="4" word="وفي">
                    <svm_prediction>
                        <morph_feature_set diac="وَفِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941713725520556">
                        <morph_feature_set diac="وَفِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="في"/>
                    </tokenized>
                </word>
                <word id="5" word="المقدمة">
                    <svm_prediction>
                        <morph_feature_set diac="المُقَدَّمَةِ" lemma="مُقَدَّمmuqad~am" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="المُقَدَّمَةِ" lemma="مُقَدَّم_3" gloss="lieutenant_colonel" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مُقَدَّم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المقدمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mqdmp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المقدمة" form1="المقدمة" form2="مُقَدَّم" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مقدمة"/>
                    </tokenized>
                </word>
                <word id="6" word="مجلس">
                    <svm_prediction>
                        <morph_feature_set diac="مَجْلِسِ" lemma="مَجْلِسmajolis" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="مَجْلِسِ" lemma="مَجْلِس_1" gloss="council;board;Majlis" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مَجْلِس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مجلس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mjls" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مجلس" form1="مجلس" form2="مَجْلِس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مجلس"/>
                    </tokenized>
                </word>
                <word id="7" word="الامن">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْنِ" lemma="أَمْن&gt;amon" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8294371058673811">
                        <morph_feature_set diac="الأَمْنِ" lemma="أَمْن_1" gloss="security;safety" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَمْن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمن" form1="الامن" form2="أَمْن" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امن"/>
                    </tokenized>
                </word>
                <word id="8" word="والمدافعين">
                    <svm_prediction>
                        <morph_feature_set diac="وَالمُدافِعِينَ" lemma="مُدافِعmudAfiE" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939500952382777">
                        <morph_feature_set diac="وَالمُدافِعِينَ" lemma="مُدافِع_1" gloss="defender;advocate" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0" stem="مُدافِع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="المدافعين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="mdAfEyn" form1="NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="المدافعين" form1="المدافعين" form2="مُدافِع" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="مدافعين"/>
                    </tokenized>
                </word>
                <word id="9" word="عن">
                    <svm_prediction>
                        <morph_feature_set diac="عَن" lemma="عَنEan" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَن" lemma="عَن_1" gloss="from;about" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="En" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عن" form1="عن" form2="عَن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                </word>
                <word id="10" word="حقوق">
                    <svm_prediction>
                        <morph_feature_set diac="حُقُوقِ" lemma="حَقّHaq~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="حُقُوقِ" lemma="حَقّ_2" gloss="rights;law" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="حُقُوق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حقوق"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Hqwq" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حقوق" form1="حقوق" form2="حَقّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حقوق"/>
                    </tokenized>
                </word>
                <word id="11" word="الانسان">
                    <svm_prediction>
                        <morph_feature_set diac="الإِنْسانِ" lemma="إِنْسان&lt;inosAn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8294371058673811">
                        <morph_feature_set diac="الإِنْسانِ" lemma="إِنْسان_1" gloss="human_being" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="إِنْسان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الانسان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AnsAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الإنسان" form1="الانسان" form2="إِنْسان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="انسان"/>
                    </tokenized>
                </word>
                <word id="12" word="الى">
                    <svm_prediction>
                        <morph_feature_set diac="إِلَى" lemma="إِلَى&lt;ilaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8331090354286067">
                        <morph_feature_set diac="إِلَى" lemma="إِلَى_1" gloss="to;towards" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aly" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلى" form1="الي" form2="إِلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                </word>
                <word id="13" word="تحمل">
                    <svm_prediction>
                        <morph_feature_set diac="تَحَمُّلِ" lemma="تَحَمُّلtaHam~ul" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7597699437035434">
                        <morph_feature_set diac="تَحْمِل" lemma="حَمَل-ِ_1" gloss="carry;bear;transport" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="f" num="s" stt="na" cas="na" enc0="0" stem="حْمِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تحمل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tHml" form1="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تحمل" form1="تحمل" form2="حَمَل" form3="VRB" form4="VBP" form5="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تحمل"/>
                    </tokenized>
                </word>
                <word id="14" word="مسؤولياتهم">
                    <svm_prediction>
                        <morph_feature_set diac="مَسْؤُولِيّاتِهِم" lemma="مَسْؤُولِيَّةmaso&amp;uwliy~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="a" enc0="3mp_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939044900424041">
                        <morph_feature_set diac="مَسْؤُولِيّاتِهِم" lemma="مَسْؤُولِيَّة_1" gloss="responsibility" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="a" enc0="3mp_poss" stem="مَسْؤُولِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مسؤوليات"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ms&amp;wlyAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_ACC"/>
                        <tok id="1" form0="+hm" form1="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مسؤوليات" form1="مسؤوليات" form2="مَسْؤُولِيَّة" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_ACC"/>
                        <tok id="1" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مسؤوليات"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="15" word="والخروج">
                    <svm_prediction>
                        <morph_feature_set diac="وَالخُرُوجِ" lemma="خُرُوجxuruwj" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943362057940295">
                        <morph_feature_set diac="وَالخُرُوجِ" lemma="خُرُوج_1" gloss="exit;getting_out;departure;deviation" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="خُرُوج"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الخروج"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="xrwj" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الخروج" form1="الخروج" form2="خُرُوج" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="خروج"/>
                    </tokenized>
                </word>
                <word id="16" word="عن">
                    <svm_prediction>
                        <morph_feature_set diac="عَن" lemma="عَنEan" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَن" lemma="عَن_1" gloss="from;about" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="En" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عن" form1="عن" form2="عَن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                </word>
                <word id="17" word="حالة">
                    <svm_prediction>
                        <morph_feature_set diac="حالَةِ" lemma="حالَةHAlap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="حالَةِ" lemma="حالَة_1" gloss="condition;case;situation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="حال"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حالة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="HAlp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حالة" form1="حالة" form2="حالَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حالة"/>
                    </tokenized>
                </word>
                <word id="18" word="الصمت">
                    <svm_prediction>
                        <morph_feature_set diac="الصَّمْتَ" lemma="صَمْتSamot" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="الصَّمْتِ" lemma="صَمْت_1" gloss="silence" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="صَمْت"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الصمت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Smt" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الصمت" form1="الصمت" form2="صَمْت" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="صمت"/>
                    </tokenized>
                </word>
                <word id="19" word="المخزي">
                    <svm_prediction>
                        <morph_feature_set diac="المَخْزِيّ" lemma="مُخْزِيmuxoziy" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8693383835832349">
                        <morph_feature_set diac="المَخْزِيِّ" lemma="مَخْزِيّ_1" gloss="ashamed;disgraceful" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="مَخْزِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المخزي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mxzy" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المخزي" form1="المخزي" form2="مَخْزِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مخزي"/>
                    </tokenized>
                </word>
                <word id="20" word="التي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8945079933398044">
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِي_1" gloss="which;who;whom_[fem.sg.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="الَّتِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alty" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التي" form1="التي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                </word>
                <word id="21" word="باتت">
                    <svm_prediction>
                        <morph_feature_set diac="باتَت" lemma="باتbAt" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="باتَت" lemma="بات-ِ_1" gloss="become;remain" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0" stem="بات"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="باتت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bAtt" form1="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="باتت" form1="باتت" form2="بات" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="باتت"/>
                    </tokenized>
                </word>
                <word id="22" word="وصمة">
                    <svm_prediction>
                        <morph_feature_set diac="وَصِمَّةٌ" lemma="أَصَمّ&gt;aSam~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8678620411306026">
                        <morph_feature_set diac="وَصْمَةَ" lemma="وَصْمَة_1" gloss="blemish;defect;disgrace" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0" stem="وَصْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="وصمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="wSmp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="وصمة" form1="وصمة" form2="وَصْمَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="وصمة"/>
                    </tokenized>
                </word>
                <word id="23" word="عار">
                    <svm_prediction>
                        <morph_feature_set diac="عارٍ" lemma="عارِيEAriy" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895576339810859">
                        <morph_feature_set diac="عارٍ" lemma="عارِي_1" gloss="naked;bare" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="عار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EAr" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عار" form1="عار" form2="عارِي" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عار"/>
                    </tokenized>
                </word>
                <word id="24" word="تلطخ">
                    <svm_prediction>
                        <morph_feature_set diac="تُلَطِّخ" lemma="لَطَّخlaT~ax" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8423851017933645">
                        <morph_feature_set diac="تَلَطَّخَ" lemma="تَلَطَّخ_1" gloss="be_soiled;be_stained" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="تَلَطَّخ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تلطخ"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tlTx" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تلطخ" form1="تلطخ" form2="تَلَطَّخ" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تلطخ"/>
                    </tokenized>
                </word>
                <word id="25" word="سمعة">
                    <svm_prediction>
                        <morph_feature_set diac="سُمْعَةِ" lemma="سَمِعsamiE" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8678620411306026">
                        <morph_feature_set diac="سُمْعَةَ" lemma="سُمْعَة_1" gloss="reputation;renown;fame" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0" stem="سُمْع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سمعة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="smEp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سمعة" form1="سمعة" form2="سُمْعَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سمعة"/>
                    </tokenized>
                </word>
                <word id="26" word="المجتمع">
                    <svm_prediction>
                        <morph_feature_set diac="المُجْتَمَعِ" lemma="مُجْتَمَعmujotamaE" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="المُجْتَمَعِ" lemma="مُجْتَمَع_1" gloss="society" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="مُجْتَمَع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المجتمع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mjtmE" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المجتمع" form1="المجتمع" form2="مُجْتَمَع" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مجتمع"/>
                    </tokenized>
                </word>
                <word id="27" word="الدولي">
                    <svm_prediction>
                        <morph_feature_set diac="الدُّوَلِيِّ" lemma="دَوْلِيّdawoliy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="الدُّوَلِيِّ" lemma="دَوْلِيّ_1" gloss="international;world" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="دُوَلِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدولي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwly" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدولي" form1="الدولي" form2="دَوْلِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دولي"/>
                    </tokenized>
                </word>
                <word id="28" word="وهو">
                    <svm_prediction>
                        <morph_feature_set diac="وَهُوَ" lemma="هُوَhuwa" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939703415048932">
                        <morph_feature_set diac="وَهُوَ" lemma="هُوَ_1" gloss="it;he" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="هُوَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هو"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="hw" form1="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="هو" form1="هو" form2="هُوَ" form3="NOM" form4="PRP" form5="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هو"/>
                    </tokenized>
                </word>
                <word id="29" word="يشاهد">
                    <svm_prediction>
                        <morph_feature_set diac="يُشاهَد" lemma="شاهَد$Ahad" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يُشاهِد" lemma="شاهَد_1" gloss="watch;observe;witness" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="شاهِد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يشاهد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="y$Ahd" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يشاهد" form1="يشاهد" form2="شاهَد" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يشاهد"/>
                    </tokenized>
                </word>
                <word id="30" word="ما">
                    <svm_prediction>
                        <morph_feature_set diac="ما" lemma="ماmA" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="ما" lemma="ما_1" gloss="what" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ما"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mA" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ما" form1="ما" form2="ما" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                </word>
                <word id="31" word="يرتكب">
                    <svm_prediction>
                        <morph_feature_set diac="يُرْتَكَب" lemma="ٱِرْتَكَب{irotakab" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يَرْتَكِب" lemma="ٱِرْتَكَب_1" gloss="commit;perpetrate" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="رْتَكِب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يرتكب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yrtkb" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يرتكب" form1="يرتكب" form2="ٱِرْتَكَب" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يرتكب"/>
                    </tokenized>
                </word>
                <word id="32" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="33" word="جرائم">
                    <svm_prediction>
                        <morph_feature_set diac="جَرائِمِ" lemma="جَرِيمَةjariymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="جَرائِمِ" lemma="جَرِيمَة_1" gloss="crimes" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="جَرائِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jrA}m" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جرائم" form1="جرائم" form2="جَرِيمَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                </word>
                <word id="34" word="ابادة">
                    <svm_prediction>
                        <morph_feature_set diac="إِبادَةٍ" lemma="آباد|bAd" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8085771629050374">
                        <morph_feature_set diac="إِبادَةٍ" lemma="إِبادَة_1" gloss="extermination;annihilation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="إِباد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ابادة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AbAdp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إبادة" form1="ابادة" form2="إِبادَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ابادة"/>
                    </tokenized>
                </word>
                <word id="35" word="ممنهجة">
                    <svm_prediction>
                        <morph_feature_set diac="ممنهجة" lemma="ممنهجةmmnhjp" pos="adj" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="na" cas="g" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ممنهجة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mmnhjp" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ممنهجة" form1="ممنهجة" form2="ممنهجة" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ممنهجة"/>
                    </tokenized>
                </word>
                <word id="36" word="بحق">
                    <svm_prediction>
                        <morph_feature_set diac="بِحَقِّ" lemma="حَقّHaq~" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِحَقِّ" lemma="حَقّ_2" gloss="truth;right" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="حَقّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="حق"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Hq" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="حق" form1="حق" form2="حَقّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="حق"/>
                    </tokenized>
                </word>
                <word id="37" word="الشعب">
                    <svm_prediction>
                        <morph_feature_set diac="الشَّعْبِ" lemma="شَعْب$aEob" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الشَّعْبِ" lemma="شَعْب_1" gloss="people;nation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شَعْب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشعب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$Eb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشعب" form1="الشعب" form2="شَعْب" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعب"/>
                    </tokenized>
                </word>
                <word id="38" word="اليمني">
                    <svm_prediction>
                        <morph_feature_set diac="اليُمْنَى" lemma="يَمَنِيّyamaniy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="اليَمَنِيِّ" lemma="يَمَنِيّ_1" gloss="Yemeni" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="يَمَنِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اليمني"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="ymny" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="اليمني" form1="اليمني" form2="يَمَنِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="يمني"/>
                    </tokenized>
                </word>
                <word id="39" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="40" word="قبل">
                    <svm_prediction>
                        <morph_feature_set diac="قِبَلِ" lemma="قِبَلqibal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="قِبَلِ" lemma="قِبَل_1" gloss="(on_the)_part_of" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قِبَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قبل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qbl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قبل" form1="قبل" form2="قِبَل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قبل"/>
                    </tokenized>
                </word>
                <word id="41" word="تحالف">
                    <svm_prediction>
                        <morph_feature_set diac="تَحالُفٍ" lemma="تَحالُفtaHAluf" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8873965659541032">
                        <morph_feature_set diac="تَحالُفِ" lemma="تَحالُف_1" gloss="alliance" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="تَحالُف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تحالف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tHAlf" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تحالف" form1="تحالف" form2="تَحالُف" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تحالف"/>
                    </tokenized>
                </word>
                <word id="42" word="العدوان">
                    <svm_prediction>
                        <morph_feature_set diac="العُدْوانِ" lemma="عَدُوّEaduw~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8830781083175002">
                        <morph_feature_set diac="العُدْوانِ" lemma="عُدْوان_1" gloss="aggression;hostility;enmity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عُدْوان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العدوان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EdwAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العدوان" form1="العدوان" form2="عُدْوان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدوان"/>
                    </tokenized>
                </word>
                <word id="43" word="السعودي">
                    <svm_prediction>
                        <morph_feature_set diac="السَّعُودِيُّ" lemma="سَعُودِيّsaEuwdiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="السَّعُودِيِّ" lemma="سَعُودِيّ_1" gloss="Saudi" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="سَعُودِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السعودي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="sEwdy" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السعودي" form1="السعودي" form2="سَعُودِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سعودي"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        
        <out_seg id="SENT5">
            <segment_info>
                <preprocessed>وعبر المصدر عن تعازي قيادة المؤتمر الشعبي العام ممثلة بالزعيم علي عبدالله صالح رئيس الجمهورية الاسبق رئيس المؤتمر الشعبي العام الحارة لاسر الشهيدات وتمنياته بالشفاء العاجل للمصابات</preprocessed>
                <bpc>
                    <chunk id="0" type="S">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="1" type="VP">
                        <tok id="0" form0="عبر"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </chunk>
                    <chunk id="3" type="PP">
                        <tok id="0" form0="عن"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="تعازي"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="قيادة"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤتمر"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="شعبي"/>
                        <tok id="4" form0="ال+"/>
                        <tok id="5" form0="عام"/>
                    </chunk>
                    <chunk id="7" type="ADJP">
                        <tok id="0" form0="ممثلة"/>
                    </chunk>
                    <chunk id="8" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="زعيم"/>
                    </chunk>
                    <chunk id="10" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="عبدالله"/>
                        <tok id="1" form0="صالح"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="رئيس"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جمهورية"/>
                    </chunk>
                    <chunk id="14" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اسبق"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="رئيس"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤتمر"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="شعبي"/>
                        <tok id="4" form0="ال+"/>
                        <tok id="5" form0="عام"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حارة"/>
                    </chunk>
                    <chunk id="18" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="اسر"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="الشهيدات"/>
                        <tok id="1" form0="و+"/>
                        <tok id="2" form0="تمنيات"/>
                    </chunk>
                    <chunk id="21" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="22" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شفاء"/>
                    </chunk>
                    <chunk id="24" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عاجل"/>
                    </chunk>
                    <chunk id="25" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصابات"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="و+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="عبر"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ال+"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="مصدر"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="عن"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="تعازي"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="قيادة"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="ال+"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="مؤتمر"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="ال+"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="شعبي"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="ال+"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="عام"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="ممثلة"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="ب+"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="ال+"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="زعيم"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="علي"/>
                    </ne>
                    <ne id="18" type="PER">
                        <tok id="18" form0="عبدالله"/>
                        <tok id="18" form0="صالح"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="رئيس"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ال+"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="جمهورية"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="ال+"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="اسبق"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="رئيس"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="ال+"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="مؤتمر"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ال+"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="شعبي"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="ال+"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="عام"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="ال+"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="حارة"/>
                    </ne>
                    <ne id="33" type="LOC">
                        <tok id="33" form0="ل+"/>
                        <tok id="33" form0="اسر"/>
                    </ne>
                    <ne id="34" type="LOC">
                        <tok id="34" form0="الشهيدات"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="و+"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="تمنيات"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="+ه"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="ب+"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="ال+"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="شفاء"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="ال+"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="عاجل"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="ل+"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="ال+"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="مصابات"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="وعبر">
                    <svm_prediction>
                        <morph_feature_set diac="وَعَبَّرَ" lemma="عَبْرEabor" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8788767000571676">
                        <morph_feature_set diac="وَعَبَّرَ" lemma="عَبَّر_1" gloss="express" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="عَبَّر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="عبر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Ebr" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="عبر" form1="عبر" form2="عَبَّر" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="عبر"/>
                    </tokenized>
                </word>
                <word id="1" word="المصدر">
                    <svm_prediction>
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَرmaSodar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950630275921179">
                        <morph_feature_set diac="المَصْدَرُ" lemma="مَصْدَر_1" gloss="source" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="مَصْدَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المصدر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mSdr" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المصدر" form1="المصدر" form2="مَصْدَر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مصدر"/>
                    </tokenized>
                </word>
                <word id="2" word="عن">
                    <svm_prediction>
                        <morph_feature_set diac="عَن" lemma="عَنEan" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَن" lemma="عَن_1" gloss="from;about" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="En" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عن" form1="عن" form2="عَن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                </word>
                <word id="3" word="تعازي">
                    <svm_prediction>
                        <morph_feature_set diac="تَعازِيَ" lemma="تَعْزِيَةtaEoziyap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8873965659541032">
                        <morph_feature_set diac="تَعازِيِ" lemma="تَعْزِيَة_1" gloss="condolences;mourning" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="تَعازِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تعازي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tEAzy" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تعازي" form1="تعازي" form2="تَعْزِيَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تعازي"/>
                    </tokenized>
                </word>
                <word id="4" word="قيادة">
                    <svm_prediction>
                        <morph_feature_set diac="قِيادَةِ" lemma="قِيادَةqiyAdap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="قِيادَةِ" lemma="قِيادَة_1" gloss="leadership;command" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="قِياد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قيادة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qyAdp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قيادة" form1="قيادة" form2="قِيادَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قيادة"/>
                    </tokenized>
                </word>
                <word id="5" word="المؤتمر">
                    <svm_prediction>
                        <morph_feature_set diac="المُؤْتَمَرُ" lemma="مُؤْتَمَرmu&amp;otamar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="المُؤْتَمَرِ" lemma="مُؤْتَمَر_1" gloss="conference;convention" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="مُؤْتَمَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المؤتمر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="m&amp;tmr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المؤتمر" form1="المؤتمر" form2="مُؤْتَمَر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤتمر"/>
                    </tokenized>
                </word>
                <word id="6" word="الشعبي">
                    <svm_prediction>
                        <morph_feature_set diac="الشَّعْبِيُّ" lemma="شَعْبِيّ$aEobiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="الشَّعْبِيِّ" lemma="شَعْبِيّ_1" gloss="popular;national;people's" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شَعْبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشعبي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$Eby" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشعبي" form1="الشعبي" form2="شَعْبِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعبي"/>
                    </tokenized>
                </word>
                <word id="7" word="العام">
                    <svm_prediction>
                        <morph_feature_set diac="العامُّ" lemma="عامّEAm~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="العامِّ" lemma="عامّ_1" gloss="general;common;public" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عامّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EAm" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العام" form1="العام" form2="عامّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عام"/>
                    </tokenized>
                </word>
                <word id="8" word="ممثلة">
                    <svm_prediction>
                        <morph_feature_set diac="مُمَثَّلَةً" lemma="مُمَثِّلmumav~il" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8781288151948654">
                        <morph_feature_set diac="مُمَثَّلَةً" lemma="مُمَثَّل_1" gloss="represented;depicted" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="a" enc0="0" stem="مُمَثَّل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ممثلة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mmvlp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ممثلة" form1="ممثلة" form2="مُمَثَّل" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ممثلة"/>
                    </tokenized>
                </word>
                <word id="9" word="بالزعيم">
                    <svm_prediction>
                        <morph_feature_set diac="بِالزَّعِيمِ" lemma="زَعِيمzaEiym" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941697366852527">
                        <morph_feature_set diac="بِالزَّعِيمِ" lemma="زَعِيم_1" gloss="leader;head_of_state" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="زَعِيم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="الزعيم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="zEym" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الزعيم" form1="الزعيم" form2="زَعِيم" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="زعيم"/>
                    </tokenized>
                </word>
                <word id="10" word="علي">
                    <svm_prediction>
                        <morph_feature_set diac="عَلِيّ" lemma="عَلِيّEaliy~" pos="prep" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7810516733095484">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="11" word="عبدالله">
                    <svm_prediction>
                        <morph_feature_set diac="عَبْداللّٰه" lemma="عَبْداللّٰهEabodAll~`h" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="عَبْداللّٰه" lemma="عَبْداللّٰه_1" gloss="Abdallah" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="عَبْداللّٰه"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عبدالله"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EbdAllh" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عبدالله" form1="عبدالله" form2="عَبْداللّٰه" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عبدالله"/>
                    </tokenized>
                </word>
                <word id="12" word="صالح">
                    <svm_prediction>
                        <morph_feature_set diac="صالِح" lemma="صالِحSAliH" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8998215129572901">
                        <morph_feature_set diac="صالِح" lemma="صالِح_1" gloss="Salih;Saleh" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="صالِح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="صالح"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="SAlH" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="صالح" form1="صالح" form2="صالِح" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="صالح"/>
                    </tokenized>
                </word>
                <word id="13" word="رئيس">
                    <svm_prediction>
                        <morph_feature_set diac="رَئِيسِ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="رَئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رئيس" form1="رئيس" form2="رَئِيس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="14" word="الجمهورية">
                    <svm_prediction>
                        <morph_feature_set diac="الجُمْهُورِيَّةِ" lemma="جُمْهُورِيّjumohuwriy~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الجُمْهُورِيَّةِ" lemma="جُمْهُورِيّ_1" gloss="republic" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="جُمْهُورِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجمهورية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jmhwryp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجمهورية" form1="الجمهورية" form2="جُمْهُورِيّ" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جمهورية"/>
                    </tokenized>
                </word>
                <word id="15" word="الاسبق">
                    <svm_prediction>
                        <morph_feature_set diac="الأَسْبَقِ" lemma="أَسْبَق&gt;asobaq" pos="adj_comp" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.745566086446586">
                        <morph_feature_set diac="الأَسْبَقُ" lemma="أَسْبَق_1" gloss="previous;former;earlier" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="أَسْبَق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاسبق"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Asbq" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأسبق" form1="الاسبق" form2="أَسْبَق" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اسبق"/>
                    </tokenized>
                </word>
                <word id="16" word="رئيس">
                    <svm_prediction>
                        <morph_feature_set diac="رَئِيسُ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8948599496329743">
                        <morph_feature_set diac="رَئِيسُ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="r}ys" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رئيس" form1="رئيس" form2="رَئِيس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="17" word="المؤتمر">
                    <svm_prediction>
                        <morph_feature_set diac="المُؤْتَمَرُ" lemma="مُؤْتَمَرmu&amp;otamar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="المُؤْتَمَرِ" lemma="مُؤْتَمَر_1" gloss="conference;convention" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="مُؤْتَمَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المؤتمر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="m&amp;tmr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المؤتمر" form1="المؤتمر" form2="مُؤْتَمَر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤتمر"/>
                    </tokenized>
                </word>
                <word id="18" word="الشعبي">
                    <svm_prediction>
                        <morph_feature_set diac="الشَّعْبِيُّ" lemma="شَعْبِيّ$aEobiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="الشَّعْبِيِّ" lemma="شَعْبِيّ_1" gloss="popular;national;people's" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شَعْبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشعبي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$Eby" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشعبي" form1="الشعبي" form2="شَعْبِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعبي"/>
                    </tokenized>
                </word>
                <word id="19" word="العام">
                    <svm_prediction>
                        <morph_feature_set diac="العامُّ" lemma="عامّEAm~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="العامِّ" lemma="عامّ_1" gloss="general;common;public" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عامّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EAm" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العام" form1="العام" form2="عامّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عام"/>
                    </tokenized>
                </word>
                <word id="20" word="الحارة">
                    <svm_prediction>
                        <morph_feature_set diac="الحارَّةِ" lemma="حارّHAr~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الحارَّةِ" lemma="حارّ_1" gloss="hot;fervent" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="حارّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الحارة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="HArp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الحارة" form1="الحارة" form2="حارّ" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حارة"/>
                    </tokenized>
                </word>
                <word id="21" word="لاسر">
                    <svm_prediction>
                        <morph_feature_set diac="لِأُسَرِ" lemma="أُسْرَة&gt;usorap" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8246381262094312">
                        <morph_feature_set diac="لِأُسَرِ" lemma="أُسْرَة_1" gloss="families;communities" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="أُسَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="اسر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Asr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="أسر" form1="اسر" form2="أُسْرَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="اسر"/>
                    </tokenized>
                </word>
                <word id="22" word="الشهيدات">
                    <svm_prediction>
                        <morph_feature_set diac="الشهيدات" lemma="الشهيداتAl$hydAt" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشهيدات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al$hydAt" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشهيدات" form1="الشهيدات" form2="الشهيدات" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الشهيدات"/>
                    </tokenized>
                </word>
                <word id="23" word="وتمنياته">
                    <svm_prediction>
                        <morph_feature_set diac="وَتَمَنِّياتِهِ" lemma="تَمَنِّيtaman~iy" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939085801890397">
                        <morph_feature_set diac="وَتَمَنِّياتِهِ" lemma="تَمَنِّي_1" gloss="wishes;hopes;desires" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="3ms_poss" stem="تَمَنِّي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="تمنيات"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="tmnyAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="تمنيات" form1="تمنيات" form2="تَمَنِّي" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="تمنيات"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="24" word="بالشفاء">
                    <svm_prediction>
                        <morph_feature_set diac="بِالشِّفاء" lemma="شِفاء$ifA'" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8838712637762707">
                        <morph_feature_set diac="بِالشِّفاءِ" lemma="شِفاء_1" gloss="cure;remedy;medication" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شِفاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="الشفاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="$fA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الشفاء" form1="الشفاء" form2="شِفاء" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="شفاء"/>
                    </tokenized>
                </word>
                <word id="25" word="العاجل">
                    <svm_prediction>
                        <morph_feature_set diac="العاجِلِ" lemma="عاجِلEAjil" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8297979948737684">
                        <morph_feature_set diac="العاجِلِ" lemma="عاجِل_1" gloss="urgent;speedy" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عاجِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العاجل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EAjl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العاجل" form1="العاجل" form2="عاجِل" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عاجل"/>
                    </tokenized>
                </word>
                <word id="26" word="للمصابات">
                    <svm_prediction>
                        <morph_feature_set diac="لِلمُصابات" lemma="مُصابmuSAb" pos="adj" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.883602335991648">
                        <morph_feature_set diac="لِلمُصاباتِ" lemma="مُصاب_1" gloss="afflicted;injured;wounded" pos="adj" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0" stem="مُصاب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="المصابات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="mSAbAt" form1="ADJ+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="المصابات" form1="المصابات" form2="مُصاب" form3="NOM" form4="DT+JJ+#S" form5="DET+ADJ+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="مصابات"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
     
        
		</out_doc>
	<out_doc id="Text_Document_02.txt">
        <out_seg id="SENT1">
            <segment_info>
                <preprocessed>عبد الباري عطوان</preprocessed>
                <bpc>
                    <chunk id="0" type="NP">
                        <tok id="0" form0="عبد"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="باري"/>
                        <tok id="3" form0="عطوان"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="PER">
                        <tok id="0" form0="عبد"/>
                        <tok id="0" form0="ال+"/>
                    </ne>
                    <ne id="1" type="PER">
                        <tok id="1" form0="باري"/>
                    </ne>
                    <ne id="2" type="PER">
                        <tok id="2" form0="عطوان"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="عبد">
                    <svm_prediction>
                        <morph_feature_set diac="عَبْد" lemma="عَبْدEabod" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8998215129572901">
                        <morph_feature_set diac="عَبْد" lemma="عَبْد_1" gloss="Abd" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="عَبْد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عبد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ebd" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عبد" form1="عبد" form2="عَبْد" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عبد"/>
                    </tokenized>
                </word>
                <word id="1" word="الباري">
                    <svm_prediction>
                        <morph_feature_set diac="البارِي" lemma="بارِيbAriy" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="البارِي" lemma="بارِي_1" gloss="Bari;Bary" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="بارِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الباري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="bAry" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الباري" form1="الباري" form2="بارِي" form3="PROP" form4="DT+NNP" form5="DET+NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="باري"/>
                    </tokenized>
                </word>
                <word id="2" word="عطوان">
                    <svm_prediction>
                        <morph_feature_set diac="عَطْوان" lemma="عَطْوانEaTowAn" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8998215129572901">
                        <morph_feature_set diac="عَطْوان" lemma="عَطْوان_1" gloss="Atwan" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="عَطْوان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عطوان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ETwAn" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عطوان" form1="عطوان" form2="عَطْوان" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عطوان"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT2">
            <segment_info>
                <preprocessed>قررنا الابتعاد مؤقتا في هذه الزاوية عن الملفات العربية المعتادة مثل سورية واليمن والحروب الدائرة فيها او حولها , عسكريا ودبلوماسيا , بحثا عن جديد لتجنب ملل القارئ العزيز على قلوبنا , والحفاظ على اهتمامه , ومودته , معا , فاستوقفنا حدثان سياسيان ينطويان على الكثير من المعاني والدروس والعبر , وان كنا لا نستطيع فصلهما كليا عن منطقتنا العربية</preprocessed>
                <bpc>
                    <chunk id="0" type="VP">
                        <tok id="0" form0="قررنا"/>
                    </chunk>
                    <chunk id="1" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ابتعاد"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="مؤقتا"/>
                    </chunk>
                    <chunk id="3" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="هذه"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="زاوية"/>
                    </chunk>
                    <chunk id="6" type="PP">
                        <tok id="0" form0="عن"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ملفات"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="عربية"/>
                        <tok id="4" form0="ال+"/>
                        <tok id="5" form0="معتادة"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="مثل"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="سورية"/>
                        <tok id="1" form0="و+"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="يمن"/>
                    </chunk>
                    <chunk id="10" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حروب"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="دائرة"/>
                    </chunk>
                    <chunk id="12" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="14" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="حول"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="17" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="عسكريا"/>
                        <tok id="1" form0="و+"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="دبلوماسيا"/>
                    </chunk>
                    <chunk id="20" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="21" type="NP">
                        <tok id="0" form0="بحثا"/>
                    </chunk>
                    <chunk id="22" type="PP">
                        <tok id="0" form0="عن"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="جديد"/>
                    </chunk>
                    <chunk id="24" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="تجنب"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="ملل"/>
                    </chunk>
                    <chunk id="27" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قارئ"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="عزيز"/>
                    </chunk>
                    <chunk id="28" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="قلوب"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                    <chunk id="31" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="32" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="33" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حفاظ"/>
                    </chunk>
                    <chunk id="34" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="اهتمام"/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="37" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="38" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="39" type="NP">
                        <tok id="0" form0="مودة"/>
                    </chunk>
                    <chunk id="40" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="41" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="42" type="NP">
                        <tok id="0" form0="معا"/>
                    </chunk>
                    <chunk id="43" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="44" type="">
                        <tok id="0" form0="ف+"/>
                    </chunk>
                    <chunk id="45" type="VP">
                        <tok id="0" form0="استوقف"/>
                    </chunk>
                    <chunk id="46" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                    <chunk id="47" type="NP">
                        <tok id="0" form0="حدثان"/>
                        <tok id="1" form0="سياسيان"/>
                    </chunk>
                    <chunk id="48" type="VP">
                        <tok id="0" form0="ينطويان"/>
                    </chunk>
                    <chunk id="49" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="50" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="كثير"/>
                    </chunk>
                    <chunk id="51" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="52" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="معاني"/>
                        <tok id="2" form0="و+"/>
                        <tok id="3" form0="ال+"/>
                        <tok id="4" form0="دروس"/>
                        <tok id="5" form0="و+"/>
                        <tok id="6" form0="ال+"/>
                        <tok id="7" form0="عبر"/>
                    </chunk>
                    <chunk id="53" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="54" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="55" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="56" type="VP">
                        <tok id="0" form0="كنا"/>
                    </chunk>
                    <chunk id="57" type="VP">
                        <tok id="0" form0="لا"/>
                        <tok id="1" form0="نستطيع"/>
                    </chunk>
                    <chunk id="58" type="NP">
                        <tok id="0" form0="فصل"/>
                    </chunk>
                    <chunk id="59" type="NP">
                        <tok id="0" form0="+هما"/>
                    </chunk>
                    <chunk id="60" type="NP">
                        <tok id="0" form0="كليا"/>
                    </chunk>
                    <chunk id="61" type="PP">
                        <tok id="0" form0="عن"/>
                    </chunk>
                    <chunk id="62" type="NP">
                        <tok id="0" form0="منطقة"/>
                    </chunk>
                    <chunk id="63" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                    <chunk id="64" type="ADJP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عربية"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="قررنا"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="ال+"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ابتعاد"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="مؤقتا"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="في"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="هذه"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="ال+"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="زاوية"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="عن"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="ال+"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="ملفات"/>
                    </ne>
                    <ne id="11" type="PER">
                        <tok id="11" form0="ال+"/>
                        <tok id="11" form0="عربية"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="ال+"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="معتادة"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="مثل"/>
                    </ne>
                    <ne id="15" type="LOC">
                        <tok id="15" form0="سورية"/>
                    </ne>
                    <ne id="16" type="LOC">
                        <tok id="16" form0="و+"/>
                    </ne>
                    <ne id="17" type="LOC">
                        <tok id="17" form0="ال+"/>
                        <tok id="17" form0="يمن"/>
                    </ne>
                    <ne id="18" type="PER">
                        <tok id="18" form0="و+"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="ال+"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="حروب"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="ال+"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="دائرة"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="في"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="+ها"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="او"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="حول"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="+ها"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0=","/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="عسكريا"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="و+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="دبلوماسيا"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0=","/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="بحثا"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="عن"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="جديد"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="ل+"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="تجنب"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="ملل"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="ال+"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="قارئ"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="ال+"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="عزيز"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="علي"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="قلوب"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="+نا"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0=","/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="و+"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="ال+"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="حفاظ"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="علي"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="اهتمام"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="+ه"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0=","/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="و+"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="مودة"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="+ه"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0=","/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="معا"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0=","/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="ف+"/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0="استوقف"/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="+نا"/>
                    </ne>
                    <ne id="63" type="">
                        <tok id="63" form0="حدثان"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0="سياسيان"/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0="ينطويان"/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="علي"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0="ال+"/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="كثير"/>
                    </ne>
                    <ne id="69" type="">
                        <tok id="69" form0="من"/>
                    </ne>
                    <ne id="70" type="">
                        <tok id="70" form0="ال+"/>
                    </ne>
                    <ne id="71" type="">
                        <tok id="71" form0="معاني"/>
                    </ne>
                    <ne id="72" type="">
                        <tok id="72" form0="و+"/>
                    </ne>
                    <ne id="73" type="">
                        <tok id="73" form0="ال+"/>
                    </ne>
                    <ne id="74" type="">
                        <tok id="74" form0="دروس"/>
                    </ne>
                    <ne id="75" type="">
                        <tok id="75" form0="و+"/>
                    </ne>
                    <ne id="76" type="">
                        <tok id="76" form0="ال+"/>
                    </ne>
                    <ne id="77" type="">
                        <tok id="77" form0="عبر"/>
                    </ne>
                    <ne id="78" type="">
                        <tok id="78" form0=","/>
                    </ne>
                    <ne id="79" type="">
                        <tok id="79" form0="و+"/>
                    </ne>
                    <ne id="80" type="">
                        <tok id="80" form0="ان"/>
                    </ne>
                    <ne id="81" type="">
                        <tok id="81" form0="كنا"/>
                    </ne>
                    <ne id="82" type="">
                        <tok id="82" form0="لا"/>
                    </ne>
                    <ne id="83" type="">
                        <tok id="83" form0="نستطيع"/>
                    </ne>
                    <ne id="84" type="">
                        <tok id="84" form0="فصل"/>
                    </ne>
                    <ne id="85" type="">
                        <tok id="85" form0="+هما"/>
                    </ne>
                    <ne id="86" type="">
                        <tok id="86" form0="كليا"/>
                    </ne>
                    <ne id="87" type="">
                        <tok id="87" form0="عن"/>
                    </ne>
                    <ne id="88" type="">
                        <tok id="88" form0="منطقة"/>
                    </ne>
                    <ne id="89" type="">
                        <tok id="89" form0="+نا"/>
                    </ne>
                    <ne id="90" type="">
                        <tok id="90" form0="ال+"/>
                    </ne>
                    <ne id="91" type="">
                        <tok id="91" form0="عربية"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="قررنا">
                    <svm_prediction>
                        <morph_feature_set diac="قَرَرْنا" lemma="قَرَّرqar~ar" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8569682471950438">
                        <morph_feature_set diac="قَرَّرْنا" lemma="قَرَّر_1" gloss="decide;resolve" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="قَرَّر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قررنا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qrrnA" form1="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قررنا" form1="قررنا" form2="قَرَّر" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قررنا"/>
                    </tokenized>
                </word>
                <word id="1" word="الابتعاد">
                    <svm_prediction>
                        <morph_feature_set diac="الاِبْتِعادِ" lemma="ٱِبْتِعاد{ibotiEAd" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8849138440518091">
                        <morph_feature_set diac="الاِبْتِعادَ" lemma="ٱِبْتِعاد_1" gloss="avoiding;eschewing" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="ٱِبْتِعاد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الابتعاد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AbtEAd" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الابتعاد" form1="الابتعاد" form2="ٱِبْتِعاد" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ابتعاد"/>
                    </tokenized>
                </word>
                <word id="2" word="مؤقتا">
                    <svm_prediction>
                        <morph_feature_set diac="مُؤَقَّتاً" lemma="مُؤَقَّتmu&amp;aq~at" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8256884121246769">
                        <morph_feature_set diac="مُؤَقَّتاً" lemma="مُؤَقَّت_1" gloss="temporary;provisional" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="مُؤَقَّت"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مؤقتا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="m&amp;qtA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مؤقتا" form1="مؤقتا" form2="مُؤَقَّت" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مؤقتا"/>
                    </tokenized>
                </word>
                <word id="3" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="4" word="هذه">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذا_1" gloss="this;these" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="هٰذِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*h" form1="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذه" form1="هذه" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                </word>
                <word id="5" word="الزاوية">
                    <svm_prediction>
                        <morph_feature_set diac="الزّاوِيَةِ" lemma="زاوِيَةzAwiyap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الزّاوِيَةِ" lemma="زاوِيَة_1" gloss="corner;nook;angle" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="زاوِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الزاوية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="zAwyp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الزاوية" form1="الزاوية" form2="زاوِيَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="زاوية"/>
                    </tokenized>
                </word>
                <word id="6" word="عن">
                    <svm_prediction>
                        <morph_feature_set diac="عَن" lemma="عَنEan" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَن" lemma="عَن_1" gloss="from;about" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="En" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عن" form1="عن" form2="عَن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                </word>
                <word id="7" word="الملفات">
                    <svm_prediction>
                        <morph_feature_set diac="المِلَفّاتِ" lemma="مِلَفَّةmilaf~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8947650584943242">
                        <morph_feature_set diac="المِلَفّاتِ" lemma="مِلَفَّة_1" gloss="dossier;letter_file" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0" stem="مِلَفّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الملفات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mlfAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الملفات" form1="الملفات" form2="مِلَفَّة" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ملفات"/>
                    </tokenized>
                </word>
                <word id="8" word="العربية">
                    <svm_prediction>
                        <morph_feature_set diac="العَرَبِيَّةِ" lemma="عَرَبِيّEarabiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="العَرَبِيَّةِ" lemma="عَرَبِيّ_1" gloss="Arabic;Arab" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="عَرَبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العربية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Erbyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العربية" form1="العربية" form2="عَرَبِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عربية"/>
                    </tokenized>
                </word>
                <word id="9" word="المعتادة">
                    <svm_prediction>
                        <morph_feature_set diac="المُعْتادَةِ" lemma="مُعْتادmuEotAd" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="المُعْتادَةِ" lemma="مُعْتاد_1" gloss="habituated;accustomed" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مُعْتاد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المعتادة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mEtAdp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المعتادة" form1="المعتادة" form2="مُعْتاد" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="معتادة"/>
                    </tokenized>
                </word>
                <word id="10" word="مثل">
                    <svm_prediction>
                        <morph_feature_set diac="مِثْلَ" lemma="مِثْلmivol" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8969741517107328">
                        <morph_feature_set diac="مِثْلَ" lemma="مِثْل_1" gloss="same;like" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="مِثْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مثل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mvl" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مثل" form1="مثل" form2="مِثْل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مثل"/>
                    </tokenized>
                </word>
                <word id="11" word="سورية">
                    <svm_prediction>
                        <morph_feature_set diac="سُورِيَّةَ" lemma="سُورِياsuwriyA" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836129704006463">
                        <morph_feature_set diac="سُورِيَّةِ" lemma="سُورِيا_1" gloss="Syria" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="سُورِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سورية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="swryp" form1="NOUN_PROP+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سورية" form1="سورية" form2="سُورِيا" form3="PROP" form4="NNP" form5="NOUN_PROP+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سورية"/>
                    </tokenized>
                </word>
                <word id="12" word="واليمن">
                    <svm_prediction>
                        <morph_feature_set diac="وَاليَمَنِ" lemma="يَمَنyaman" pos="noun_prop" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.893930667019417">
                        <morph_feature_set diac="وَاليَمَنِ" lemma="يَمَن_2" gloss="Yemen" pos="noun_prop" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="يَمَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اليمن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="ymn" form1="NOUN_PROP+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="اليمن" form1="اليمن" form2="يَمَن" form3="PROP" form4="DT+NNP" form5="DET+NOUN_PROP+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="يمن"/>
                    </tokenized>
                </word>
                <word id="13" word="والحروب">
                    <svm_prediction>
                        <morph_feature_set diac="وَالحُرُوبِ" lemma="حَرْبHarob" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943362057940295">
                        <morph_feature_set diac="وَالحُرُوبِ" lemma="حَرْب_1" gloss="wars" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="حُرُوب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الحروب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="Hrwb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الحروب" form1="الحروب" form2="حَرْب" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="حروب"/>
                    </tokenized>
                </word>
                <word id="14" word="الدائرة">
                    <svm_prediction>
                        <morph_feature_set diac="الدّائِرَةِ" lemma="دائِرdA}ir" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="الدّائِرَةِ" lemma="دائِر_1" gloss="current;running" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="دائِر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدائرة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dA}rp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدائرة" form1="الدائرة" form2="دائِر" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دائرة"/>
                    </tokenized>
                </word>
                <word id="15" word="فيها">
                    <svm_prediction>
                        <morph_feature_set diac="فِيها" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="فِيها" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="16" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="17" word="حولها">
                    <svm_prediction>
                        <morph_feature_set diac="حَوْلَها" lemma="حَوْلHawol" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3fs_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940280127411849">
                        <morph_feature_set diac="حَوْلَها" lemma="حَوْل_1" gloss="power" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3fs_poss" stem="حَوْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حول"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Hwl" form1="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+hA" form1="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حول" form1="حول" form2="حَوْل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حول"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="18" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="19" word="عسكريا">
                    <svm_prediction>
                        <morph_feature_set diac="عَسْكَرِيّاً" lemma="عَسْكَرِيّEasokariy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946349927825878">
                        <morph_feature_set diac="عَسْكَرِيّاً" lemma="عَسْكَرِيّ_1" gloss="military;army" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="عَسْكَرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عسكريا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EskryA" form1="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عسكريا" form1="عسكريا" form2="عَسْكَرِيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عسكريا"/>
                    </tokenized>
                </word>
                <word id="20" word="ودبلوماسيا">
                    <svm_prediction>
                        <morph_feature_set diac="وَدِبلُوماسِيّا" lemma="دِبلُوماسِيّdibluwmAsiy~" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836403744190412">
                        <morph_feature_set diac="وَدِبلُوماسِيّاً" lemma="دِبلُوماسِيّ_1" gloss="diplomatic" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="دِبلُوماسِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="دبلوماسيا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="dblwmAsyA" form1="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="دبلوماسيا" form1="دبلوماسيا" form2="دِبلُوماسِيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="دبلوماسيا"/>
                    </tokenized>
                </word>
                <word id="21" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="22" word="بحثا">
                    <svm_prediction>
                        <morph_feature_set diac="بَحْثاً" lemma="بَحَثbaHav" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8789685255684088">
                        <morph_feature_set diac="بَحْثاً" lemma="بَحْث_1" gloss="discussion" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="بَحْث"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بحثا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bHvA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بحثا" form1="بحثا" form2="بَحْث" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بحثا"/>
                    </tokenized>
                </word>
                <word id="23" word="عن">
                    <svm_prediction>
                        <morph_feature_set diac="عَن" lemma="عَنEan" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَن" lemma="عَن_1" gloss="from;about" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="En" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عن" form1="عن" form2="عَن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                </word>
                <word id="24" word="جديد">
                    <svm_prediction>
                        <morph_feature_set diac="جَدِيدٍ" lemma="جَدِيدjadiyd" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894442345679612">
                        <morph_feature_set diac="جَدِيدٍ" lemma="جَدِيد_1" gloss="new;modern" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="جَدِيد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جديد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jdyd" form1="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جديد" form1="جديد" form2="جَدِيد" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جديد"/>
                    </tokenized>
                </word>
                <word id="25" word="لتجنب">
                    <svm_prediction>
                        <morph_feature_set diac="لِتَجَنُّبِ" lemma="تَجَنُّبtajan~ub" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944178048308999">
                        <morph_feature_set diac="لِتَجَنُّبِ" lemma="تَجَنُّب_1" gloss="avoidance;avoiding" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="تَجَنُّب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="تجنب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="tjnb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="تجنب" form1="تجنب" form2="تَجَنُّب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="تجنب"/>
                    </tokenized>
                </word>
                <word id="26" word="ملل">
                    <svm_prediction>
                        <morph_feature_set diac="مَلَلٍ" lemma="مَلَلmalal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895576339810859">
                        <morph_feature_set diac="مَلَلٍ" lemma="مَلَل_1" gloss="boredom;annoyance" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="مَلَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ملل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mll" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ملل" form1="ملل" form2="مَلَل" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ملل"/>
                    </tokenized>
                </word>
                <word id="27" word="القارئ">
                    <svm_prediction>
                        <morph_feature_set diac="القارِئُ" lemma="قارِئqAri}" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="القارِئِ" lemma="قارِئ_1" gloss="reader" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="قارِئ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القارئ"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qAr}" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القارئ" form1="القارئ" form2="قارِئ" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قارئ"/>
                    </tokenized>
                </word>
                <word id="28" word="العزيز">
                    <svm_prediction>
                        <morph_feature_set diac="العَزِيزُ" lemma="عَزِيزEaziyz" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="العَزِيزِ" lemma="عَزِيز_2" gloss="dear;precious" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عَزِيز"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العزيز"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Ezyz" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العزيز" form1="العزيز" form2="عَزِيز" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عزيز"/>
                    </tokenized>
                </word>
                <word id="29" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="30" word="قلوبنا">
                    <svm_prediction>
                        <morph_feature_set diac="قُلُوبِنا" lemma="قَلْبqalob" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939458006110683">
                        <morph_feature_set diac="قُلُوبِنا" lemma="قَلْب_3" gloss="hearts" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss" stem="قُلُوب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قلوب"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qlwb" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+nA" form1="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قلوب" form1="قلوب" form2="قَلْب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قلوب"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="31" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="32" word="والحفاظ">
                    <svm_prediction>
                        <morph_feature_set diac="وَالحِفاظِ" lemma="حِفاظHifAZ" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943362057940295">
                        <morph_feature_set diac="وَالحِفاظِ" lemma="حِفاظ_1" gloss="preservation;guarding" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="حِفاظ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الحفاظ"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="HfAZ" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الحفاظ" form1="الحفاظ" form2="حِفاظ" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="حفاظ"/>
                    </tokenized>
                </word>
                <word id="33" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="34" word="اهتمامه">
                    <svm_prediction>
                        <morph_feature_set diac="اِهْتِمامِهِ" lemma="ٱِهْتِمام{ihotimAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942773079888653">
                        <morph_feature_set diac="اِهْتِمامِهِ" lemma="ٱِهْتِمام_1" gloss="interest;concern;care;attention" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="ٱِهْتِمام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اهتمام"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AhtmAm" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="اهتمام" form1="اهتمام" form2="ٱِهْتِمام" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اهتمام"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="35" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="36" word="ومودته">
                    <svm_prediction>
                        <morph_feature_set diac="وَمَوَدَّتُهُ" lemma="مَوَدَّةmawad~ap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="n" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939040810220006">
                        <morph_feature_set diac="وَمَوَدَّتُهُ" lemma="مَوَدَّة_1" gloss="friendship;love" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="n" enc0="3ms_poss" stem="مَوَدّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مودة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="mwdp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="مودة" form1="مودة" form2="مَوَدَّة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مودة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="37" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="38" word="معا">
                    <svm_prediction>
                        <morph_feature_set diac="مَعاً" lemma="مَعاًmaEAF" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مَعاً" lemma="مَعاً_1" gloss="together" pos="adv" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="مَعاً"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="معا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mEA" form1="ADV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="معا" form1="معا" form2="مَعاً" form3="NOM" form4="RB" form5="ADV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="معا"/>
                    </tokenized>
                </word>
                <word id="39" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="40" word="فاستوقفنا">
                    <svm_prediction>
                        <morph_feature_set diac="فَاِسْتَوْقَفْنا" lemma="ٱِسْتَوْقَف{isotawoqaf" pos="verb" prc3="0" prc2="fa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8278883633008345">
                        <morph_feature_set diac="فَاِسْتَوْقَفَنا" lemma="ٱِسْتَوْقَف_1" gloss="ask_to_stop;catch" pos="verb" prc3="0" prc2="fa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="1p_dobj" stem="ٱِسْتَوْقَف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="استوقف"/>
                        <tok id="2" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="f+" form1="CONJ+"/>
                        <tok id="1" form0="Astwqf" form1="PV+PVSUFF_SUBJ:3MS"/>
                        <tok id="2" form0="+nA" form1="+PVSUFF_DO:1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ف+" form1="ف+" form2="فَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="استوقف" form1="استوقف" form2="ٱِسْتَوْقَف" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                        <tok id="2" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP" form5="+PVSUFF_DO:1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="استوقف"/>
                        <tok id="2" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="41" word="حدثان">
                    <svm_prediction>
                        <morph_feature_set diac="حَدَثانِ" lemma="حَدَثHadav" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939153289641083">
                        <morph_feature_set diac="حَدَثانِ" lemma="حَدَث_1" gloss="incident;event" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="i" cas="n" enc0="0" stem="حَدَث"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حدثان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="HdvAn" form1="NOUN+NSUFF_MASC_DU_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حدثان" form1="حدثان" form2="حَدَث" form3="NOM" form4="NNS" form5="NOUN+NSUFF_MASC_DU_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حدثان"/>
                    </tokenized>
                </word>
                <word id="42" word="سياسيان">
                    <svm_prediction>
                        <morph_feature_set diac="سِياسِيّانِ" lemma="سِياسِيّsiyAsiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939069441333173">
                        <morph_feature_set diac="سِياسِيّانِ" lemma="سِياسِيّ_1" gloss="political" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="i" cas="n" enc0="0" stem="سِياسِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سياسيان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="syAsyAn" form1="ADJ+NSUFF_MASC_DU_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سياسيان" form1="سياسيان" form2="سِياسِيّ" form3="NOM" form4="JJ+#S" form5="ADJ+NSUFF_MASC_DU_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سياسيان"/>
                    </tokenized>
                </word>
                <word id="43" word="ينطويان">
                    <svm_prediction>
                        <morph_feature_set diac="يَنْطَوِيانِ" lemma="ٱِنْطَوَى{inoTawaY" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="d" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="يَنْطَوِيانِ" lemma="ٱِنْطَوَى_1" gloss="contain;include;harbor" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="d" stt="na" cas="na" enc0="0" stem="نْطَوِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ينطويان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ynTwyAn" form1="IV3MD+IV+IVSUFF_SUBJ:D_MOOD:I"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ينطويان" form1="ينطويان" form2="ٱِنْطَوَى" form3="VRB" form4="VBP" form5="IV3MD+IV+IVSUFF_SUBJ:D_MOOD:I"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ينطويان"/>
                    </tokenized>
                </word>
                <word id="44" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="45" word="الكثير">
                    <svm_prediction>
                        <morph_feature_set diac="الكَثِيرَ" lemma="كَثِيرkaviyr" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8194995219647865">
                        <morph_feature_set diac="الكَثِيرِ" lemma="كَثِير_1" gloss="many;much;numerous" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="كَثِير"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الكثير"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="kvyr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الكثير" form1="الكثير" form2="كَثِير" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="كثير"/>
                    </tokenized>
                </word>
                <word id="46" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="47" word="المعاني">
                    <svm_prediction>
                        <morph_feature_set diac="المَعانِي" lemma="مَعْنَىmaEonaY" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943368191769413">
                        <morph_feature_set diac="المَعانِي" lemma="مَعْنَى_1" gloss="meanings;senses;concepts;nuances" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="مَعانِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المعاني"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mEAny" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المعاني" form1="المعاني" form2="مَعْنَى" form3="NOM" form4="DT+NN" form5="DET+NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="معاني"/>
                    </tokenized>
                </word>
                <word id="48" word="والدروس">
                    <svm_prediction>
                        <morph_feature_set diac="وَالدُّرُوسِ" lemma="دَرْسdaros" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943362057940295">
                        <morph_feature_set diac="وَالدُّرُوسِ" lemma="دَرْس_1" gloss="lessons;classes" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="دُرُوس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الدروس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="drws" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الدروس" form1="الدروس" form2="دَرْس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="دروس"/>
                    </tokenized>
                </word>
                <word id="49" word="والعبر">
                    <svm_prediction>
                        <morph_feature_set diac="وَالعِبَرِ" lemma="عِبْرَةEiborap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943362057940295">
                        <morph_feature_set diac="وَالعِبَرِ" lemma="عِبْرَة_1" gloss="admonitions;lessons" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عِبَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="العبر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="Ebr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="العبر" form1="العبر" form2="عِبْرَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="عبر"/>
                    </tokenized>
                </word>
                <word id="50" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="51" word="وان">
                    <svm_prediction>
                        <morph_feature_set diac="وَأَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.81393677270044">
                        <morph_feature_set diac="وَأَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                </word>
                <word id="52" word="كنا">
                    <svm_prediction>
                        <morph_feature_set diac="كُنّا" lemma="كانkAn" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939586845549484">
                        <morph_feature_set diac="كُنّا" lemma="كان_1" gloss="was;were" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="كُن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كنا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="knA" form1="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كنا" form1="كنا" form2="كان" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كنا"/>
                    </tokenized>
                </word>
                <word id="53" word="لا">
                    <svm_prediction>
                        <morph_feature_set diac="لا" lemma="لاlA" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="لا" lemma="لا_1" gloss="no;not" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="lA" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="لا" form1="لا" form2="لا" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                </word>
                <word id="54" word="نستطيع">
                    <svm_prediction>
                        <morph_feature_set diac="نَسْتَطِيع" lemma="ٱِسْتَطاع{isotaTAE" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="نَسْتَطِيع" lemma="ٱِسْتَطاع_1" gloss="be_able;be_capable" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="u" gen="m" num="p" stt="na" cas="na" enc0="0" stem="سْتَطِيع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نستطيع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nstTyE" form1="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نستطيع" form1="نستطيع" form2="ٱِسْتَطاع" form3="VRB" form4="VBP" form5="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نستطيع"/>
                    </tokenized>
                </word>
                <word id="55" word="فصلهما">
                    <svm_prediction>
                        <morph_feature_set diac="فَصْلهما" lemma="فَصْلfaSol" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3d_dobj"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8630462627917533">
                        <morph_feature_set diac="فَصْلَهُما" lemma="فَصْل_1" gloss="discharge;dismissal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3d_poss" stem="فَصْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="فصل"/>
                        <tok id="1" form0="+هما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fSl" form1="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+hmA" form1="+POSS_PRON_3D"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="فصل" form1="فصل" form2="فَصْل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+هما" form1="+هما" form2="+هُما" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3D"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="فصل"/>
                        <tok id="1" form0="+هما"/>
                    </tokenized>
                </word>
                <word id="56" word="كليا">
                    <svm_prediction>
                        <morph_feature_set diac="كُلِّيّاً" lemma="كُلِّيّkul~iy~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8252162031675067">
                        <morph_feature_set diac="كُلِّيّاً" lemma="كُلِّيّ_1" gloss="total;complete;entire" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="كُلِّيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كليا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="klyA" form1="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كليا" form1="كليا" form2="كُلِّيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كليا"/>
                    </tokenized>
                </word>
                <word id="57" word="عن">
                    <svm_prediction>
                        <morph_feature_set diac="عَن" lemma="عَنEan" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَن" lemma="عَن_1" gloss="from;about" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="En" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عن" form1="عن" form2="عَن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عن"/>
                    </tokenized>
                </word>
                <word id="58" word="منطقتنا">
                    <svm_prediction>
                        <morph_feature_set diac="مِنْطَقَتِنا" lemma="مِنْطَقَةminoTaqap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="1p_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939132838679384">
                        <morph_feature_set diac="مِنْطَقَتِنا" lemma="مِنْطَقَة_1" gloss="area;zone;territory" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="1p_poss" stem="مِنْطَق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="منطقة"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mnTqp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="1" form0="+nA" form1="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="منطقة" form1="منطقة" form2="مِنْطَقَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="منطقة"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="59" word="العربية">
                    <svm_prediction>
                        <morph_feature_set diac="العَرَبِيَّةُ" lemma="عَرَبِيّEarabiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8862218760012581">
                        <morph_feature_set diac="العَرَبِيَّةِ" lemma="عَرَبِيّ_1" gloss="Arabic;Arab" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="عَرَبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العربية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Erbyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العربية" form1="العربية" form2="عَرَبِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عربية"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT3">
            <segment_info>
                <preprocessed>الأول</preprocessed>
                <bpc>
                    <chunk id="0" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اول"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="ال+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="اول"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="الأول">
                    <svm_prediction>
                        <morph_feature_set diac="الأَوَّلِ" lemma="أَوَّل&gt;aw~al" pos="adj_num" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8147391943739112">
                        <morph_feature_set diac="الأَوَّلُ" lemma="أَوَّل_2" gloss="first" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="أَوَّل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Awl" form1="ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأول" form1="الاول" form2="أَوَّل" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اول"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT4">
            <segment_info>
                <preprocessed>اعلان مكتب الرئيس النيجيري محمد بخاري ( منتخب ديمقراطيا ) , ان الرئيس طلب من البرلمان تمديد اجازته المرضية بعد ان قضى أسبوعين لاجراء فحوص طبية في بريطانيا , وذلك لاستكمال هذه الفحوص التي أوصى بها اطباؤه , وانتظار النتائج</preprocessed>
                <bpc>
                    <chunk id="0" type="NP">
                        <tok id="0" form0="اعلان"/>
                    </chunk>
                    <chunk id="1" type="NP">
                        <tok id="0" form0="مكتب"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="نيجيري"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="محمد"/>
                        <tok id="1" form0="بخاري"/>
                    </chunk>
                    <chunk id="4" type="">
                        <tok id="0" form0="-LRB-"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="منتخب"/>
                        <tok id="1" form0="ديمقراطيا"/>
                    </chunk>
                    <chunk id="6" type="">
                        <tok id="0" form0="-RRB-"/>
                    </chunk>
                    <chunk id="7" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="8" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                    </chunk>
                    <chunk id="10" type="VP">
                        <tok id="0" form0="طلب"/>
                    </chunk>
                    <chunk id="11" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="برلمان"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="تمديد"/>
                    </chunk>
                    <chunk id="14" type="NP">
                        <tok id="0" form0="اجازة"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="16" type="ADJP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مرضية"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="بعد"/>
                    </chunk>
                    <chunk id="18" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="19" type="VP">
                        <tok id="0" form0="قضي"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="اسبوعين"/>
                    </chunk>
                    <chunk id="21" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="22" type="NP">
                        <tok id="0" form0="اجراء"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="فحوص"/>
                        <tok id="1" form0="طبية"/>
                    </chunk>
                    <chunk id="24" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="بريطانيا"/>
                    </chunk>
                    <chunk id="26" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="27" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="ذلك"/>
                    </chunk>
                    <chunk id="29" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="استكمال"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="هذه"/>
                    </chunk>
                    <chunk id="32" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فحوص"/>
                    </chunk>
                    <chunk id="33" type="WHNP">
                        <tok id="0" form0="التي"/>
                    </chunk>
                    <chunk id="34" type="VP">
                        <tok id="0" form0="اوصي"/>
                    </chunk>
                    <chunk id="35" type="PP">
                        <tok id="0" form0="ب"/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="37" type="NP">
                        <tok id="0" form0="@@اطباؤه@@"/>
                    </chunk>
                    <chunk id="38" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="39" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="40" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="41" type="NP">
                        <tok id="0" form0="انتظار"/>
                    </chunk>
                    <chunk id="42" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نتائج"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="اعلان"/>
                    </ne>
                    <ne id="1" type="ORG">
                        <tok id="1" form0="مكتب"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ال+"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="رئيس"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="ال+"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="نيجيري"/>
                    </ne>
                    <ne id="6" type="PER">
                        <tok id="6" form0="محمد"/>
                        <tok id="6" form0="بخاري"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="-LRB-"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="منتخب"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="ديمقراطيا"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="-RRB-"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0=","/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="ان"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="ال+"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="رئيس"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="طلب"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="من"/>
                    </ne>
                    <ne id="17" type="PER">
                        <tok id="17" form0="ال+"/>
                        <tok id="17" form0="برلمان"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="تمديد"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="اجازة"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="+ه"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="ال+"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="مرضية"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="بعد"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="ان"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="قضي"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="اسبوعين"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ل+"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="اجراء"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="فحوص"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="طبية"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="في"/>
                    </ne>
                    <ne id="32" type="LOC">
                        <tok id="32" form0="بريطانيا"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0=","/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="و+"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="ذلك"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="ل+"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="استكمال"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="هذه"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="ال+"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="فحوص"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="التي"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="اوصي"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="ب"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="+ها"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="@@اطباؤه@@"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="+ه"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0=","/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="و+"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="انتظار"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="ال+"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="نتائج"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="اعلان">
                    <svm_prediction>
                        <morph_feature_set diac="إِعْلانِ" lemma="إِعْلان&lt;iEolAn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8147817981025236">
                        <morph_feature_set diac="إِعْلانُ" lemma="إِعْلان_1" gloss="declaration;statement;announcement" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="إِعْلان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اعلان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AElAn" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إعلان" form1="اعلان" form2="إِعْلان" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اعلان"/>
                    </tokenized>
                </word>
                <word id="1" word="مكتب">
                    <svm_prediction>
                        <morph_feature_set diac="مَكْتَبِ" lemma="مَكْتَبmakotab" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="مَكْتَبِ" lemma="مَكْتَب_1" gloss="bureau;office;department" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مَكْتَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مكتب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mktb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مكتب" form1="مكتب" form2="مَكْتَب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مكتب"/>
                    </tokenized>
                </word>
                <word id="2" word="الرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="الرَّئِيسُ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="الرَّئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="3" word="النيجيري">
                    <svm_prediction>
                        <morph_feature_set diac="النَّيْجِيرِيُّ" lemma="نَيْجِيرِيّnayojiyriy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="النَّيْجِيرِيِّ" lemma="نَيْجِيرِيّ_1" gloss="Nigerian" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="نَيْجِيرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="النيجيري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="nyjyry" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="النيجيري" form1="النيجيري" form2="نَيْجِيرِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نيجيري"/>
                    </tokenized>
                </word>
                <word id="4" word="محمد">
                    <svm_prediction>
                        <morph_feature_set diac="مُحَمَّد" lemma="مُحَمَّدmuHam~ad" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مُحَمَّد" lemma="مُحَمَّد_1" gloss="Muhammad;Mohamed" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="مُحَمَّد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="محمد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mHmd" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="محمد" form1="محمد" form2="مُحَمَّد" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="محمد"/>
                    </tokenized>
                </word>
                <word id="5" word="بخاري">
                    <svm_prediction>
                        <morph_feature_set diac="بُخارِيّ" lemma="بُخارِيّbuxAriy~" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8998215129572901">
                        <morph_feature_set diac="بُخارِيّ" lemma="بُخارِيّ_1" gloss="Bukhari" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="بُخارِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بخاري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bxAry" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بخاري" form1="بخاري" form2="بُخارِيّ" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بخاري"/>
                    </tokenized>
                </word>
                <word id="6" word="(">
                    <svm_prediction>
                        <morph_feature_set diac="(" lemma="((" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="(" lemma="(_0" gloss="(" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="-LRB-"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="-LRB-" form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="-LRB-" form1="-LRB-" form2="-LRB-" form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="-LRB-"/>
                    </tokenized>
                </word>
                <word id="7" word="منتخب">
                    <svm_prediction>
                        <morph_feature_set diac="مُنْتَخَبِ" lemma="مُنْتَخَبmunotaxab" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8845614767239923">
                        <morph_feature_set diac="مُنْتَخَبُ" lemma="مُنْتَخَب_1" gloss="elected_candidate;elect" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="مُنْتَخَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="منتخب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mntxb" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="منتخب" form1="منتخب" form2="مُنْتَخَب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="منتخب"/>
                    </tokenized>
                </word>
                <word id="8" word="ديمقراطيا">
                    <svm_prediction>
                        <morph_feature_set diac="دِيمُقراطِيّاً" lemma="دِيمُوقراطِيّdiymuwqrATiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946349927825878">
                        <morph_feature_set diac="دِيمُقراطِيّاً" lemma="دِيمُوقراطِيّ_1" gloss="democratic" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="دِيمُقراطِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ديمقراطيا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dymqrATyA" form1="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ديمقراطيا" form1="ديمقراطيا" form2="دِيمُوقراطِيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ديمقراطيا"/>
                    </tokenized>
                </word>
                <word id="9" word=")">
                    <svm_prediction>
                        <morph_feature_set diac=")" lemma="))" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac=")" lemma=")_0" gloss=")" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="-RRB-"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="-RRB-" form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="-RRB-" form1="-RRB-" form2="-RRB-" form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="-RRB-"/>
                    </tokenized>
                </word>
                <word id="10" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="11" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7060057254085116">
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ_1" gloss="that" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="12" word="الرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="الرَّئِيسَ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895212316960791">
                        <morph_feature_set diac="الرَّئِيسَ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="r}ys" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="13" word="طلب">
                    <svm_prediction>
                        <morph_feature_set diac="طَلَبَ" lemma="طَلَبTalab" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="طَلَبَ" lemma="طَلَب-ُ_1" gloss="request" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="طَلَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="طلب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Tlb" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="طلب" form1="طلب" form2="طَلَب" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="طلب"/>
                    </tokenized>
                </word>
                <word id="14" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="15" word="البرلمان">
                    <svm_prediction>
                        <morph_feature_set diac="البَرْلَمانِ" lemma="بَرْلَمانbarolamAn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="البَرْلَمانِ" lemma="بَرْلَمان_1" gloss="parliament" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="بَرْلَمان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="البرلمان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="brlmAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="البرلمان" form1="البرلمان" form2="بَرْلَمان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="برلمان"/>
                    </tokenized>
                </word>
                <word id="16" word="تمديد">
                    <svm_prediction>
                        <morph_feature_set diac="تَمْدِيدِ" lemma="تَمْدِيدtamodiyd" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="تَمْدِيدِ" lemma="تَمْدِيد_1" gloss="extension;prolongation;lengthening" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="تَمْدِيد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تمديد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tmdyd" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تمديد" form1="تمديد" form2="تَمْدِيد" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تمديد"/>
                    </tokenized>
                </word>
                <word id="17" word="اجازته">
                    <svm_prediction>
                        <morph_feature_set diac="إِجازَتَهُ" lemma="إِجازَة&lt;ijAzap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8241691896262313">
                        <morph_feature_set diac="إِجازَتَهُ" lemma="إِجازَة_1" gloss="furlough;permit" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="3ms_poss" stem="إِجاز"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اجازة"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AjAzp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إجازة" form1="اجازة" form2="إِجازَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اجازة"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="18" word="المرضية">
                    <svm_prediction>
                        <morph_feature_set diac="المَرَضِيَّةُ" lemma="مُرْضِيmuroDiy" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8700831998299086">
                        <morph_feature_set diac="المَرَضِيَّةِ" lemma="مَرَضِيّ_1" gloss="diseased;sick;pathological" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مَرَضِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المرضية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mrDyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المرضية" form1="المرضية" form2="مَرَضِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مرضية"/>
                    </tokenized>
                </word>
                <word id="19" word="بعد">
                    <svm_prediction>
                        <morph_feature_set diac="بَعْدَ" lemma="بَعْدbaEod" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8705370026304016">
                        <morph_feature_set diac="بُعْدَ" lemma="بُعْد_1" gloss="dimension;distance" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="بُعْد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بعد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bEd" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بعد" form1="بعد" form2="بُعْد" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بعد"/>
                    </tokenized>
                </word>
                <word id="20" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="إِنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8155640401058297">
                        <morph_feature_set diac="أَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="21" word="قضى">
                    <svm_prediction>
                        <morph_feature_set diac="قَضَى" lemma="قَضَىqaDaY" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="قَضَى" lemma="قَضَى-ِ_1" gloss="execute;perform;decree" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="قَضَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قضي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qDy" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قضى" form1="قضي" form2="قَضَى" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قضي"/>
                    </tokenized>
                </word>
                <word id="22" word="أسبوعين">
                    <svm_prediction>
                        <morph_feature_set diac="أُسْبُوعَيْنِ" lemma="أُسْبُوع&gt;usobuwE" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939171695363182">
                        <morph_feature_set diac="أُسْبُوعَيْنِ" lemma="أُسْبُوع_1" gloss="week" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="i" cas="a" enc0="0" stem="أُسْبُوع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اسبوعين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AsbwEyn" form1="NOUN+NSUFF_MASC_DU_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أسبوعين" form1="اسبوعين" form2="أُسْبُوع" form3="NOM" form4="NNS" form5="NOUN+NSUFF_MASC_DU_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اسبوعين"/>
                    </tokenized>
                </word>
                <word id="23" word="لاجراء">
                    <svm_prediction>
                        <morph_feature_set diac="لِإِجْراءِ" lemma="إِجْراء&lt;ijorA'" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8246381262094312">
                        <morph_feature_set diac="لِإِجْراءِ" lemma="إِجْراء_1" gloss="conducting;undertaking;carrying_out" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="إِجْراء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="اجراء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="AjrA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="إجراء" form1="اجراء" form2="إِجْراء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="اجراء"/>
                    </tokenized>
                </word>
                <word id="24" word="فحوص">
                    <svm_prediction>
                        <morph_feature_set diac="فُحُوصٍ" lemma="فَحْصfaHoS" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895576339810859">
                        <morph_feature_set diac="فُحُوصٍ" lemma="فَحْص_1" gloss="examinations;checkups;scrutiny" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="فُحُوص"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="فحوص"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fHwS" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="فحوص" form1="فحوص" form2="فَحْص" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="فحوص"/>
                    </tokenized>
                </word>
                <word id="25" word="طبية">
                    <svm_prediction>
                        <morph_feature_set diac="طِبِّيَّةٌ" lemma="طِبِّيّTib~iy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8843514487627575">
                        <morph_feature_set diac="طِبِّيَّةٍ" lemma="طِبِّيّ_1" gloss="medical" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="طِبِّيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="طبية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Tbyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="طبية" form1="طبية" form2="طِبِّيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="طبية"/>
                    </tokenized>
                </word>
                <word id="26" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="27" word="بريطانيا">
                    <svm_prediction>
                        <morph_feature_set diac="برِيطانِيا" lemma="برِيطانِياbriyTAniyA" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8998215129572901">
                        <morph_feature_set diac="برِيطانِيا" lemma="برِيطانِيا_1" gloss="Britain" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="برِيطانِيا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بريطانيا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bryTAnyA" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بريطانيا" form1="بريطانيا" form2="برِيطانِيا" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بريطانيا"/>
                    </tokenized>
                </word>
                <word id="28" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="29" word="وذلك">
                    <svm_prediction>
                        <morph_feature_set diac="وَذٰلِكَ" lemma="ذٰلِكَ*`lika" pos="pron_dem" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939697280217194">
                        <morph_feature_set diac="وَذٰلِكَ" lemma="ذٰلِكَ_1" gloss="that" pos="pron_dem" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ذٰلِكَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ذلك"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="*lk" form1="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="ذلك" form1="ذلك" form2="ذٰلِكَ" form3="NOM" form4="DEM" form5="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ذلك"/>
                    </tokenized>
                </word>
                <word id="30" word="لاستكمال">
                    <svm_prediction>
                        <morph_feature_set diac="لِاِسْتِكْمالِ" lemma="ٱِسْتِكْمال{isotikomAl" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944178048308999">
                        <morph_feature_set diac="لِاِسْتِكْمالِ" lemma="ٱِسْتِكْمال_1" gloss="conclusion;termination" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِسْتِكْمال"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="استكمال"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="AstkmAl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="استكمال" form1="استكمال" form2="ٱِسْتِكْمال" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="استكمال"/>
                    </tokenized>
                </word>
                <word id="31" word="هذه">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذا_1" gloss="this;these" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="هٰذِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*h" form1="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذه" form1="هذه" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                </word>
                <word id="32" word="الفحوص">
                    <svm_prediction>
                        <morph_feature_set diac="الفُحُوصَ" lemma="فَحْصfaHoS" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="الفُحُوصِ" lemma="فَحْص_1" gloss="examinations;checkups;scrutiny" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="فُحُوص"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الفحوص"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="fHwS" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الفحوص" form1="الفحوص" form2="فَحْص" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فحوص"/>
                    </tokenized>
                </word>
                <word id="33" word="التي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8945079933398044">
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِي_1" gloss="which;who;whom_[fem.sg.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="الَّتِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alty" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التي" form1="التي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                </word>
                <word id="34" word="أوصى">
                    <svm_prediction>
                        <morph_feature_set diac="أَوْصَى" lemma="أَوْصَى&gt;awoSaY" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="أَوْصَى" lemma="أَوْصَى_1" gloss="recommend;advise;prescribe" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="أَوْصَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اوصي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AwSy" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أوصى" form1="اوصي" form2="أَوْصَى" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اوصي"/>
                    </tokenized>
                </word>
                <word id="35" word="بها">
                    <svm_prediction>
                        <morph_feature_set diac="بِها" lemma="بِbi" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="بِها" lemma="بِ_1" gloss="with;by_+_it;them;her" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="بِها"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b" form1="PREP"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب" form1="ب" form2="بِ" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="36" word="اطباؤه">
                    <svm_prediction>
                        <morph_feature_set diac="أَطِبّاؤِهِ" lemma="طَبِيبTabiyb" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8139032334821976">
                        <morph_feature_set diac="أَطِبّاؤُهُ" lemma="طَبِيب_1" gloss="physicians;doctors" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3ms_poss" stem="أَطِبّاؤ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="@@اطباؤه@@"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="@@ATbA&amp;h@@" form1="NOUN+CASE_DEF_NOM"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="@@أطباؤه@@" form1="@@اطباؤه@@" form2="طَبِيب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="@@اطباؤه@@"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="37" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="38" word="وانتظار">
                    <svm_prediction>
                        <morph_feature_set diac="وَاِنْتِظارٌ" lemma="ٱِنْتِظار{inotiZAr" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8837313803605074">
                        <morph_feature_set diac="وَاِنْتِظارُ" lemma="ٱِنْتِظار_1" gloss="waiting;anticipating" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="ٱِنْتِظار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="انتظار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AntZAr" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="انتظار" form1="انتظار" form2="ٱِنْتِظار" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="انتظار"/>
                    </tokenized>
                </word>
                <word id="39" word="النتائج">
                    <svm_prediction>
                        <morph_feature_set diac="النَّتائِجُ" lemma="نَتِيجَةnatiyjap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950630275921179">
                        <morph_feature_set diac="النَّتائِجُ" lemma="نَتِيجَة_1" gloss="results;consequences" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="نَتائِج"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="النتائج"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="ntA}j" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="النتائج" form1="النتائج" form2="نَتِيجَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نتائج"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT5">
            <segment_info>
                <preprocessed>الثاني</preprocessed>
                <bpc>
                    <chunk id="0" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ثاني"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="ال+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="ثاني"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="الثاني">
                    <svm_prediction>
                        <morph_feature_set diac="الثّانِي" lemma="ثانِيvAniy" pos="adj_num" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8253141617129782">
                        <morph_feature_set diac="الثّانِي" lemma="ثانِي_2" gloss="Second" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="ثانِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الثاني"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="vAny" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الثاني" form1="الثاني" form2="ثانِي" form3="PROP" form4="DT+NNP" form5="DET+NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ثاني"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT6">
            <segment_info>
                <preprocessed>اصدار محكمة أمريكية في ساعة متأخرة من مساء السبت حكما قضائيا برفض الطلب الذي تقدمت به إدارة الرئيس دونالد ترامب , وإعادة العمل على الفور بقانون حظر دول مهاجري سبع دول إسلامية , موجهة صفعة ثانية للرئيس الأمريكي وادارته العنصرية في اقل من 24 ساعة</preprocessed>
                <bpc>
                    <chunk id="0" type="NP">
                        <tok id="0" form0="اصدار"/>
                    </chunk>
                    <chunk id="1" type="NP">
                        <tok id="0" form0="محكمة"/>
                        <tok id="1" form0="امريكية"/>
                    </chunk>
                    <chunk id="2" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="ساعة"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="متاخرة"/>
                    </chunk>
                    <chunk id="5" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="مساء"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سبت"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="حكما"/>
                        <tok id="1" form0="قضائيا"/>
                    </chunk>
                    <chunk id="9" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="رفض"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="طلب"/>
                    </chunk>
                    <chunk id="12" type="WHNP">
                        <tok id="0" form0="الذي"/>
                    </chunk>
                    <chunk id="13" type="VP">
                        <tok id="0" form0="تقدمت"/>
                    </chunk>
                    <chunk id="14" type="PP">
                        <tok id="0" form0="ب"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="ادارة"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="دونالد"/>
                        <tok id="1" form0="ترامب"/>
                    </chunk>
                    <chunk id="19" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="20" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="21" type="NP">
                        <tok id="0" form0="اعادة"/>
                    </chunk>
                    <chunk id="22" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عمل"/>
                    </chunk>
                    <chunk id="23" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="24" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فور"/>
                    </chunk>
                    <chunk id="25" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="قانون"/>
                    </chunk>
                    <chunk id="27" type="NP">
                        <tok id="0" form0="حظر"/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="دول"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="مهاجري"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="سبع"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="دول"/>
                        <tok id="1" form0="اسلامية"/>
                    </chunk>
                    <chunk id="32" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="33" type="ADJP">
                        <tok id="0" form0="موجهة"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="صفعة"/>
                        <tok id="1" form0="ثانية"/>
                    </chunk>
                    <chunk id="35" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="امريكي"/>
                    </chunk>
                    <chunk id="37" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="38" type="NP">
                        <tok id="0" form0="ادارة"/>
                    </chunk>
                    <chunk id="39" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="40" type="ADJP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عنصرية"/>
                    </chunk>
                    <chunk id="41" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="42" type="NP">
                        <tok id="0" form0="اقل"/>
                    </chunk>
                    <chunk id="43" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="44" type="NP">
                        <tok id="0" form0="24"/>
                    </chunk>
                    <chunk id="45" type="NP">
                        <tok id="0" form0="ساعة"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="اصدار"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="محكمة"/>
                    </ne>
                    <ne id="2" type="LOC">
                        <tok id="2" form0="امريكية"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="في"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="ساعة"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="متاخرة"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="من"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="مساء"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="ال+"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="سبت"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="حكما"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="قضائيا"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="ب+"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="رفض"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="ال+"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="طلب"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="الذي"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="تقدمت"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="ب"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="+ه"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ادارة"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="ال+"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="رئيس"/>
                    </ne>
                    <ne id="23" type="PER">
                        <tok id="23" form0="دونالد"/>
                        <tok id="23" form0="ترامب"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0=","/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="و+"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="اعادة"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ال+"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="عمل"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="علي"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="ال+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="فور"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="ب+"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="قانون"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="حظر"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="دول"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="مهاجري"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="سبع"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="دول"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="اسلامية"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0=","/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="موجهة"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="صفعة"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="ثانية"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="ل+"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="ال+"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="رئيس"/>
                    </ne>
                    <ne id="47" type="LOC">
                        <tok id="47" form0="ال+"/>
                        <tok id="47" form0="امريكي"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="و+"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="ادارة"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="+ه"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="ال+"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="عنصرية"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="في"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="اقل"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="من"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="24"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="ساعة"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="اصدار">
                    <svm_prediction>
                        <morph_feature_set diac="إِصْدارِ" lemma="إِصْدار&lt;iSodAr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8147817981025236">
                        <morph_feature_set diac="إِصْدارُ" lemma="إِصْدار_1" gloss="export;issuance" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="إِصْدار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اصدار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ASdAr" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إصدار" form1="اصدار" form2="إِصْدار" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اصدار"/>
                    </tokenized>
                </word>
                <word id="1" word="محكمة">
                    <svm_prediction>
                        <morph_feature_set diac="مَحْكَمَةُ" lemma="مَحْكَمَةmaHokamap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8837559213663835">
                        <morph_feature_set diac="مَحْكَمَةٌ" lemma="مَحْكَمَة_1" gloss="court;tribunal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="مَحْكَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="محكمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mHkmp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="محكمة" form1="محكمة" form2="مَحْكَمَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="محكمة"/>
                    </tokenized>
                </word>
                <word id="2" word="أمريكية">
                    <svm_prediction>
                        <morph_feature_set diac="أَمْرِيكِيَّةٌ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8843514487627575">
                        <morph_feature_set diac="أَمْرِيكِيَّةٍ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="امريكية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Amrykyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أمريكية" form1="امريكية" form2="أَمْرِيكِيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="امريكية"/>
                    </tokenized>
                </word>
                <word id="3" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="4" word="ساعة">
                    <svm_prediction>
                        <morph_feature_set diac="ساعَةٍ" lemma="ساعَةsAEap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944955176978556">
                        <morph_feature_set diac="ساعَةٍ" lemma="ساعَة_1" gloss="hour;time" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="ساع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ساعة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sAEp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ساعة" form1="ساعة" form2="ساعَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ساعة"/>
                    </tokenized>
                </word>
                <word id="5" word="متأخرة">
                    <svm_prediction>
                        <morph_feature_set diac="مُتَأَخِّرَةٍ" lemma="مُتَأَخِّرmuta&gt;ax~ir" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8250767280827742">
                        <morph_feature_set diac="مُتَأَخِّرَةٍ" lemma="مُتَأَخِّر_1" gloss="late;delayed" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="مُتَأَخِّر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="متاخرة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mtAxrp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="متأخرة" form1="متاخرة" form2="مُتَأَخِّر" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="متاخرة"/>
                    </tokenized>
                </word>
                <word id="6" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="7" word="مساء">
                    <svm_prediction>
                        <morph_feature_set diac="مَساءَ" lemma="مَساءmasA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8969741517107328">
                        <morph_feature_set diac="مَساءَ" lemma="مَساء_1" gloss="evening" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="مَساء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مساء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="msA'" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مساء" form1="مساء" form2="مَساء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مساء"/>
                    </tokenized>
                </word>
                <word id="8" word="السبت">
                    <svm_prediction>
                        <morph_feature_set diac="السَّبْتِ" lemma="سَبْتsabot" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8727796354085182">
                        <morph_feature_set diac="السَّبَتِ" lemma="سَبَت_1" gloss="basket" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="سَبَت"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السبت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="sbt" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السبت" form1="السبت" form2="سَبَت" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سبت"/>
                    </tokenized>
                </word>
                <word id="9" word="حكما">
                    <svm_prediction>
                        <morph_feature_set diac="حُكْماً" lemma="حُكْمHukom" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8951072017397583">
                        <morph_feature_set diac="حُكْماً" lemma="حُكْم_1" gloss="judgment;decision" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="حُكْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حكما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="HkmA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حكما" form1="حكما" form2="حُكْم" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حكما"/>
                    </tokenized>
                </word>
                <word id="10" word="قضائيا">
                    <svm_prediction>
                        <morph_feature_set diac="قَضائِيّاً" lemma="قَضائِيّqaDA}iy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946349927825878">
                        <morph_feature_set diac="قَضائِيّاً" lemma="قَضائِيّ_1" gloss="judicial;legal" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="قَضائِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قضائيا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qDA}yA" form1="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قضائيا" form1="قضائيا" form2="قَضائِيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قضائيا"/>
                    </tokenized>
                </word>
                <word id="11" word="برفض">
                    <svm_prediction>
                        <morph_feature_set diac="بِرَفْضِ" lemma="رَفْضrafoD" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِرَفْضِ" lemma="رَفْض_1" gloss="rejection;refusal" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="رَفْض"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="رفض"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="rfD" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="رفض" form1="رفض" form2="رَفْض" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="رفض"/>
                    </tokenized>
                </word>
                <word id="12" word="الطلب">
                    <svm_prediction>
                        <morph_feature_set diac="الطَّلَبِ" lemma="طَلَبTalab" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الطَّلَبِ" lemma="طَلَب_1" gloss="quest;search" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="طَلَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الطلب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Tlb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الطلب" form1="الطلب" form2="طَلَب" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="طلب"/>
                    </tokenized>
                </word>
                <word id="13" word="الذي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِي_1" gloss="which;who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="الَّذِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*y" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذي" form1="الذي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                </word>
                <word id="14" word="تقدمت">
                    <svm_prediction>
                        <morph_feature_set diac="تَقَدَّمَت" lemma="تَقَدَّمtaqad~am" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8948497252865323">
                        <morph_feature_set diac="تَقَدَّمَت" lemma="تَقَدَّم_1" gloss="present;advance" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0" stem="تَقَدَّم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تقدمت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tqdmt" form1="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تقدمت" form1="تقدمت" form2="تَقَدَّم" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تقدمت"/>
                    </tokenized>
                </word>
                <word id="15" word="به">
                    <svm_prediction>
                        <morph_feature_set diac="بِهِ" lemma="بِbi" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3ms_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="بِهِ" lemma="بِ_1" gloss="with;by_+_it;him" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3ms_pron" stem="بِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b" form1="PREP"/>
                        <tok id="1" form0="+h" form1="+PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب" form1="ب" form2="بِ" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP" form5="+PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="16" word="إدارة">
                    <svm_prediction>
                        <morph_feature_set diac="إِدارَةَ" lemma="إِدارَة&lt;idArap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839569522780454">
                        <morph_feature_set diac="إِدارَةُ" lemma="إِدارَة_1" gloss="administration;management;bureau" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="n" enc0="0" stem="إِدار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ادارة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AdArp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إدارة" form1="ادارة" form2="إِدارَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ادارة"/>
                    </tokenized>
                </word>
                <word id="17" word="الرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="الرَّئِيسِ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الرَّئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="18" word="دونالد">
                    <svm_prediction>
                        <morph_feature_set diac="دُونالد" lemma="دُونالدduwnAld" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="دُونالد" lemma="دُونالد_1" gloss="Donald" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="دُونالد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دونالد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dwnAld" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دونالد" form1="دونالد" form2="دُونالد" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دونالد"/>
                    </tokenized>
                </word>
                <word id="19" word="ترامب">
                    <svm_prediction>
                        <morph_feature_set diac="ترامب" lemma="ترامبtrAmb" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="na" cas="na" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ترامب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="trAmb" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ترامب" form1="ترامب" form2="ترامب" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ترامب"/>
                    </tokenized>
                </word>
                <word id="20" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="21" word="وإعادة">
                    <svm_prediction>
                        <morph_feature_set diac="وَإِعادَةِ" lemma="أَعاد&gt;aEAd" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8674986306234509">
                        <morph_feature_set diac="وَإِعادَةُ" lemma="إِعادَة_1" gloss="return;repetition;re-(doing)" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="n" enc0="0" stem="إِعاد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اعادة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AEAdp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="إعادة" form1="اعادة" form2="إِعادَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اعادة"/>
                    </tokenized>
                </word>
                <word id="22" word="العمل">
                    <svm_prediction>
                        <morph_feature_set diac="العَمَلِ" lemma="عَمَلEamal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="العَمَلِ" lemma="عَمَل_1" gloss="work;action" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عَمَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العمل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Eml" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العمل" form1="العمل" form2="عَمَل" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عمل"/>
                    </tokenized>
                </word>
                <word id="23" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="24" word="الفور">
                    <svm_prediction>
                        <morph_feature_set diac="الفَوْرِ" lemma="فَوْرfawor" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الفَوْرِ" lemma="فَوْر_1" gloss="immediately;at_once" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="فَوْر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الفور"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="fwr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الفور" form1="الفور" form2="فَوْر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فور"/>
                    </tokenized>
                </word>
                <word id="25" word="بقانون">
                    <svm_prediction>
                        <morph_feature_set diac="بِقانُونِ" lemma="قانُونqAnuwn" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِقانُونِ" lemma="قانُون_1" gloss="law;statutes;regulations" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قانُون"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="قانون"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="qAnwn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="قانون" form1="قانون" form2="قانُون" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="قانون"/>
                    </tokenized>
                </word>
                <word id="26" word="حظر">
                    <svm_prediction>
                        <morph_feature_set diac="حَظْرِ" lemma="حَظْرHaZor" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="حَظْرِ" lemma="حَظْر_1" gloss="prohibition;ban" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="حَظْر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حظر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="HZr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حظر" form1="حظر" form2="حَظْر" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حظر"/>
                    </tokenized>
                </word>
                <word id="27" word="دول">
                    <svm_prediction>
                        <morph_feature_set diac="دُوَلِ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="دُوَلِ" lemma="دَوْلَة_1" gloss="states;countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="دُوَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dwl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دول" form1="دول" form2="دَوْلَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دول"/>
                    </tokenized>
                </word>
                <word id="28" word="مهاجري">
                    <svm_prediction>
                        <morph_feature_set diac="مُهاجِرِي" lemma="مَهْجَرmahojar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.867485746652639">
                        <morph_feature_set diac="مُهاجِرَيْ" lemma="مُهاجِر_1" gloss="emigrant" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="c" cas="g" enc0="0" stem="مُهاجِر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مهاجري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mhAjry" form1="NOUN+NSUFF_MASC_DU_GEN_POSS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مهاجري" form1="مهاجري" form2="مُهاجِر" form3="NOM" form4="NNS" form5="NOUN+NSUFF_MASC_DU_GEN_POSS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مهاجري"/>
                    </tokenized>
                </word>
                <word id="29" word="سبع">
                    <svm_prediction>
                        <morph_feature_set diac="سَبْعِ" lemma="سَبْعsaboE" pos="noun_num" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8282762492480038">
                        <morph_feature_set diac="سَبْعِ" lemma="سَبْع_1" gloss="lion;predatory_beast" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="سَبْع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سبع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sbE" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سبع" form1="سبع" form2="سَبْع" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سبع"/>
                    </tokenized>
                </word>
                <word id="30" word="دول">
                    <svm_prediction>
                        <morph_feature_set diac="دُوَلٍ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895576339810859">
                        <morph_feature_set diac="دُوَلٍ" lemma="دَوْلَة_1" gloss="states;countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="دُوَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dwl" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دول" form1="دول" form2="دَوْلَة" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دول"/>
                    </tokenized>
                </word>
                <word id="31" word="إسلامية">
                    <svm_prediction>
                        <morph_feature_set diac="إِسْلامِيَّةٍ" lemma="إِسْلامِيّ&lt;isolAmiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946499216717394">
                        <morph_feature_set diac="إِسْلامِيَّةٍ" lemma="إِسْلامِيّ_1" gloss="Islamic;Islamist;Muslim" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="إِسْلامِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اسلامية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AslAmyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إسلامية" form1="اسلامية" form2="إِسْلامِيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اسلامية"/>
                    </tokenized>
                </word>
                <word id="32" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="33" word="موجهة">
                    <svm_prediction>
                        <morph_feature_set diac="مُوَجَّهَةً" lemma="مُوَجَّهmuwaj~ah" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8838763768027637">
                        <morph_feature_set diac="مُوَجَّهَةٌ" lemma="مُوَجَّه_1" gloss="directed;aimed" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="مُوَجَّه"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="موجهة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mwjhp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="موجهة" form1="موجهة" form2="مُوَجَّه" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="موجهة"/>
                    </tokenized>
                </word>
                <word id="34" word="صفعة">
                    <svm_prediction>
                        <morph_feature_set diac="صَفْعَةٌ" lemma="صَفْعَةSafoEap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940543942753655">
                        <morph_feature_set diac="صَفْعَةٌ" lemma="صَفْعَة_1" gloss="slap;blow" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="صَفْع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="صفعة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="SfEp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="صفعة" form1="صفعة" form2="صَفْعَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="صفعة"/>
                    </tokenized>
                </word>
                <word id="35" word="ثانية">
                    <svm_prediction>
                        <morph_feature_set diac="ثانِيَةً" lemma="ثانِيvAniy" pos="adj_num" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8144575871876825">
                        <morph_feature_set diac="ثانِيَةٌ" lemma="ثانِي_3" gloss="second;next" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="ثانِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ثانية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="vAnyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ثانية" form1="ثانية" form2="ثانِي" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ثانية"/>
                    </tokenized>
                </word>
                <word id="36" word="للرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="لِلرَّئِيسِ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944374375687777">
                        <morph_feature_set diac="لِلرَّئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="37" word="الأمريكي">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْرِيكِيِّ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="الأَمْرِيكِيِّ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامريكي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amryky" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمريكي" form1="الامريكي" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكي"/>
                    </tokenized>
                </word>
                <word id="38" word="وادارته">
                    <svm_prediction>
                        <morph_feature_set diac="وَإِدارَتَهُ" lemma="إِدارَة&lt;idArap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8138406540772399">
                        <morph_feature_set diac="وَإِدارَتِهِ" lemma="إِدارَة_1" gloss="administration;management;bureau" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss" stem="إِدار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ادارة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AdArp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="إدارة" form1="ادارة" form2="إِدارَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ادارة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="39" word="العنصرية">
                    <svm_prediction>
                        <morph_feature_set diac="العُنْصُرِيَّةِ" lemma="عُنْصُرِيّEunoSuriy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="العُنْصُرِيَّةِ" lemma="عُنْصُرِيّ_1" gloss="racial;ethnic" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="عُنْصُرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العنصرية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EnSryp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العنصرية" form1="العنصرية" form2="عُنْصُرِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عنصرية"/>
                    </tokenized>
                </word>
                <word id="40" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="41" word="اقل">
                    <svm_prediction>
                        <morph_feature_set diac="أَقَلِّ" lemma="أَقَلّ&gt;aqal~" pos="adj_comp" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7584965706265352">
                        <morph_feature_set diac="أَقَلِّ" lemma="أَقَلّ_2" gloss="less;least;smaller;smallest;minimum" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="أَقَلّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اقل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aql" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أقل" form1="اقل" form2="أَقَلّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اقل"/>
                    </tokenized>
                </word>
                <word id="42" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="43" word="24">
                    <svm_prediction>
                        <morph_feature_set diac="88" lemma="8888" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="24" lemma="24_0" gloss="24" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="24"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="24" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="24" form1="24" form2="24" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="24"/>
                    </tokenized>
                </word>
                <word id="44" word="ساعة">
                    <svm_prediction>
                        <morph_feature_set diac="ساعَةً" lemma="ساعَةsAEap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943274124611241">
                        <morph_feature_set diac="ساعَةً" lemma="ساعَة_1" gloss="hour;time" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="a" enc0="0" stem="ساع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ساعة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sAEp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ساعة" form1="ساعة" form2="ساعَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ساعة"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT7">
            <segment_info>
                <preprocessed>ما يربط بين الحدثين من وجهة نظرنا هو عظمة قيم الديمقراطية وحقوق الانسان , وسيادة القانون , والفصل بين السلطات واحترام القضاء ومؤسسته التي يجب ان يتساوى امامها الجميع</preprocessed>
                <bpc>
                    <chunk id="0" type="WHNP">
                        <tok id="0" form0="ما"/>
                    </chunk>
                    <chunk id="1" type="VP">
                        <tok id="0" form0="يربط"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="بين"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حدثين"/>
                    </chunk>
                    <chunk id="4" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="وجهة"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="نظر"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="هو"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="عظمة"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="قيم"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ديمقراطية"/>
                    </chunk>
                    <chunk id="12" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="حقوق"/>
                    </chunk>
                    <chunk id="14" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="انسان"/>
                    </chunk>
                    <chunk id="15" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="16" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="سيادة"/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قانون"/>
                    </chunk>
                    <chunk id="19" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="20" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="21" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فصل"/>
                    </chunk>
                    <chunk id="22" type="NP">
                        <tok id="0" form0="بين"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سلطات"/>
                    </chunk>
                    <chunk id="24" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="احترام"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قضاء"/>
                    </chunk>
                    <chunk id="27" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="مؤسسة"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="30" type="WHNP">
                        <tok id="0" form0="التي"/>
                    </chunk>
                    <chunk id="31" type="VP">
                        <tok id="0" form0="يجب"/>
                    </chunk>
                    <chunk id="32" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="33" type="VP">
                        <tok id="0" form0="يتساوي"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="امام"/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جميع"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="ما"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="يربط"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="بين"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="ال+"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="حدثين"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="من"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="وجهة"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="نظر"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="+نا"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="هو"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="عظمة"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="قيم"/>
                    </ne>
                    <ne id="12" type="ORG">
                        <tok id="12" form0="ال+"/>
                        <tok id="12" form0="ديمقراطية"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="و+"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="حقوق"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="ال+"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="انسان"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0=","/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="و+"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="سيادة"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ال+"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="قانون"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0=","/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="و+"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="ال+"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="فصل"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="بين"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ال+"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="سلطات"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="و+"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="احترام"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="ال+"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="قضاء"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="و+"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="مؤسسة"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="+ه"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="التي"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="يجب"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="ان"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="يتساوي"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="امام"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="+ها"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="ال+"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="جميع"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="ما">
                    <svm_prediction>
                        <morph_feature_set diac="ما" lemma="ماmA" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="ما" lemma="ما_1" gloss="what" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ما"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mA" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ما" form1="ما" form2="ما" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                </word>
                <word id="1" word="يربط">
                    <svm_prediction>
                        <morph_feature_set diac="يَرْبِط" lemma="رَبَطrabaT" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="يَرْبِط" lemma="رَبَط-ُِ_1" gloss="tie;connect" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="رْبِط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يربط"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yrbT" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يربط" form1="يربط" form2="رَبَط" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يربط"/>
                    </tokenized>
                </word>
                <word id="2" word="بين">
                    <svm_prediction>
                        <morph_feature_set diac="بَيْنَ" lemma="بَيْنَbayona" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8705370026304016">
                        <morph_feature_set diac="بَيِّنَ" lemma="بَيِّن_1" gloss="clear;evident;explicit" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="بَيِّن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="byn" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بين" form1="بين" form2="بَيِّن" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بين"/>
                    </tokenized>
                </word>
                <word id="3" word="الحدثين">
                    <svm_prediction>
                        <morph_feature_set diac="الحَدَثَيْنِ" lemma="حَدَثHadav" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939781128322154">
                        <morph_feature_set diac="الحَدَثَيْنِ" lemma="حَدَث_1" gloss="incident;event" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="d" cas="g" enc0="0" stem="حَدَث"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الحدثين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Hdvyn" form1="NOUN+NSUFF_MASC_DU_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الحدثين" form1="الحدثين" form2="حَدَث" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_MASC_DU_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حدثين"/>
                    </tokenized>
                </word>
                <word id="4" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="5" word="وجهة">
                    <svm_prediction>
                        <morph_feature_set diac="وِجْهَةِ" lemma="وِجْهَةwijohap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="وِجْهَةِ" lemma="وِجْهَة_1" gloss="point_of_view;angle" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="وِجْه"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="وجهة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="wjhp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="وجهة" form1="وجهة" form2="وِجْهَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="وجهة"/>
                    </tokenized>
                </word>
                <word id="6" word="نظرنا">
                    <svm_prediction>
                        <morph_feature_set diac="نَظَرِنا" lemma="نَظَرnaZar" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939458006110683">
                        <morph_feature_set diac="نَظَرِنا" lemma="نَظَر_1" gloss="view;look;seeing" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss" stem="نَظَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نظر"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nZr" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+nA" form1="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نظر" form1="نظر" form2="نَظَر" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نظر"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="7" word="هو">
                    <svm_prediction>
                        <morph_feature_set diac="هُوَ" lemma="هُوَhuwa" pos="pron" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940263767879477">
                        <morph_feature_set diac="هُوَ" lemma="هُوَ_1" gloss="it;he" pos="pron" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="هُوَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هو"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="hw" form1="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هو" form1="هو" form2="هُوَ" form3="NOM" form4="PRP" form5="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هو"/>
                    </tokenized>
                </word>
                <word id="8" word="عظمة">
                    <svm_prediction>
                        <morph_feature_set diac="عَظْمَةِ" lemma="عَظْمEaZom" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8791137251869433">
                        <morph_feature_set diac="عَظْمَةِ" lemma="عَظْمَة_1" gloss="piece_of_bone" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="عَظْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عظمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EZmp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عظمة" form1="عظمة" form2="عَظْمَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عظمة"/>
                    </tokenized>
                </word>
                <word id="9" word="قيم">
                    <svm_prediction>
                        <morph_feature_set diac="قِيَمِ" lemma="قِيمَةqiymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="قِيَمِ" lemma="قِيمَة_1" gloss="values;morals;ethics" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قِيَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قيم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qym" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قيم" form1="قيم" form2="قِيمَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قيم"/>
                    </tokenized>
                </word>
                <word id="10" word="الديمقراطية">
                    <svm_prediction>
                        <morph_feature_set diac="الدِّيمُقراطِيَّةِ" lemma="دِيمُوقراطِيّdiymuwqrATiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="الدِّيمُقراطِيَّةِ" lemma="دِيمُوقراطِيّ_1" gloss="democratic" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="دِيمُقراطِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الديمقراطية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dymqrATyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الديمقراطية" form1="الديمقراطية" form2="دِيمُوقراطِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ديمقراطية"/>
                    </tokenized>
                </word>
                <word id="11" word="وحقوق">
                    <svm_prediction>
                        <morph_feature_set diac="وَحُقُوقِ" lemma="حَقّHaq~" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942026627925052">
                        <morph_feature_set diac="وَحُقُوقِ" lemma="حَقّ_2" gloss="rights;law" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="حُقُوق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="حقوق"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Hqwq" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="حقوق" form1="حقوق" form2="حَقّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="حقوق"/>
                    </tokenized>
                </word>
                <word id="12" word="الانسان">
                    <svm_prediction>
                        <morph_feature_set diac="الإِنْسانِ" lemma="إِنْسان&lt;inosAn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8294371058673811">
                        <morph_feature_set diac="الإِنْسانِ" lemma="إِنْسان_1" gloss="human_being" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="إِنْسان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الانسان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AnsAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الإنسان" form1="الانسان" form2="إِنْسان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="انسان"/>
                    </tokenized>
                </word>
                <word id="13" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="14" word="وسيادة">
                    <svm_prediction>
                        <morph_feature_set diac="وَسِيادَةِ" lemma="سِيادَةsiyAdap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939877247273975">
                        <morph_feature_set diac="وَسِيادَةِ" lemma="سِيادَة_1" gloss="sovereignty;supremacy;Excellency" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="سِياد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="سيادة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="syAdp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="سيادة" form1="سيادة" form2="سِيادَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="سيادة"/>
                    </tokenized>
                </word>
                <word id="15" word="القانون">
                    <svm_prediction>
                        <morph_feature_set diac="القانُونِ" lemma="قانُونqAnuwn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="القانُونِ" lemma="قانُون_1" gloss="law;statutes;regulations" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="قانُون"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القانون"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qAnwn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القانون" form1="القانون" form2="قانُون" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قانون"/>
                    </tokenized>
                </word>
                <word id="16" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="17" word="والفصل">
                    <svm_prediction>
                        <morph_feature_set diac="وَالفَصْلِ" lemma="فَصْلfaSol" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8837448779117538">
                        <morph_feature_set diac="وَالفَصْلُ" lemma="فَصْل_1" gloss="discharge;dismissal" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="فَصْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الفصل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="fSl" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الفصل" form1="الفصل" form2="فَصْل" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="فصل"/>
                    </tokenized>
                </word>
                <word id="18" word="بين">
                    <svm_prediction>
                        <morph_feature_set diac="بَيْنَ" lemma="بَيْنَbayona" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8705370026304016">
                        <morph_feature_set diac="بَيِّنَ" lemma="بَيِّن_1" gloss="clear;evident;explicit" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="بَيِّن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="byn" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بين" form1="بين" form2="بَيِّن" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بين"/>
                    </tokenized>
                </word>
                <word id="19" word="السلطات">
                    <svm_prediction>
                        <morph_feature_set diac="السُّلُطاتِ" lemma="سُلْطَةsuloTap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8947650584943242">
                        <morph_feature_set diac="السُّلُطاتِ" lemma="سُلْطَة_1" gloss="authorities" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0" stem="سُلُط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السلطات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="slTAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السلطات" form1="السلطات" form2="سُلْطَة" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سلطات"/>
                    </tokenized>
                </word>
                <word id="20" word="واحترام">
                    <svm_prediction>
                        <morph_feature_set diac="وَاِحْتِرامِ" lemma="ٱِحْتِرام{iHotirAm" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942026627925052">
                        <morph_feature_set diac="وَاِحْتِرامِ" lemma="ٱِحْتِرام_1" gloss="respect;honoring" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِحْتِرام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="احترام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AHtrAm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="احترام" form1="احترام" form2="ٱِحْتِرام" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="احترام"/>
                    </tokenized>
                </word>
                <word id="21" word="القضاء">
                    <svm_prediction>
                        <morph_feature_set diac="القَضاءِ" lemma="قَضاءqaDA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="القَضاءِ" lemma="قَضاء_1" gloss="justice;judiciary" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="قَضاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القضاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qDA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القضاء" form1="القضاء" form2="قَضاء" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قضاء"/>
                    </tokenized>
                </word>
                <word id="22" word="ومؤسسته">
                    <svm_prediction>
                        <morph_feature_set diac="وَمُؤَسَّسَتَهُ" lemma="مُؤَسَّسَةmu&amp;as~asap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836203326987088">
                        <morph_feature_set diac="وَمُؤَسَّسَتِهِ" lemma="مُؤَسَّسَة_1" gloss="institution;organization" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss" stem="مُؤَسَّس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مؤسسة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="m&amp;ssp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="مؤسسة" form1="مؤسسة" form2="مُؤَسَّسَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مؤسسة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="23" word="التي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8945079933398044">
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِي_1" gloss="which;who;whom_[fem.sg.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="الَّتِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alty" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التي" form1="التي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                </word>
                <word id="24" word="يجب">
                    <svm_prediction>
                        <morph_feature_set diac="يَجْب" lemma="وَجَبwajab" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يَجِب" lemma="وَجَب-ِ_1" gloss="be_necessary;be_incumbent" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="جِب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يجب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yjb" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يجب" form1="يجب" form2="وَجَب" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يجب"/>
                    </tokenized>
                </word>
                <word id="25" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8155640401058297">
                        <morph_feature_set diac="أَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="26" word="يتساوى">
                    <svm_prediction>
                        <morph_feature_set diac="يَتَساوَى" lemma="تَساوَىtasAwaY" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="يَتَساوَى" lemma="تَساوَى_1" gloss="be_balanced;be_equal" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="تَساوَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يتساوي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ytsAwy" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يتساوى" form1="يتساوي" form2="تَساوَى" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يتساوي"/>
                    </tokenized>
                </word>
                <word id="27" word="امامها">
                    <svm_prediction>
                        <morph_feature_set diac="أَمامَها" lemma="أَمام&gt;amAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3fs_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8242483341197162">
                        <morph_feature_set diac="أَمامَها" lemma="أَمام_1" gloss="front;forward" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3fs_poss" stem="أَمام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="امام"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AmAm" form1="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+hA" form1="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أمام" form1="امام" form2="أَمام" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="امام"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="28" word="الجميع">
                    <svm_prediction>
                        <morph_feature_set diac="الجَمِيعُ" lemma="جَمِيعjamiyE" pos="noun_quant" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8256442379770365">
                        <morph_feature_set diac="الجَمِيعُ" lemma="جَمِيع_1" gloss="all_of;every_one_of" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="جَمِيع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجميع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jmyE" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجميع" form1="الجميع" form2="جَمِيع" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جميع"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        
        <out_seg id="SENT8">
            <segment_info>
                <preprocessed>في بلادنا العربية , ومعظم الدول الإسلامية , تعتبر صحة الملك او رئيس الجمهورية من اسرار الامن القومي لا يجوز ان يعرفها احد , الا القلة القليلة المحيطة به , اما رحلاته الى الخارج , او الداخل لقضاء إجازة او للعلاج سيان , فهي مفتوحة , ولا سقف لها , وهو الذي يحدد بدايتها ونهايتها , ولا يستأذن أحدا , لان هذا القرار " سيادي " والاستئذان يرتقي الى مستوى الإهانة , ثم لمن يتقدم بالاذن , للبرلمان غير الموجود في معظم الدول , او لمجالس الشورى غير المنتخبة , ولا تملك أي صلاحيات تشريعية , وهي بمثابة ديكور للزينة فقط</preprocessed>
                <bpc>
                    <chunk id="0" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="1" type="NP">
                        <tok id="0" form0="بلاد"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="+نا"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="عربية"/>
                    </chunk>
                    <chunk id="3" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="4" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="معظم"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دول"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="اسلامية"/>
                    </chunk>
                    <chunk id="7" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="8" type="VP">
                        <tok id="0" form0="تعتبر"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="صحة"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ملك"/>
                    </chunk>
                    <chunk id="11" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="رئيس"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جمهورية"/>
                    </chunk>
                    <chunk id="14" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="اسرار"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امن"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="قومي"/>
                    </chunk>
                    <chunk id="17" type="VP">
                        <tok id="0" form0="لا"/>
                        <tok id="1" form0="يجوز"/>
                    </chunk>
                    <chunk id="18" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="19" type="VP">
                        <tok id="0" form0="يعرف"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="21" type="NP">
                        <tok id="0" form0="احد"/>
                    </chunk>
                    <chunk id="22" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="الا"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="قلة"/>
                        <tok id="3" form0="ال+"/>
                        <tok id="4" form0="قليلة"/>
                    </chunk>
                    <chunk id="24" type="ADJP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="محيطة"/>
                    </chunk>
                    <chunk id="25" type="PP">
                        <tok id="0" form0="ب"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="27" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="اما"/>
                        <tok id="1" form0="رحلات"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="30" type="PP">
                        <tok id="0" form0="الي"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="خارج"/>
                    </chunk>
                    <chunk id="32" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="33" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="داخل"/>
                    </chunk>
                    <chunk id="35" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="قضاء"/>
                    </chunk>
                    <chunk id="37" type="NP">
                        <tok id="0" form0="اجازة"/>
                    </chunk>
                    <chunk id="38" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="39" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="40" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="علاج"/>
                    </chunk>
                    <chunk id="41" type="NP">
                        <tok id="0" form0="سيان"/>
                    </chunk>
                    <chunk id="42" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="43" type="">
                        <tok id="0" form0="ف+"/>
                    </chunk>
                    <chunk id="44" type="NP">
                        <tok id="0" form0="هي"/>
                    </chunk>
                    <chunk id="45" type="ADJP">
                        <tok id="0" form0="مفتوحة"/>
                    </chunk>
                    <chunk id="46" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="47" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="48" type="NP">
                        <tok id="0" form0="لا"/>
                        <tok id="1" form0="سقف"/>
                    </chunk>
                    <chunk id="49" type="PP">
                        <tok id="0" form0="ل"/>
                    </chunk>
                    <chunk id="50" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="51" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="52" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="53" type="NP">
                        <tok id="0" form0="هو"/>
                    </chunk>
                    <chunk id="54" type="WHNP">
                        <tok id="0" form0="الذي"/>
                    </chunk>
                    <chunk id="55" type="VP">
                        <tok id="0" form0="يحدد"/>
                    </chunk>
                    <chunk id="56" type="NP">
                        <tok id="0" form0="بداية"/>
                    </chunk>
                    <chunk id="57" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="58" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="59" type="NP">
                        <tok id="0" form0="نهاية"/>
                    </chunk>
                    <chunk id="60" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="61" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="62" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="63" type="VP">
                        <tok id="0" form0="لا"/>
                        <tok id="1" form0="يستاذن"/>
                    </chunk>
                    <chunk id="64" type="NP">
                        <tok id="0" form0="احدا"/>
                    </chunk>
                    <chunk id="65" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="66" type="SBAR">
                        <tok id="0" form0="لان"/>
                    </chunk>
                    <chunk id="67" type="NP">
                        <tok id="0" form0="هذا"/>
                    </chunk>
                    <chunk id="68" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قرار"/>
                        <tok id="2" form0="&quot;"/>
                        <tok id="3" form0="سيادي"/>
                        <tok id="4" form0="&quot;"/>
                    </chunk>
                    <chunk id="69" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="70" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="استئذان"/>
                    </chunk>
                    <chunk id="71" type="VP">
                        <tok id="0" form0="يرتقي"/>
                    </chunk>
                    <chunk id="72" type="PP">
                        <tok id="0" form0="الي"/>
                    </chunk>
                    <chunk id="73" type="NP">
                        <tok id="0" form0="مستوي"/>
                    </chunk>
                    <chunk id="74" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اهانة"/>
                    </chunk>
                    <chunk id="75" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="76" type="">
                        <tok id="0" form0="ثم"/>
                    </chunk>
                    <chunk id="77" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="78" type="WHNP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="79" type="VP">
                        <tok id="0" form0="يتقدم"/>
                    </chunk>
                    <chunk id="80" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="81" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اذن"/>
                    </chunk>
                    <chunk id="82" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="83" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="84" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="برلمان"/>
                    </chunk>
                    <chunk id="85" type="NP">
                        <tok id="0" form0="غير"/>
                    </chunk>
                    <chunk id="86" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="موجود"/>
                    </chunk>
                    <chunk id="87" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="88" type="NP">
                        <tok id="0" form0="معظم"/>
                    </chunk>
                    <chunk id="89" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دول"/>
                    </chunk>
                    <chunk id="90" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="91" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="92" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="93" type="NP">
                        <tok id="0" form0="مجالس"/>
                    </chunk>
                    <chunk id="94" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شوري"/>
                    </chunk>
                    <chunk id="95" type="NP">
                        <tok id="0" form0="غير"/>
                    </chunk>
                    <chunk id="96" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="منتخبة"/>
                    </chunk>
                    <chunk id="97" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="98" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="99" type="VP">
                        <tok id="0" form0="لا"/>
                        <tok id="1" form0="تملك"/>
                    </chunk>
                    <chunk id="100" type="NP">
                        <tok id="0" form0="اي"/>
                    </chunk>
                    <chunk id="101" type="NP">
                        <tok id="0" form0="صلاحيات"/>
                        <tok id="1" form0="تشريعية"/>
                    </chunk>
                    <chunk id="102" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="103" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="104" type="NP">
                        <tok id="0" form0="هي"/>
                    </chunk>
                    <chunk id="105" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="106" type="NP">
                        <tok id="0" form0="مثابة"/>
                    </chunk>
                    <chunk id="107" type="NP">
                        <tok id="0" form0="ديكور"/>
                    </chunk>
                    <chunk id="108" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="109" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="زينة"/>
                    </chunk>
                    <chunk id="110" type="ADVP">
                        <tok id="0" form0="فقط"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="في"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="بلاد"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="+نا"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="ال+"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="عربية"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0=","/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="و+"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="معظم"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="ال+"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="دول"/>
                    </ne>
                    <ne id="10" type="PER">
                        <tok id="10" form0="ال+"/>
                        <tok id="10" form0="اسلامية"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0=","/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="تعتبر"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="صحة"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="ال+"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="ملك"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="او"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="رئيس"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="ال+"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="جمهورية"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="من"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="اسرار"/>
                    </ne>
                    <ne id="22" type="ORG">
                        <tok id="22" form0="ال+"/>
                        <tok id="22" form0="امن"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="ال+"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="قومي"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="لا"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="يجوز"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ان"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="يعرف"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="+ها"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="احد"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0=","/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="الا"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="ال+"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="قلة"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="ال+"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="قليلة"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="ال+"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="محيطة"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="ب"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="+ه"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0=","/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="اما"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="رحلات"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="+ه"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="الي"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="ال+"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="خارج"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0=","/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="او"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="ال+"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="داخل"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="ل+"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="قضاء"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="اجازة"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="او"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="ل+"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="ال+"/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="علاج"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="سيان"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0=","/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0="ف+"/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="هي"/>
                    </ne>
                    <ne id="63" type="">
                        <tok id="63" form0="مفتوحة"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0=","/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0="و+"/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="لا"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0="سقف"/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="ل"/>
                    </ne>
                    <ne id="69" type="">
                        <tok id="69" form0="+ها"/>
                    </ne>
                    <ne id="70" type="">
                        <tok id="70" form0=","/>
                    </ne>
                    <ne id="71" type="">
                        <tok id="71" form0="و+"/>
                    </ne>
                    <ne id="72" type="">
                        <tok id="72" form0="هو"/>
                    </ne>
                    <ne id="73" type="">
                        <tok id="73" form0="الذي"/>
                    </ne>
                    <ne id="74" type="">
                        <tok id="74" form0="يحدد"/>
                    </ne>
                    <ne id="75" type="">
                        <tok id="75" form0="بداية"/>
                    </ne>
                    <ne id="76" type="">
                        <tok id="76" form0="+ها"/>
                    </ne>
                    <ne id="77" type="">
                        <tok id="77" form0="و+"/>
                    </ne>
                    <ne id="78" type="">
                        <tok id="78" form0="نهاية"/>
                    </ne>
                    <ne id="79" type="">
                        <tok id="79" form0="+ها"/>
                    </ne>
                    <ne id="80" type="">
                        <tok id="80" form0=","/>
                    </ne>
                    <ne id="81" type="">
                        <tok id="81" form0="و+"/>
                    </ne>
                    <ne id="82" type="">
                        <tok id="82" form0="لا"/>
                    </ne>
                    <ne id="83" type="">
                        <tok id="83" form0="يستاذن"/>
                    </ne>
                    <ne id="84" type="">
                        <tok id="84" form0="احدا"/>
                    </ne>
                    <ne id="85" type="">
                        <tok id="85" form0=","/>
                    </ne>
                    <ne id="86" type="">
                        <tok id="86" form0="لان"/>
                    </ne>
                    <ne id="87" type="">
                        <tok id="87" form0="هذا"/>
                    </ne>
                    <ne id="88" type="">
                        <tok id="88" form0="ال+"/>
                    </ne>
                    <ne id="89" type="">
                        <tok id="89" form0="قرار"/>
                    </ne>
                    <ne id="90" type="">
                        <tok id="90" form0="&quot;"/>
                    </ne>
                    <ne id="91" type="">
                        <tok id="91" form0="سيادي"/>
                    </ne>
                    <ne id="92" type="">
                        <tok id="92" form0="&quot;"/>
                    </ne>
                    <ne id="93" type="">
                        <tok id="93" form0="و+"/>
                    </ne>
                    <ne id="94" type="">
                        <tok id="94" form0="ال+"/>
                    </ne>
                    <ne id="95" type="">
                        <tok id="95" form0="استئذان"/>
                    </ne>
                    <ne id="96" type="">
                        <tok id="96" form0="يرتقي"/>
                    </ne>
                    <ne id="97" type="">
                        <tok id="97" form0="الي"/>
                    </ne>
                    <ne id="98" type="">
                        <tok id="98" form0="مستوي"/>
                    </ne>
                    <ne id="99" type="">
                        <tok id="99" form0="ال+"/>
                    </ne>
                    <ne id="100" type="">
                        <tok id="100" form0="اهانة"/>
                    </ne>
                    <ne id="101" type="">
                        <tok id="101" form0=","/>
                    </ne>
                    <ne id="102" type="">
                        <tok id="102" form0="ثم"/>
                    </ne>
                    <ne id="103" type="">
                        <tok id="103" form0="ل+"/>
                    </ne>
                    <ne id="104" type="">
                        <tok id="104" form0="من"/>
                    </ne>
                    <ne id="105" type="">
                        <tok id="105" form0="يتقدم"/>
                    </ne>
                    <ne id="106" type="">
                        <tok id="106" form0="ب+"/>
                    </ne>
                    <ne id="107" type="">
                        <tok id="107" form0="ال+"/>
                    </ne>
                    <ne id="108" type="">
                        <tok id="108" form0="اذن"/>
                    </ne>
                    <ne id="109" type="">
                        <tok id="109" form0=","/>
                    </ne>
                    <ne id="110" type="">
                        <tok id="110" form0="ل+"/>
                    </ne>
                    <ne id="111" type="LOC">
                        <tok id="111" form0="ال+"/>
                        <tok id="111" form0="برلمان"/>
                    </ne>
                    <ne id="112" type="">
                        <tok id="112" form0="غير"/>
                    </ne>
                    <ne id="113" type="">
                        <tok id="113" form0="ال+"/>
                    </ne>
                    <ne id="114" type="">
                        <tok id="114" form0="موجود"/>
                    </ne>
                    <ne id="115" type="">
                        <tok id="115" form0="في"/>
                    </ne>
                    <ne id="116" type="">
                        <tok id="116" form0="معظم"/>
                    </ne>
                    <ne id="117" type="">
                        <tok id="117" form0="ال+"/>
                    </ne>
                    <ne id="118" type="">
                        <tok id="118" form0="دول"/>
                    </ne>
                    <ne id="119" type="">
                        <tok id="119" form0=","/>
                    </ne>
                    <ne id="120" type="">
                        <tok id="120" form0="او"/>
                    </ne>
                    <ne id="121" type="">
                        <tok id="121" form0="ل+"/>
                    </ne>
                    <ne id="122" type="">
                        <tok id="122" form0="مجالس"/>
                    </ne>
                    <ne id="123" type="PER">
                        <tok id="123" form0="ال+"/>
                        <tok id="123" form0="شوري"/>
                    </ne>
                    <ne id="124" type="">
                        <tok id="124" form0="غير"/>
                    </ne>
                    <ne id="125" type="">
                        <tok id="125" form0="ال+"/>
                    </ne>
                    <ne id="126" type="">
                        <tok id="126" form0="منتخبة"/>
                    </ne>
                    <ne id="127" type="">
                        <tok id="127" form0=","/>
                    </ne>
                    <ne id="128" type="">
                        <tok id="128" form0="و+"/>
                    </ne>
                    <ne id="129" type="">
                        <tok id="129" form0="لا"/>
                    </ne>
                    <ne id="130" type="">
                        <tok id="130" form0="تملك"/>
                    </ne>
                    <ne id="131" type="">
                        <tok id="131" form0="اي"/>
                    </ne>
                    <ne id="132" type="">
                        <tok id="132" form0="صلاحيات"/>
                    </ne>
                    <ne id="133" type="">
                        <tok id="133" form0="تشريعية"/>
                    </ne>
                    <ne id="134" type="">
                        <tok id="134" form0=","/>
                    </ne>
                    <ne id="135" type="">
                        <tok id="135" form0="و+"/>
                    </ne>
                    <ne id="136" type="">
                        <tok id="136" form0="هي"/>
                    </ne>
                    <ne id="137" type="">
                        <tok id="137" form0="ب+"/>
                    </ne>
                    <ne id="138" type="">
                        <tok id="138" form0="مثابة"/>
                    </ne>
                    <ne id="139" type="PER">
                        <tok id="139" form0="ديكور"/>
                    </ne>
                    <ne id="140" type="ORG">
                        <tok id="140" form0="ل+"/>
                    </ne>
                    <ne id="141" type="">
                        <tok id="141" form0="ال+"/>
                    </ne>
                    <ne id="142" type="">
                        <tok id="142" form0="زينة"/>
                    </ne>
                    <ne id="143" type="">
                        <tok id="143" form0="فقط"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="1" word="بلادنا">
                    <svm_prediction>
                        <morph_feature_set diac="بِلادِنا" lemma="بَلَدbalad" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939458006110683">
                        <morph_feature_set diac="بِلادِنا" lemma="بَلَد_1" gloss="country;countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss" stem="بِلاد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بلاد"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="blAd" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+nA" form1="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بلاد" form1="بلاد" form2="بَلَد" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بلاد"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="2" word="العربية">
                    <svm_prediction>
                        <morph_feature_set diac="العَرَبِيَّةِ" lemma="عَرَبِيّEarabiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="العَرَبِيَّةِ" lemma="عَرَبِيّ_1" gloss="Arabic;Arab" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="عَرَبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العربية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Erbyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العربية" form1="العربية" form2="عَرَبِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عربية"/>
                    </tokenized>
                </word>
                <word id="3" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="4" word="ومعظم">
                    <svm_prediction>
                        <morph_feature_set diac="وَمُعْظَمِ" lemma="مُعْظَمmuEoZam" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8837313803605074">
                        <morph_feature_set diac="وَمُعْظَمُ" lemma="مُعْظَم_1" gloss="most_of;the_majority_of" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="مُعْظَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="معظم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="mEZm" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="معظم" form1="معظم" form2="مُعْظَم" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="معظم"/>
                    </tokenized>
                </word>
                <word id="5" word="الدول">
                    <svm_prediction>
                        <morph_feature_set diac="الدُّوَلَ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="الدُّوَلِ" lemma="دَوْلَة_1" gloss="states;countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="دُوَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدول" form1="الدول" form2="دَوْلَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دول"/>
                    </tokenized>
                </word>
                <word id="6" word="الإسلامية">
                    <svm_prediction>
                        <morph_feature_set diac="الإِسْلامِيَّةَ" lemma="إِسْلامِيّ&lt;isolAmiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8862218760012581">
                        <morph_feature_set diac="الإِسْلامِيَّةِ" lemma="إِسْلامِيّ_1" gloss="Islamic;Islamist;Muslim" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="إِسْلامِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاسلامية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AslAmyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الإسلامية" form1="الاسلامية" form2="إِسْلامِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اسلامية"/>
                    </tokenized>
                </word>
                <word id="7" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="8" word="تعتبر">
                    <svm_prediction>
                        <morph_feature_set diac="تُعْتَبَر" lemma="ٱِعْتَبَر{iEotabar" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="p" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="تُعْتَبَر" lemma="ٱِعْتَبَر_1" gloss="be_considered;be_regarded" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="p" mod="u" gen="f" num="s" stt="na" cas="na" enc0="0" stem="عْتَبَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تعتبر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tEtbr" form1="IV3FS+IV_PASS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تعتبر" form1="تعتبر" form2="ٱِعْتَبَر" form3="VRB-PASS" form4="VBN" form5="IV3FS+IV_PASS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تعتبر"/>
                    </tokenized>
                </word>
                <word id="9" word="صحة">
                    <svm_prediction>
                        <morph_feature_set diac="صِحَّةِ" lemma="صِحَّةSiH~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840007173019522">
                        <morph_feature_set diac="صِحَّةَ" lemma="صِحَّة_1" gloss="health;truth;correctness" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0" stem="صِحّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="صحة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="SHp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="صحة" form1="صحة" form2="صِحَّة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="صحة"/>
                    </tokenized>
                </word>
                <word id="10" word="الملك">
                    <svm_prediction>
                        <morph_feature_set diac="المَلِكِ" lemma="مَلِكmalik" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="المَلِكِ" lemma="مَلِك_2" gloss="king" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="مَلِك"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الملك"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mlk" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الملك" form1="الملك" form2="مَلِك" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ملك"/>
                    </tokenized>
                </word>
                <word id="11" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="12" word="رئيس">
                    <svm_prediction>
                        <morph_feature_set diac="رَئِيسِ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="رَئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رئيس" form1="رئيس" form2="رَئِيس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="13" word="الجمهورية">
                    <svm_prediction>
                        <morph_feature_set diac="الجُمْهُورِيَّةِ" lemma="جُمْهُورِيّjumohuwriy~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الجُمْهُورِيَّةِ" lemma="جُمْهُورِيّ_1" gloss="republic" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="جُمْهُورِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجمهورية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jmhwryp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجمهورية" form1="الجمهورية" form2="جُمْهُورِيّ" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جمهورية"/>
                    </tokenized>
                </word>
                <word id="14" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="15" word="اسرار">
                    <svm_prediction>
                        <morph_feature_set diac="أَسْرارٌ" lemma="سِرّsir~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8176168873326346">
                        <morph_feature_set diac="أَسْرارِ" lemma="سِرّ_1" gloss="secrets" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="أَسْرار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اسرار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AsrAr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أسرار" form1="اسرار" form2="سِرّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اسرار"/>
                    </tokenized>
                </word>
                <word id="16" word="الامن">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْنِ" lemma="أَمْن&gt;amon" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8294371058673811">
                        <morph_feature_set diac="الأَمْنِ" lemma="أَمْن_1" gloss="security;safety" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَمْن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمن" form1="الامن" form2="أَمْن" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امن"/>
                    </tokenized>
                </word>
                <word id="17" word="القومي">
                    <svm_prediction>
                        <morph_feature_set diac="القَوْمِيِّ" lemma="قَوْمِيّqawomiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="القَوْمِيِّ" lemma="قَوْمِيّ_1" gloss="national;state" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="قَوْمِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القومي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qwmy" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القومي" form1="القومي" form2="قَوْمِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قومي"/>
                    </tokenized>
                </word>
                <word id="18" word="لا">
                    <svm_prediction>
                        <morph_feature_set diac="لا" lemma="لاlA" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="لا" lemma="لا_1" gloss="no;not" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="lA" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="لا" form1="لا" form2="لا" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                </word>
                <word id="19" word="يجوز">
                    <svm_prediction>
                        <morph_feature_set diac="يَجُوز" lemma="جازjAz" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="يَجُوز" lemma="جاز-ُ_1" gloss="be_allowed;be_possible" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="جُوز"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يجوز"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yjwz" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يجوز" form1="يجوز" form2="جاز" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يجوز"/>
                    </tokenized>
                </word>
                <word id="20" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8155640401058297">
                        <morph_feature_set diac="أَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="21" word="يعرفها">
                    <svm_prediction>
                        <morph_feature_set diac="يَعْرِفها" lemma="عَرَفEaraf" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="3fs_dobj"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="يَعْرِفها" lemma="عَرَف-ِ_1" gloss="know" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="3fs_dobj" stem="عْرِف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يعرف"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yErf" form1="IV3MS+IV"/>
                        <tok id="1" form0="+hA" form1="+IVSUFF_DO:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يعرف" form1="يعرف" form2="عَرَف" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+IVSUFF_DO:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يعرف"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="22" word="احد">
                    <svm_prediction>
                        <morph_feature_set diac="أَحَدٍ" lemma="أَحَد&gt;aHad" pos="noun_num" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7448085888249397">
                        <morph_feature_set diac="أَحَدٌ" lemma="أَحَد_1" gloss="one;someone" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="أَحَد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="احد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AHd" form1="NOUN+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أحد" form1="احد" form2="أَحَد" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="احد"/>
                    </tokenized>
                </word>
                <word id="23" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="24" word="الا">
                    <svm_prediction>
                        <morph_feature_set diac="إِلّا" lemma="إِلّا&lt;il~A" pos="part_restrict" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7547557172440148">
                        <morph_feature_set diac="إِلّا" lemma="إِلّا_1" gloss="however;except" pos="part" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلّا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AlA" form1="PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلا" form1="الا" form2="إِلّا" form3="PRT" form4="RP" form5="PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الا"/>
                    </tokenized>
                </word>
                <word id="25" word="القلة">
                    <svm_prediction>
                        <morph_feature_set diac="القُلَّةَ" lemma="قِلَّةqil~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840123746217501">
                        <morph_feature_set diac="القِلَّةَ" lemma="قِلَّة_1" gloss="scarcity;lack_of;small_number_or_amount_of" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0" stem="قِلّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القلة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qlp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القلة" form1="القلة" form2="قِلَّة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قلة"/>
                    </tokenized>
                </word>
                <word id="26" word="القليلة">
                    <svm_prediction>
                        <morph_feature_set diac="القَلِيلَةَ" lemma="قَلِيلqaliyl" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942580844295446">
                        <morph_feature_set diac="القَلِيلَةَ" lemma="قَلِيل_1" gloss="little;few" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0" stem="قَلِيل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القليلة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qlylp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القليلة" form1="القليلة" form2="قَلِيل" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قليلة"/>
                    </tokenized>
                </word>
                <word id="27" word="المحيطة">
                    <svm_prediction>
                        <morph_feature_set diac="المُحِيطَةِ" lemma="مُحِيطmuHiyT" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.883959611520563">
                        <morph_feature_set diac="المُحِيطَةَ" lemma="مُحِيط_2" gloss="surrounding;peripheral" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="a" enc0="0" stem="مُحِيط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المحيطة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mHyTp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المحيطة" form1="المحيطة" form2="مُحِيط" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="محيطة"/>
                    </tokenized>
                </word>
                <word id="28" word="به">
                    <svm_prediction>
                        <morph_feature_set diac="بِهِ" lemma="بِbi" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3ms_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="بِهِ" lemma="بِ_1" gloss="with;by_+_it;him" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3ms_pron" stem="بِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b" form1="PREP"/>
                        <tok id="1" form0="+h" form1="+PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب" form1="ب" form2="بِ" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP" form5="+PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="29" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="30" word="اما">
                    <svm_prediction>
                        <morph_feature_set diac="أَمّا" lemma="أَمّا&gt;am~A" pos="part_focus" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8241679626190229">
                        <morph_feature_set diac="أَمّا" lemma="أَمّا_1" gloss="as_for;concerning" pos="part_focus" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَمّا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AmA" form1="FOCUS_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أما" form1="اما" form2="أَمّا" form3="PRT" form4="RP" form5="FOCUS_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اما"/>
                    </tokenized>
                </word>
                <word id="31" word="رحلاته">
                    <svm_prediction>
                        <morph_feature_set diac="رِحْلاتُهُ" lemma="رِحْلَةriHolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="n" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939036720115751">
                        <morph_feature_set diac="رِحْلاتُهُ" lemma="رِحْلَة_1" gloss="journey;career" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="n" enc0="3ms_poss" stem="رِحْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رحلات"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="rHlAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_NOM"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رحلات" form1="رحلات" form2="رِحْلَة" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_NOM"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رحلات"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="32" word="الى">
                    <svm_prediction>
                        <morph_feature_set diac="إِلَى" lemma="إِلَى&lt;ilaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8331090354286067">
                        <morph_feature_set diac="إِلَى" lemma="إِلَى_1" gloss="to;towards" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aly" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلى" form1="الي" form2="إِلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                </word>
                <word id="33" word="الخارج">
                    <svm_prediction>
                        <morph_feature_set diac="الخارِجِ" lemma="خارِجxArij" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الخارِجِ" lemma="خارِج_1" gloss="outside;exterior;outer_part" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="خارِج"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الخارج"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="xArj" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الخارج" form1="الخارج" form2="خارِج" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="خارج"/>
                    </tokenized>
                </word>
                <word id="34" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="35" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="36" word="الداخل">
                    <svm_prediction>
                        <morph_feature_set diac="الدّاخِلِ" lemma="داخِلdAxil" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الدّاخِلِ" lemma="داخِل_1" gloss="interior;inside" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="داخِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الداخل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dAxl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الداخل" form1="الداخل" form2="داخِل" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="داخل"/>
                    </tokenized>
                </word>
                <word id="37" word="لقضاء">
                    <svm_prediction>
                        <morph_feature_set diac="لَقَضاء" lemma="قَضاءqaDA'" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.884119331921918">
                        <morph_feature_set diac="لِقَضاءِ" lemma="قَضاء_1" gloss="justice;judiciary" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قَضاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="قضاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="qDA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="قضاء" form1="قضاء" form2="قَضاء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="قضاء"/>
                    </tokenized>
                </word>
                <word id="38" word="إجازة">
                    <svm_prediction>
                        <morph_feature_set diac="إِجازَةِ" lemma="إِجازَة&lt;ijAzap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8841970447888736">
                        <morph_feature_set diac="إِجازَةٍ" lemma="إِجازَة_1" gloss="furlough;permit" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="إِجاز"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اجازة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AjAzp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إجازة" form1="اجازة" form2="إِجازَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اجازة"/>
                    </tokenized>
                </word>
                <word id="39" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="40" word="للعلاج">
                    <svm_prediction>
                        <morph_feature_set diac="لِلعِلاجِ" lemma="عِلاجEilAj" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944374375687777">
                        <morph_feature_set diac="لِلعِلاجِ" lemma="عِلاج_1" gloss="medical_treatment;therapy;processing" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عِلاج"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="العلاج"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="ElAj" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="العلاج" form1="العلاج" form2="عِلاج" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="علاج"/>
                    </tokenized>
                </word>
                <word id="41" word="سيان">
                    <svm_prediction>
                        <morph_feature_set diac="سِيانٌ" lemma="سِيّsiy~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8691391907305279">
                        <morph_feature_set diac="سِيانٍ" lemma="سِيان_1" gloss="cyanogen" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="سِيان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سيان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="syAn" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سيان" form1="سيان" form2="سِيان" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سيان"/>
                    </tokenized>
                </word>
                <word id="42" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="43" word="فهي">
                    <svm_prediction>
                        <morph_feature_set diac="فَهِيَ" lemma="هِيَhiya" pos="pron" prc3="0" prc2="fa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="فَهِيَ" lemma="هِيَ_1" gloss="it;they;she" pos="pron" prc3="0" prc2="fa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="هِيَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="هي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="f+" form1="CONJ+"/>
                        <tok id="1" form0="hy" form1="PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ف+" form1="ف+" form2="فَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="هي" form1="هي" form2="هِيَ" form3="NOM" form4="PRP" form5="PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="هي"/>
                    </tokenized>
                </word>
                <word id="44" word="مفتوحة">
                    <svm_prediction>
                        <morph_feature_set diac="مَفْتُوحَةٌ" lemma="مَفْتُوحmafotuwH" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941748497117457">
                        <morph_feature_set diac="مَفْتُوحَةٌ" lemma="مَفْتُوح_1" gloss="open;opened" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="مَفْتُوح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مفتوحة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mftwHp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مفتوحة" form1="مفتوحة" form2="مَفْتُوح" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مفتوحة"/>
                    </tokenized>
                </word>
                <word id="45" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="46" word="ولا">
                    <svm_prediction>
                        <morph_feature_set diac="وَلا" lemma="لاlA" pos="verb_pseudo" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8246521697373949">
                        <morph_feature_set diac="وَلا" lemma="لا_1" gloss="no;not" pos="part_neg" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="lA" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="لا" form1="لا" form2="لا" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لا"/>
                    </tokenized>
                </word>
                <word id="47" word="سقف">
                    <svm_prediction>
                        <morph_feature_set diac="سَقْفِ" lemma="سَقْفsaqof" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8866756788017508">
                        <morph_feature_set diac="سَقْفَ" lemma="سَقْف_1" gloss="roof" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="سَقْف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سقف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sqf" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سقف" form1="سقف" form2="سَقْف" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سقف"/>
                    </tokenized>
                </word>
                <word id="48" word="لها">
                    <svm_prediction>
                        <morph_feature_set diac="لَها" lemma="لِli" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942873284255194">
                        <morph_feature_set diac="لَها" lemma="لِ_1" gloss="to;for_+_it;them;her_(it;she_has,_they_have)" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="لَها"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l" form1="PREP"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل" form1="ل" form2="لِ" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="49" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="50" word="وهو">
                    <svm_prediction>
                        <morph_feature_set diac="وَهُوَ" lemma="هُوَhuwa" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939703415048932">
                        <morph_feature_set diac="وَهُوَ" lemma="هُوَ_1" gloss="it;he" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="هُوَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هو"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="hw" form1="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="هو" form1="هو" form2="هُوَ" form3="NOM" form4="PRP" form5="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هو"/>
                    </tokenized>
                </word>
                <word id="51" word="الذي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِي_1" gloss="which;who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="الَّذِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*y" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذي" form1="الذي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                </word>
                <word id="52" word="يحدد">
                    <svm_prediction>
                        <morph_feature_set diac="يُحَدِّد" lemma="حَدَّدHad~ad" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="يُحَدِّد" lemma="حَدَّد_1" gloss="determine;define;specify" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="حَدِّد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يحدد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yHdd" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يحدد" form1="يحدد" form2="حَدَّد" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يحدد"/>
                    </tokenized>
                </word>
                <word id="53" word="بدايتها">
                    <svm_prediction>
                        <morph_feature_set diac="بِدايَتِها" lemma="بِدايَةbidAyap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3fs_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939666603746118">
                        <morph_feature_set diac="بِدايَتِها" lemma="بِدايَة_1" gloss="beginning;start" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3fs_poss" stem="بِداي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بداية"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bdAyp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="1" form0="+hA" form1="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بداية" form1="بداية" form2="بِدايَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بداية"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="54" word="ونهايتها">
                    <svm_prediction>
                        <morph_feature_set diac="وَنِهايَتُها" lemma="نِهايَةnihAyap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="3fs_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836033585323948">
                        <morph_feature_set diac="وَنِهايَتَها" lemma="نِهايَة_1" gloss="end;termination" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="3fs_poss" stem="نِهاي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="نهاية"/>
                        <tok id="2" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="nhAyp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                        <tok id="2" form0="+hA" form1="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="نهاية" form1="نهاية" form2="نِهايَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                        <tok id="2" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="نهاية"/>
                        <tok id="2" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="55" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="56" word="ولا">
                    <svm_prediction>
                        <morph_feature_set diac="وَلا" lemma="لاlA" pos="part_neg" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940709593524763">
                        <morph_feature_set diac="وَلا" lemma="لا_1" gloss="no;not" pos="part_neg" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="lA" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="لا" form1="لا" form2="لا" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لا"/>
                    </tokenized>
                </word>
                <word id="57" word="يستأذن">
                    <svm_prediction>
                        <morph_feature_set diac="يَسْتَأْذِنَّ" lemma="ٱِسْتَأْذَن{isota&gt;o*an" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8841291673133848">
                        <morph_feature_set diac="يَسْتَأْذِن" lemma="ٱِسْتَأْذَن_1" gloss="request_authorization" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="سْتَأْذِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يستاذن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ystA*n" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يستأذن" form1="يستاذن" form2="ٱِسْتَأْذَن" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يستاذن"/>
                    </tokenized>
                </word>
                <word id="58" word="أحدا">
                    <svm_prediction>
                        <morph_feature_set diac="أَحَداً" lemma="أَحَد&gt;aHad" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8951072017397583">
                        <morph_feature_set diac="أَحَداً" lemma="أَحَد_1" gloss="one;someone" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="أَحَد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="احدا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AHdA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أحدا" form1="احدا" form2="أَحَد" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="احدا"/>
                    </tokenized>
                </word>
                <word id="59" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="60" word="لان">
                    <svm_prediction>
                        <morph_feature_set diac="لِأَنَّ" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="0" prc1="li_prep" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7201211087231928">
                        <morph_feature_set diac="لِأَنَّ" lemma="أَنَّ_1" gloss="because" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لِأَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="لان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="lAn" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="لأن" form1="لان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="لان"/>
                    </tokenized>
                </word>
                <word id="61" word="هذا">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذا" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذا" lemma="هٰذا_1" gloss="this" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="هٰذا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*A" form1="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذا" form1="هذا" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                </word>
                <word id="62" word="القرار">
                    <svm_prediction>
                        <morph_feature_set diac="القَرارَ" lemma="قَرارqarAr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895212316960791">
                        <morph_feature_set diac="القَرارَ" lemma="قَرار_1" gloss="decision;resolution" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="قَرار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القرار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qrAr" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القرار" form1="القرار" form2="قَرار" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قرار"/>
                    </tokenized>
                </word>
                <word id="63" word="&quot;">
                    <svm_prediction>
                        <morph_feature_set diac="&quot;" lemma="&quot;&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="&quot;" lemma="&quot;_0" gloss="&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="&quot;" form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="&quot;" form1="&quot;" form2="&quot;" form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                </word>
                <word id="64" word="سيادي">
                    <svm_prediction>
                        <morph_feature_set diac="سيادي" lemma="سياديsyAdy" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سيادي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="syAdy" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سيادي" form1="سيادي" form2="سيادي" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سيادي"/>
                    </tokenized>
                </word>
                <word id="65" word="&quot;">
                    <svm_prediction>
                        <morph_feature_set diac="&quot;" lemma="&quot;&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="&quot;" lemma="&quot;_0" gloss="&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="&quot;" form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="&quot;" form1="&quot;" form2="&quot;" form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                </word>
                <word id="66" word="والاستئذان">
                    <svm_prediction>
                        <morph_feature_set diac="وَالاِسْتِئْذانُ" lemma="ٱِسْتِئْذان{isoti}o*An" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940433508207358">
                        <morph_feature_set diac="وَالاِسْتِئْذانُ" lemma="ٱِسْتِئْذان_1" gloss="request_for_authorization" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="ٱِسْتِئْذان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الاستئذان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="Ast}*An" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الاستئذان" form1="الاستئذان" form2="ٱِسْتِئْذان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="استئذان"/>
                    </tokenized>
                </word>
                <word id="67" word="يرتقي">
                    <svm_prediction>
                        <morph_feature_set diac="يَرْتَقِي" lemma="ٱِرْتَقَى{irotaqaY" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="يَرْتَقِي" lemma="ٱِرْتَقَى_1" gloss="ascend;increase;rise" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="رْتَقِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يرتقي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yrtqy" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يرتقي" form1="يرتقي" form2="ٱِرْتَقَى" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يرتقي"/>
                    </tokenized>
                </word>
                <word id="68" word="الى">
                    <svm_prediction>
                        <morph_feature_set diac="إِلَى" lemma="إِلَى&lt;ilaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8331090354286067">
                        <morph_feature_set diac="إِلَى" lemma="إِلَى_1" gloss="to;towards" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aly" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلى" form1="الي" form2="إِلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                </word>
                <word id="69" word="مستوى">
                    <svm_prediction>
                        <morph_feature_set diac="مُسْتَوَى" lemma="مُسْتَوَىmusotawaY" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944319152280099">
                        <morph_feature_set diac="مُسْتَوَى" lemma="مُسْتَوَى_1" gloss="level;standard" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="مُسْتَوَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مستوي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mstwy" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مستوى" form1="مستوي" form2="مُسْتَوَى" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مستوي"/>
                    </tokenized>
                </word>
                <word id="70" word="الإهانة">
                    <svm_prediction>
                        <morph_feature_set diac="الإِهانَةِ" lemma="إِهانَة&lt;ihAnap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الإِهانَةِ" lemma="إِهانَة_1" gloss="insult;contempt" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="إِهان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاهانة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AhAnp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الإهانة" form1="الاهانة" form2="إِهانَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اهانة"/>
                    </tokenized>
                </word>
                <word id="71" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="72" word="ثم">
                    <svm_prediction>
                        <morph_feature_set diac="ثُمَّ" lemma="ثُمَّvum~a" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.6297444731704295">
                        <morph_feature_set diac="ثُمَّ" lemma="ثُمَّ_1" gloss="then;thereupon" pos="adv" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ثُمَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ثم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="vm" form1="ADV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ثم" form1="ثم" form2="ثُمَّ" form3="NOM" form4="RB" form5="ADV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ثم"/>
                    </tokenized>
                </word>
                <word id="73" word="لمن">
                    <svm_prediction>
                        <morph_feature_set diac="لُمْنَ" lemma="مِنmin" pos="pron_rel" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8674769528264158">
                        <morph_feature_set diac="لِمَن" lemma="مَن_1" gloss="who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="مَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="mn" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="من" form1="من" form2="مَن" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="من"/>
                    </tokenized>
                </word>
                <word id="74" word="يتقدم">
                    <svm_prediction>
                        <morph_feature_set diac="يَتَقَدَّم" lemma="تَقَدَّمtaqad~am" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="يَتَقَدَّم" lemma="تَقَدَّم_1" gloss="present;advance" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="تَقَدَّم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يتقدم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ytqdm" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يتقدم" form1="يتقدم" form2="تَقَدَّم" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يتقدم"/>
                    </tokenized>
                </word>
                <word id="75" word="بالاذن">
                    <svm_prediction>
                        <morph_feature_set diac="بِالأُذُنِ" lemma="أُذُن&gt;u*un" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.824390058063784">
                        <morph_feature_set diac="بِالأُذُنِ" lemma="أُذُن_1" gloss="ear" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أُذُن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="الاذن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="A*n" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الأذن" form1="الاذن" form2="أُذُن" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="اذن"/>
                    </tokenized>
                </word>
                <word id="76" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="77" word="للبرلمان">
                    <svm_prediction>
                        <morph_feature_set diac="لِلبَرْلَمانِ" lemma="بَرْلَمانbarolamAn" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944374375687777">
                        <morph_feature_set diac="لِلبَرْلَمانِ" lemma="بَرْلَمان_1" gloss="parliament" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="بَرْلَمان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="البرلمان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="brlmAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="البرلمان" form1="البرلمان" form2="بَرْلَمان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="برلمان"/>
                    </tokenized>
                </word>
                <word id="78" word="غير">
                    <svm_prediction>
                        <morph_feature_set diac="غَيْرِ" lemma="غَيْرgayor" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="غَيْرِ" lemma="غَيْر_1" gloss="not;other" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="غَيْر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="غير"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="gyr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="غير" form1="غير" form2="غَيْر" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="غير"/>
                    </tokenized>
                </word>
                <word id="79" word="الموجود">
                    <svm_prediction>
                        <morph_feature_set diac="المَوْجُودَ" lemma="مَوْجُودmawojuwd" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8194995219647865">
                        <morph_feature_set diac="المَوْجُودِ" lemma="مَوْجُود_1" gloss="present;existing;found" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="مَوْجُود"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الموجود"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mwjwd" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الموجود" form1="الموجود" form2="مَوْجُود" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="موجود"/>
                    </tokenized>
                </word>
                <word id="80" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="81" word="معظم">
                    <svm_prediction>
                        <morph_feature_set diac="مُعْظَمِ" lemma="مُعْظَمmuEoZam" pos="noun_quant" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8282762492480038">
                        <morph_feature_set diac="مُعْظَمِ" lemma="مُعْظَم_1" gloss="most_of;the_majority_of" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مُعْظَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="معظم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mEZm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="معظم" form1="معظم" form2="مُعْظَم" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="معظم"/>
                    </tokenized>
                </word>
                <word id="82" word="الدول">
                    <svm_prediction>
                        <morph_feature_set diac="الدُّوَلِ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الدُّوَلِ" lemma="دَوْلَة_1" gloss="states;countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="دُوَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدول" form1="الدول" form2="دَوْلَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دول"/>
                    </tokenized>
                </word>
                <word id="83" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="84" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="85" word="لمجالس">
                    <svm_prediction>
                        <morph_feature_set diac="لِمَجالِس" lemma="مَجْلِسmajolis" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.884119331921918">
                        <morph_feature_set diac="لِمَجالِسِ" lemma="مَجْلِس_1" gloss="councils;boards" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مَجالِس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="مجالس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="mjAls" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="مجالس" form1="مجالس" form2="مَجْلِس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="مجالس"/>
                    </tokenized>
                </word>
                <word id="86" word="الشورى">
                    <svm_prediction>
                        <morph_feature_set diac="الشُّورَى" lemma="شُورَى$uwraY" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943368191769413">
                        <morph_feature_set diac="الشُّورَى" lemma="شُورَى_1" gloss="consultation;deliberation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="شُورَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشوري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$wry" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشورى" form1="الشوري" form2="شُورَى" form3="NOM" form4="DT+NN" form5="DET+NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شوري"/>
                    </tokenized>
                </word>
                <word id="87" word="غير">
                    <svm_prediction>
                        <morph_feature_set diac="غَيْرِ" lemma="غَيْرgayor" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="غَيْرِ" lemma="غَيْر_1" gloss="not;other" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="غَيْر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="غير"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="gyr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="غير" form1="غير" form2="غَيْر" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="غير"/>
                    </tokenized>
                </word>
                <word id="88" word="المنتخبة">
                    <svm_prediction>
                        <morph_feature_set diac="المُنْتَخَبَةِ" lemma="مُنْتَخَبmunotaxab" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8265346650184467">
                        <morph_feature_set diac="المُنْتَخَبَةِ" lemma="مُنْتَخَب_1" gloss="elected_candidate;elect" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مُنْتَخَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المنتخبة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mntxbp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المنتخبة" form1="المنتخبة" form2="مُنْتَخَب" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="منتخبة"/>
                    </tokenized>
                </word>
                <word id="89" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="90" word="ولا">
                    <svm_prediction>
                        <morph_feature_set diac="وَلا" lemma="لاlA" pos="part_neg" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940709593524763">
                        <morph_feature_set diac="وَلا" lemma="لا_1" gloss="no;not" pos="part_neg" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="lA" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="لا" form1="لا" form2="لا" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لا"/>
                    </tokenized>
                </word>
                <word id="91" word="تملك">
                    <svm_prediction>
                        <morph_feature_set diac="تَمَلُّكِ" lemma="مَلَكmalak" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="تَمْلِك" lemma="مَلَك-َِ_1" gloss="have;hold;control" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="f" num="s" stt="na" cas="na" enc0="0" stem="مْلِك"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تملك"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tmlk" form1="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تملك" form1="تملك" form2="مَلَك" form3="VRB" form4="VBP" form5="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تملك"/>
                    </tokenized>
                </word>
                <word id="92" word="أي">
                    <svm_prediction>
                        <morph_feature_set diac="أَيْ" lemma="أَيّ&gt;ay~" pos="noun_quant" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7840180448081172">
                        <morph_feature_set diac="أَيّ" lemma="أَيّ_1" gloss="any" pos="noun_quant" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="أَيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ay" form1="NOUN_QUANT"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أي" form1="اي" form2="أَيّ" form3="NOM" form4="NOUN_QUANT" form5="NOUN_QUANT"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اي"/>
                    </tokenized>
                </word>
                <word id="93" word="صلاحيات">
                    <svm_prediction>
                        <morph_feature_set diac="صَلاحِيّاتِ" lemma="صَلاحِيَّةSalAHiy~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839166646816445">
                        <morph_feature_set diac="صَلاحِيّاتٍ" lemma="صَلاحِيَّة_1" gloss="practicability;viability;competence" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0" stem="صَلاحِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="صلاحيات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="SlAHyAt" form1="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="صلاحيات" form1="صلاحيات" form2="صَلاحِيَّة" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="صلاحيات"/>
                    </tokenized>
                </word>
                <word id="94" word="تشريعية">
                    <svm_prediction>
                        <morph_feature_set diac="تَشْرِيعِيَّةٍ" lemma="تَشْرِيعta$oriyE" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8785112455003898">
                        <morph_feature_set diac="تَشْرِيعِيَّةٍ" lemma="تَشْرِيعِيّ_1" gloss="legislative" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="تَشْرِيعِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تشريعية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="t$ryEyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تشريعية" form1="تشريعية" form2="تَشْرِيعِيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تشريعية"/>
                    </tokenized>
                </word>
                <word id="95" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="96" word="وهي">
                    <svm_prediction>
                        <morph_feature_set diac="وَهِيَ" lemma="هِيَhiya" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939533673902794">
                        <morph_feature_set diac="وَهِيَ" lemma="هِيَ_1" gloss="it;they;she" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="هِيَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="hy" form1="PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="هي" form1="هي" form2="هِيَ" form3="NOM" form4="PRP" form5="PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هي"/>
                    </tokenized>
                </word>
                <word id="97" word="بمثابة">
                    <svm_prediction>
                        <morph_feature_set diac="بِمَثابَةِ" lemma="مَثابَةmavAbap" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894096931751717">
                        <morph_feature_set diac="بِمَثابَةِ" lemma="مَثابَة_1" gloss="virtually;tantamount_to" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="مَثاب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="مثابة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="mvAbp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="مثابة" form1="مثابة" form2="مَثابَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="مثابة"/>
                    </tokenized>
                </word>
                <word id="98" word="ديكور">
                    <svm_prediction>
                        <morph_feature_set diac="دِيكُورَ" lemma="دِيكُورdiykuwr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.885277866901877">
                        <morph_feature_set diac="دِيكُورٍ" lemma="دِيكُور_1" gloss="decor;interior_decoration" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="دِيكُور"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ديكور"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dykwr" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ديكور" form1="ديكور" form2="دِيكُور" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ديكور"/>
                    </tokenized>
                </word>
                <word id="99" word="للزينة">
                    <svm_prediction>
                        <morph_feature_set diac="لِلزَّيْنَةِ" lemma="زَيْنَةzayonap" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8677029339545542">
                        <morph_feature_set diac="لِلزِّينَةِ" lemma="زِينَة_1" gloss="embellishment;decoration" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="زِين"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="الزينة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="zynp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الزينة" form1="الزينة" form2="زِينَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="زينة"/>
                    </tokenized>
                </word>
                <word id="100" word="فقط">
                    <svm_prediction>
                        <morph_feature_set diac="فَقَط" lemma="فَقَطfaqaT" pos="adv" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941603296133013">
                        <morph_feature_set diac="فَقَط" lemma="فَقَط_1" gloss="only" pos="adv" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="فَقَط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="فقط"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fqT" form1="ADV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="فقط" form1="فقط" form2="فَقَط" form3="NOM" form4="RB" form5="ADV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="فقط"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT9">
            <segment_info>
                <preprocessed>اما اذا انتقلنا الى حكم المحكمة الامريكية التي كسرت كبرياء رئيس الدولة الأعظم في العالم وعلمته درسا في ضرورة احترام مؤسسات الدولة , والقضائية منها على وجه الخصوص , فإن هذه المحكمة التي نصت في فتوى قضائية ملزمة بإلغاء العمل بالقانون الذي أصدره هذا الرئيس العنصري الجاهل ويمنع دخول مواطنين مسلمين يحملون تأشيرات رسمية , أظهرت بعض الجوانب المضيئة في النظام الأمريكي , وعززت مكانة المؤسسات , وفرضت احترام الدستور ونصوصه وروحه , والاحصائيات الامريكية الرسمية تؤكد ان 3</preprocessed>
                <bpc>
                    <chunk id="0" type="SBAR">
                        <tok id="0" form0="اما"/>
                        <tok id="1" form0="اذا"/>
                    </chunk>
                    <chunk id="1" type="VP">
                        <tok id="0" form0="انتقلنا"/>
                    </chunk>
                    <chunk id="2" type="PP">
                        <tok id="0" form0="الي"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="حكم"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="محكمة"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="امريكية"/>
                    </chunk>
                    <chunk id="5" type="WHNP">
                        <tok id="0" form0="التي"/>
                    </chunk>
                    <chunk id="6" type="VP">
                        <tok id="0" form0="كسرت"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="كبرياء"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="رئيس"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دولة"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="ال+"/>
                    </chunk>
                    <chunk id="11" type="ADJP">
                        <tok id="0" form0="اعظم"/>
                    </chunk>
                    <chunk id="12" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عالم"/>
                    </chunk>
                    <chunk id="14" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="علمة"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="درسا"/>
                    </chunk>
                    <chunk id="18" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="ضرورة"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="احترام"/>
                    </chunk>
                    <chunk id="21" type="NP">
                        <tok id="0" form0="مؤسسات"/>
                    </chunk>
                    <chunk id="22" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دولة"/>
                    </chunk>
                    <chunk id="23" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="24" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="25" type="ADJP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قضائية"/>
                    </chunk>
                    <chunk id="26" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="27" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                    <chunk id="28" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="وجه"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="خصوص"/>
                    </chunk>
                    <chunk id="31" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="32" type="">
                        <tok id="0" form0="ف+"/>
                    </chunk>
                    <chunk id="33" type="VP">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="هذه"/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="محكمة"/>
                    </chunk>
                    <chunk id="36" type="WHNP">
                        <tok id="0" form0="التي"/>
                    </chunk>
                    <chunk id="37" type="VP">
                        <tok id="0" form0="نصت"/>
                    </chunk>
                    <chunk id="38" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="39" type="NP">
                        <tok id="0" form0="فتوي"/>
                        <tok id="1" form0="قضائية"/>
                        <tok id="2" form0="ملزمة"/>
                    </chunk>
                    <chunk id="40" type="PP">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="الغاء"/>
                    </chunk>
                    <chunk id="41" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عمل"/>
                    </chunk>
                    <chunk id="42" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="43" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قانون"/>
                    </chunk>
                    <chunk id="44" type="WHNP">
                        <tok id="0" form0="الذي"/>
                    </chunk>
                    <chunk id="45" type="VP">
                        <tok id="0" form0="اصدر"/>
                    </chunk>
                    <chunk id="46" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="47" type="NP">
                        <tok id="0" form0="هذا"/>
                    </chunk>
                    <chunk id="48" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="عنصري"/>
                        <tok id="4" form0="ال+"/>
                        <tok id="5" form0="جاهل"/>
                    </chunk>
                    <chunk id="49" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="50" type="VP">
                        <tok id="0" form0="يمنع"/>
                    </chunk>
                    <chunk id="51" type="NP">
                        <tok id="0" form0="دخول"/>
                    </chunk>
                    <chunk id="52" type="NP">
                        <tok id="0" form0="مواطنين"/>
                        <tok id="1" form0="مسلمين"/>
                    </chunk>
                    <chunk id="53" type="VP">
                        <tok id="0" form0="يحملون"/>
                    </chunk>
                    <chunk id="54" type="NP">
                        <tok id="0" form0="تاشيرات"/>
                        <tok id="1" form0="رسمية"/>
                    </chunk>
                    <chunk id="55" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="56" type="VP">
                        <tok id="0" form0="اظهرت"/>
                    </chunk>
                    <chunk id="57" type="NP">
                        <tok id="0" form0="بعض"/>
                    </chunk>
                    <chunk id="58" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جوانب"/>
                    </chunk>
                    <chunk id="59" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مضيئة"/>
                    </chunk>
                    <chunk id="60" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="61" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نظام"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="امريكي"/>
                    </chunk>
                    <chunk id="62" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="63" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="64" type="VP">
                        <tok id="0" form0="عززت"/>
                    </chunk>
                    <chunk id="65" type="NP">
                        <tok id="0" form0="مكانة"/>
                    </chunk>
                    <chunk id="66" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤسسات"/>
                    </chunk>
                    <chunk id="67" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="68" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="69" type="VP">
                        <tok id="0" form0="فرضت"/>
                    </chunk>
                    <chunk id="70" type="NP">
                        <tok id="0" form0="احترام"/>
                    </chunk>
                    <chunk id="71" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دستور"/>
                    </chunk>
                    <chunk id="72" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="73" type="NP">
                        <tok id="0" form0="نصوص"/>
                    </chunk>
                    <chunk id="74" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="75" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="76" type="NP">
                        <tok id="0" form0="روح"/>
                    </chunk>
                    <chunk id="77" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="78" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="79" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="80" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="احصائيات"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="امريكية"/>
                        <tok id="4" form0="ال+"/>
                        <tok id="5" form0="رسمية"/>
                    </chunk>
                    <chunk id="81" type="VP">
                        <tok id="0" form0="تؤكد"/>
                    </chunk>
                    <chunk id="82" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="83" type="NP">
                        <tok id="0" form0="3"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="اما"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="اذا"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="انتقلنا"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="الي"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="حكم"/>
                    </ne>
                    <ne id="5" type="ORG">
                        <tok id="5" form0="ال+"/>
                        <tok id="5" form0="محكمة"/>
                    </ne>
                    <ne id="6" type="LOC">
                        <tok id="6" form0="ال+"/>
                        <tok id="6" form0="امريكية"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="التي"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="كسرت"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="كبرياء"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="رئيس"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="ال+"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="دولة"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="ال+"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="اعظم"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="في"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="ال+"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="عالم"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="و+"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="علمة"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="+ه"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="درسا"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="في"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="ضرورة"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="احترام"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="مؤسسات"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="ال+"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="دولة"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0=","/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="و+"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="ال+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="قضائية"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="من"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="+ها"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="علي"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="وجه"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="ال+"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="خصوص"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0=","/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="ف+"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="ان"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="هذه"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="ال+"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="محكمة"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="التي"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="نصت"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="في"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="فتوي"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="قضائية"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="ملزمة"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="ب+"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="الغاء"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="ال+"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="عمل"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="ب+"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="ال+"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="قانون"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="الذي"/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="اصدر"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="+ه"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="هذا"/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0="ال+"/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="رئيس"/>
                    </ne>
                    <ne id="63" type="">
                        <tok id="63" form0="ال+"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0="عنصري"/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0="ال+"/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="جاهل"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0="و+"/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="يمنع"/>
                    </ne>
                    <ne id="69" type="">
                        <tok id="69" form0="دخول"/>
                    </ne>
                    <ne id="70" type="">
                        <tok id="70" form0="مواطنين"/>
                    </ne>
                    <ne id="71" type="">
                        <tok id="71" form0="مسلمين"/>
                    </ne>
                    <ne id="72" type="">
                        <tok id="72" form0="يحملون"/>
                    </ne>
                    <ne id="73" type="">
                        <tok id="73" form0="تاشيرات"/>
                    </ne>
                    <ne id="74" type="">
                        <tok id="74" form0="رسمية"/>
                    </ne>
                    <ne id="75" type="">
                        <tok id="75" form0=","/>
                    </ne>
                    <ne id="76" type="">
                        <tok id="76" form0="اظهرت"/>
                    </ne>
                    <ne id="77" type="">
                        <tok id="77" form0="بعض"/>
                    </ne>
                    <ne id="78" type="">
                        <tok id="78" form0="ال+"/>
                    </ne>
                    <ne id="79" type="">
                        <tok id="79" form0="جوانب"/>
                    </ne>
                    <ne id="80" type="">
                        <tok id="80" form0="ال+"/>
                    </ne>
                    <ne id="81" type="">
                        <tok id="81" form0="مضيئة"/>
                    </ne>
                    <ne id="82" type="">
                        <tok id="82" form0="في"/>
                    </ne>
                    <ne id="83" type="">
                        <tok id="83" form0="ال+"/>
                    </ne>
                    <ne id="84" type="">
                        <tok id="84" form0="نظام"/>
                    </ne>
                    <ne id="85" type="LOC">
                        <tok id="85" form0="ال+"/>
                        <tok id="85" form0="امريكي"/>
                    </ne>
                    <ne id="86" type="">
                        <tok id="86" form0=","/>
                    </ne>
                    <ne id="87" type="">
                        <tok id="87" form0="و+"/>
                    </ne>
                    <ne id="88" type="">
                        <tok id="88" form0="عززت"/>
                    </ne>
                    <ne id="89" type="">
                        <tok id="89" form0="مكانة"/>
                    </ne>
                    <ne id="90" type="">
                        <tok id="90" form0="ال+"/>
                    </ne>
                    <ne id="91" type="">
                        <tok id="91" form0="مؤسسات"/>
                    </ne>
                    <ne id="92" type="">
                        <tok id="92" form0=","/>
                    </ne>
                    <ne id="93" type="">
                        <tok id="93" form0="و+"/>
                    </ne>
                    <ne id="94" type="">
                        <tok id="94" form0="فرضت"/>
                    </ne>
                    <ne id="95" type="">
                        <tok id="95" form0="احترام"/>
                    </ne>
                    <ne id="96" type="">
                        <tok id="96" form0="ال+"/>
                    </ne>
                    <ne id="97" type="">
                        <tok id="97" form0="دستور"/>
                    </ne>
                    <ne id="98" type="">
                        <tok id="98" form0="و+"/>
                    </ne>
                    <ne id="99" type="">
                        <tok id="99" form0="نصوص"/>
                    </ne>
                    <ne id="100" type="">
                        <tok id="100" form0="+ه"/>
                    </ne>
                    <ne id="101" type="">
                        <tok id="101" form0="و+"/>
                    </ne>
                    <ne id="102" type="">
                        <tok id="102" form0="روح"/>
                    </ne>
                    <ne id="103" type="">
                        <tok id="103" form0="+ه"/>
                    </ne>
                    <ne id="104" type="">
                        <tok id="104" form0=","/>
                    </ne>
                    <ne id="105" type="">
                        <tok id="105" form0="و+"/>
                    </ne>
                    <ne id="106" type="">
                        <tok id="106" form0="ال+"/>
                    </ne>
                    <ne id="107" type="">
                        <tok id="107" form0="احصائيات"/>
                    </ne>
                    <ne id="108" type="LOC">
                        <tok id="108" form0="ال+"/>
                        <tok id="108" form0="امريكية"/>
                    </ne>
                    <ne id="109" type="">
                        <tok id="109" form0="ال+"/>
                    </ne>
                    <ne id="110" type="">
                        <tok id="110" form0="رسمية"/>
                    </ne>
                    <ne id="111" type="">
                        <tok id="111" form0="تؤكد"/>
                    </ne>
                    <ne id="112" type="">
                        <tok id="112" form0="ان"/>
                    </ne>
                    <ne id="113" type="">
                        <tok id="113" form0="3"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="اما">
                    <svm_prediction>
                        <morph_feature_set diac="أَمّا" lemma="أَمّا&gt;am~A" pos="part_focus" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8241679626190229">
                        <morph_feature_set diac="أَمّا" lemma="أَمّا_1" gloss="as_for;concerning" pos="part_focus" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَمّا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AmA" form1="FOCUS_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أما" form1="اما" form2="أَمّا" form3="PRT" form4="RP" form5="FOCUS_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اما"/>
                    </tokenized>
                </word>
                <word id="1" word="اذا">
                    <svm_prediction>
                        <morph_feature_set diac="إِذا" lemma="إِذا&lt;i*A" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7552876426838027">
                        <morph_feature_set diac="إِذا" lemma="إِذا_1" gloss="if;whether" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِذا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اذا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="A*A" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إذا" form1="اذا" form2="إِذا" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اذا"/>
                    </tokenized>
                </word>
                <word id="2" word="انتقلنا">
                    <svm_prediction>
                        <morph_feature_set diac="اِنْتَقَلْنا" lemma="ٱِنْتَقَل{inotaqal" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8672667201040258">
                        <morph_feature_set diac="اِنْتَقَلْنا" lemma="ٱِنْتَقَل_1" gloss="move;transfer" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="ٱِنْتَقَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="انتقلنا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AntqlnA" form1="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="انتقلنا" form1="انتقلنا" form2="ٱِنْتَقَل" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="انتقلنا"/>
                    </tokenized>
                </word>
                <word id="3" word="الى">
                    <svm_prediction>
                        <morph_feature_set diac="إِلَى" lemma="إِلَى&lt;ilaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8331090354286067">
                        <morph_feature_set diac="إِلَى" lemma="إِلَى_1" gloss="to;towards" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aly" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلى" form1="الي" form2="إِلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                </word>
                <word id="4" word="حكم">
                    <svm_prediction>
                        <morph_feature_set diac="حُكْمِ" lemma="حُكْمHukom" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="حُكْمِ" lemma="حُكْم_1" gloss="judgment;decision" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="حُكْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حكم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Hkm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حكم" form1="حكم" form2="حُكْم" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حكم"/>
                    </tokenized>
                </word>
                <word id="5" word="المحكمة">
                    <svm_prediction>
                        <morph_feature_set diac="المَحْكَمَةِ" lemma="مَحْكَمَةmaHokamap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="المَحْكَمَةِ" lemma="مَحْكَمَة_1" gloss="court;tribunal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مَحْكَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المحكمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mHkmp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المحكمة" form1="المحكمة" form2="مَحْكَمَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="محكمة"/>
                    </tokenized>
                </word>
                <word id="6" word="الامريكية">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْرِيكِيَّةِ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8267406702887713">
                        <morph_feature_set diac="الأَمْرِيكِيَّةِ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامريكية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amrykyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمريكية" form1="الامريكية" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكية"/>
                    </tokenized>
                </word>
                <word id="7" word="التي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8945079933398044">
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِي_1" gloss="which;who;whom_[fem.sg.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="الَّتِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alty" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التي" form1="التي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                </word>
                <word id="8" word="كسرت">
                    <svm_prediction>
                        <morph_feature_set diac="كَسَرْتُ" lemma="كَسَرkasar" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8845512523775504">
                        <morph_feature_set diac="كَسَرَت" lemma="كَسَر-ِ_1" gloss="break;defeat" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0" stem="كَسَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كسرت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ksrt" form1="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كسرت" form1="كسرت" form2="كَسَر" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كسرت"/>
                    </tokenized>
                </word>
                <word id="9" word="كبرياء">
                    <svm_prediction>
                        <morph_feature_set diac="كِبْرِياءَ" lemma="كِبْرِياءkiboriyA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8873965659541032">
                        <morph_feature_set diac="كِبْرِياءِ" lemma="كِبْرِياء_1" gloss="arrogance" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="كِبْرِياء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كبرياء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="kbryA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كبرياء" form1="كبرياء" form2="كِبْرِياء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كبرياء"/>
                    </tokenized>
                </word>
                <word id="10" word="رئيس">
                    <svm_prediction>
                        <morph_feature_set diac="رَئِيسُ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8873965659541032">
                        <morph_feature_set diac="رَئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رئيس" form1="رئيس" form2="رَئِيس" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="11" word="الدولة">
                    <svm_prediction>
                        <morph_feature_set diac="الدَّوْلَةُ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8856549817245463">
                        <morph_feature_set diac="الدَّوْلَةِ" lemma="دَوْلَة_1" gloss="state;country" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="دَوْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدولة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwlp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدولة" form1="الدولة" form2="دَوْلَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دولة"/>
                    </tokenized>
                </word>
                <word id="12" word="الأعظم">
                    <svm_prediction>
                        <morph_feature_set diac="الأَعْظَمُ" lemma="أَعْظَم&gt;aEoZam" pos="adj_comp" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8194995219647865">
                        <morph_feature_set diac="الأَعْظَمِ" lemma="أَعْظَم_2" gloss="greater;greatest;major" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَعْظَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاعظم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AEZm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأعظم" form1="الاعظم" form2="أَعْظَم" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اعظم"/>
                    </tokenized>
                </word>
                <word id="13" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="14" word="العالم">
                    <svm_prediction>
                        <morph_feature_set diac="العالَمِ" lemma="عالَمEAlam" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="العالَمِ" lemma="عالَم_1" gloss="world" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عالَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العالم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EAlm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العالم" form1="العالم" form2="عالَم" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عالم"/>
                    </tokenized>
                </word>
                <word id="15" word="وعلمته">
                    <svm_prediction>
                        <morph_feature_set diac="وَعَلِمَتْهُ" lemma="عَلِمEalim" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="1" asp="na" vox="a" mod="i" gen="m" num="s" stt="c" cas="na" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7164229936284455">
                        <morph_feature_set diac="وَعُلْمَته" lemma="عُلْمَة_1" gloss="harelip" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="u" enc0="3ms_poss" stem="عُلْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="علمة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Elmp" form1="NOUN+NSUFF_FEM_SG"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="علمة" form1="علمة" form2="عُلْمَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="علمة"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="16" word="درسا">
                    <svm_prediction>
                        <morph_feature_set diac="دَرْساً" lemma="دَرْسdaros" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8466083621389496">
                        <morph_feature_set diac="دَرْساً" lemma="دَرْس_1" gloss="lesson;study" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="دَرْس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="درسا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="drsA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="درسا" form1="درسا" form2="دَرْس" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="درسا"/>
                    </tokenized>
                </word>
                <word id="17" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="18" word="ضرورة">
                    <svm_prediction>
                        <morph_feature_set diac="ضَرُورَةِ" lemma="ضَرُورَةDaruwrap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="ضَرُورَةِ" lemma="ضَرُورَة_1" gloss="necessity;need;imperative" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="ضَرُور"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ضرورة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Drwrp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ضرورة" form1="ضرورة" form2="ضَرُورَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ضرورة"/>
                    </tokenized>
                </word>
                <word id="19" word="احترام">
                    <svm_prediction>
                        <morph_feature_set diac="اِحْتِرامِ" lemma="ٱِحْتِرام{iHotirAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="اِحْتِرامِ" lemma="ٱِحْتِرام_1" gloss="respect;honoring" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِحْتِرام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="احترام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AHtrAm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="احترام" form1="احترام" form2="ٱِحْتِرام" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="احترام"/>
                    </tokenized>
                </word>
                <word id="20" word="مؤسسات">
                    <svm_prediction>
                        <morph_feature_set diac="مُؤَسَّساتِ" lemma="مُؤَسَّسَةmu&amp;as~asap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941664645259818">
                        <morph_feature_set diac="مُؤَسَّساتِ" lemma="مُؤَسَّسَة_1" gloss="institutions;organizations" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="0" stem="مُؤَسَّس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مؤسسات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="m&amp;ssAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مؤسسات" form1="مؤسسات" form2="مُؤَسَّسَة" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مؤسسات"/>
                    </tokenized>
                </word>
                <word id="21" word="الدولة">
                    <svm_prediction>
                        <morph_feature_set diac="الدَّوْلَةِ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الدَّوْلَةِ" lemma="دَوْلَة_1" gloss="state;country" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="دَوْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدولة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwlp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدولة" form1="الدولة" form2="دَوْلَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دولة"/>
                    </tokenized>
                </word>
                <word id="22" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="23" word="والقضائية">
                    <svm_prediction>
                        <morph_feature_set diac="وَالقَضائِيَّةِ" lemma="قَضائِيّqaDA}iy~" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89402085509488">
                        <morph_feature_set diac="وَالقَضائِيَّةِ" lemma="قَضائِيّ_1" gloss="judicial;legal" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="قَضائِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="القضائية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="qDA}yp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="القضائية" form1="القضائية" form2="قَضائِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="قضائية"/>
                    </tokenized>
                </word>
                <word id="24" word="منها">
                    <svm_prediction>
                        <morph_feature_set diac="مِنها" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مِنها" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
                <word id="25" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="26" word="وجه">
                    <svm_prediction>
                        <morph_feature_set diac="وَجْهِ" lemma="وَجْهwajoh" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="وَجْهِ" lemma="وَجْه_1" gloss="face;front" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="وَجْه"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="وجه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="wjh" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="وجه" form1="وجه" form2="وَجْه" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="وجه"/>
                    </tokenized>
                </word>
                <word id="27" word="الخصوص">
                    <svm_prediction>
                        <morph_feature_set diac="الخُصُوصِ" lemma="خُصُوصxuSuwS" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الخُصُوصِ" lemma="خُصُوص_1" gloss="matter;issue;regard;respect" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="خُصُوص"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الخصوص"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="xSwS" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الخصوص" form1="الخصوص" form2="خُصُوص" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="خصوص"/>
                    </tokenized>
                </word>
                <word id="28" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="29" word="فإن">
                    <svm_prediction>
                        <morph_feature_set diac="فَإِنَّ" lemma="أَنَّ&gt;an~a" pos="verb_pseudo" prc3="0" prc2="fa_conn" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8151891147104919">
                        <morph_feature_set diac="فَإِنَّ" lemma="إِنَّ_1" gloss="that;indeed" pos="verb_pseudo" prc3="0" prc2="fa_conj" prc1="0" prc0="na" per="na" asp="i" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="f+" form1="CONJ+"/>
                        <tok id="1" form0="An" form1="PSEUDO_VERB"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ف+" form1="ف+" form2="فَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="إن" form1="ان" form2="إِنَّ" form3="PRT" form4="AN" form5="PSEUDO_VERB"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                </word>
                <word id="30" word="هذه">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذا_1" gloss="this;these" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="هٰذِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*h" form1="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذه" form1="هذه" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                </word>
                <word id="31" word="المحكمة">
                    <svm_prediction>
                        <morph_feature_set diac="المَحْكَمَةِ" lemma="مَحْكَمَةmaHokamap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840385512557991">
                        <morph_feature_set diac="المَحْكَمَةُ" lemma="مَحْكَمَة_1" gloss="court;tribunal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="n" enc0="0" stem="مَحْكَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المحكمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mHkmp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المحكمة" form1="المحكمة" form2="مَحْكَمَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="محكمة"/>
                    </tokenized>
                </word>
                <word id="32" word="التي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8945079933398044">
                        <morph_feature_set diac="الَّتِي" lemma="الَّذِي_1" gloss="which;who;whom_[fem.sg.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="الَّتِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Alty" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التي" form1="التي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التي"/>
                    </tokenized>
                </word>
                <word id="33" word="نصت">
                    <svm_prediction>
                        <morph_feature_set diac="نَصَّت" lemma="نَصّnaS~" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8948497252865323">
                        <morph_feature_set diac="نَصَّت" lemma="نَصّ-ُ_1" gloss="stipulate;specify" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0" stem="نَصّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نصت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nSt" form1="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نصت" form1="نصت" form2="نَصّ" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نصت"/>
                    </tokenized>
                </word>
                <word id="34" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="35" word="فتوى">
                    <svm_prediction>
                        <morph_feature_set diac="فَتْوَى" lemma="فَتْوَىfatowaY" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944319152280099">
                        <morph_feature_set diac="فَتْوَى" lemma="فَتْوَى_1" gloss="fatwa;legal_opinion" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="فَتْوَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="فتوي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ftwy" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="فتوى" form1="فتوي" form2="فَتْوَى" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="فتوي"/>
                    </tokenized>
                </word>
                <word id="36" word="قضائية">
                    <svm_prediction>
                        <morph_feature_set diac="قَضائِيَّةٍ" lemma="قَضائِيّqaDA}iy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8838763768027637">
                        <morph_feature_set diac="قَضائِيَّةٌ" lemma="قَضائِيّ_1" gloss="judicial;legal" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="قَضائِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قضائية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qDA}yp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قضائية" form1="قضائية" form2="قَضائِيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قضائية"/>
                    </tokenized>
                </word>
                <word id="37" word="ملزمة">
                    <svm_prediction>
                        <morph_feature_set diac="مُلْزَمَةً" lemma="مُلْزَمmulozam" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8838763768027637">
                        <morph_feature_set diac="مُلْزَمَةٌ" lemma="مُلْزَم_1" gloss="obligated;liable" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="n" enc0="0" stem="مُلْزَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ملزمة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mlzmp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ملزمة" form1="ملزمة" form2="مُلْزَم" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ملزمة"/>
                    </tokenized>
                </word>
                <word id="38" word="بإلغاء">
                    <svm_prediction>
                        <morph_feature_set diac="بِإِلْغاءِ" lemma="إِلْغاء&lt;ilogA'" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِإِلْغاءِ" lemma="إِلْغاء_1" gloss="cancellation;abrogation;repeal" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="إِلْغاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="الغاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="AlgA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="إلغاء" form1="الغاء" form2="إِلْغاء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="الغاء"/>
                    </tokenized>
                </word>
                <word id="39" word="العمل">
                    <svm_prediction>
                        <morph_feature_set diac="العَمَلِ" lemma="عَمَلEamal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="العَمَلِ" lemma="عَمَل_1" gloss="work;action" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عَمَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العمل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Eml" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العمل" form1="العمل" form2="عَمَل" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عمل"/>
                    </tokenized>
                </word>
                <word id="40" word="بالقانون">
                    <svm_prediction>
                        <morph_feature_set diac="بِالقانُونِ" lemma="قانُونqAnuwn" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941697366852527">
                        <morph_feature_set diac="بِالقانُونِ" lemma="قانُون_1" gloss="law;statutes;regulations" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="قانُون"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="القانون"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="qAnwn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="القانون" form1="القانون" form2="قانُون" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="قانون"/>
                    </tokenized>
                </word>
                <word id="41" word="الذي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِي_1" gloss="which;who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="الَّذِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*y" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذي" form1="الذي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                </word>
                <word id="42" word="أصدره">
                    <svm_prediction>
                        <morph_feature_set diac="أَصْدَرَهُ" lemma="أَصْدَر&gt;aSodar" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="3ms_dobj"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939836345488741">
                        <morph_feature_set diac="أَصْدَرَهُ" lemma="أَصْدَر_1" gloss="issue;publish" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="3ms_dobj" stem="أَصْدَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اصدر"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ASdr" form1="PV+PVSUFF_SUBJ:3MS"/>
                        <tok id="1" form0="+h" form1="+PVSUFF_DO:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أصدر" form1="اصدر" form2="أَصْدَر" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP" form5="+PVSUFF_DO:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اصدر"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="43" word="هذا">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذا" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذا" lemma="هٰذا_1" gloss="this" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="هٰذا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*A" form1="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذا" form1="هذا" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذا"/>
                    </tokenized>
                </word>
                <word id="44" word="الرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="الرَّئِيسِ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8847645546831359">
                        <morph_feature_set diac="الرَّئِيسُ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="r}ys" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="45" word="العنصري">
                    <svm_prediction>
                        <morph_feature_set diac="العُنْصُرِيِّ" lemma="عُنْصُرِيّEunoSuriy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840023527847742">
                        <morph_feature_set diac="العُنْصُرِيَّ" lemma="عُنْصُرِيّ_1" gloss="racial;ethnic" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="عُنْصُرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العنصري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EnSry" form1="ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العنصري" form1="العنصري" form2="عُنْصُرِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عنصري"/>
                    </tokenized>
                </word>
                <word id="46" word="الجاهل">
                    <svm_prediction>
                        <morph_feature_set diac="الجاهِلِ" lemma="جاهِلjAhil" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840023527847742">
                        <morph_feature_set diac="الجاهِلَ" lemma="جاهِل_1" gloss="ignorant;foolish" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="جاهِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجاهل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jAhl" form1="ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجاهل" form1="الجاهل" form2="جاهِل" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جاهل"/>
                    </tokenized>
                </word>
                <word id="47" word="ويمنع">
                    <svm_prediction>
                        <morph_feature_set diac="وَيَمْنَع" lemma="مَنَعmanaE" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="i" vox="p" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8447463437475393">
                        <morph_feature_set diac="وَيَمْنَع" lemma="مَنَع_1" gloss="prevent;forbid" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="مْنَع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="يمنع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="ymnE" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="يمنع" form1="يمنع" form2="مَنَع" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="يمنع"/>
                    </tokenized>
                </word>
                <word id="48" word="دخول">
                    <svm_prediction>
                        <morph_feature_set diac="دُخُولِ" lemma="دُخُولduxuwl" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8866756788017508">
                        <morph_feature_set diac="دُخُولَ" lemma="دُخُول_1" gloss="entrance;penetration" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="دُخُول"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دخول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dxwl" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دخول" form1="دخول" form2="دُخُول" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دخول"/>
                    </tokenized>
                </word>
                <word id="49" word="مواطنين">
                    <svm_prediction>
                        <morph_feature_set diac="مُواطِنِينَ" lemma="مُواطِنmuwATin" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939235092661292">
                        <morph_feature_set diac="مُواطِنِينَ" lemma="مُواطِن_1" gloss="citizen" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="a" enc0="0" stem="مُواطِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مواطنين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mwATnyn" form1="NOUN+NSUFF_MASC_PL_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مواطنين" form1="مواطنين" form2="مُواطِن" form3="NOM" form4="NNS" form5="NOUN+NSUFF_MASC_PL_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مواطنين"/>
                    </tokenized>
                </word>
                <word id="50" word="مسلمين">
                    <svm_prediction>
                        <morph_feature_set diac="مُسْلِمِينَ" lemma="مُسْلِمmusolim" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939498907769442">
                        <morph_feature_set diac="مُسْلِمِينَ" lemma="مُسْلِم_1" gloss="Muslim" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="a" enc0="0" stem="مُسْلِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مسلمين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mslmyn" form1="ADJ+NSUFF_MASC_PL_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مسلمين" form1="مسلمين" form2="مُسْلِم" form3="NOM" form4="JJ+#S" form5="ADJ+NSUFF_MASC_PL_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مسلمين"/>
                    </tokenized>
                </word>
                <word id="51" word="يحملون">
                    <svm_prediction>
                        <morph_feature_set diac="يَحْمِلُونَ" lemma="حَمَلHamal" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940588935625101">
                        <morph_feature_set diac="يَحْمِلُونَ" lemma="حَمَل-ِ_1" gloss="carry;bear;transport" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="حْمِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يحملون"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yHmlwn" form1="IV3MP+IV+IVSUFF_SUBJ:MP_MOOD:I"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يحملون" form1="يحملون" form2="حَمَل" form3="VRB" form4="VBP" form5="IV3MP+IV+IVSUFF_SUBJ:MP_MOOD:I"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يحملون"/>
                    </tokenized>
                </word>
                <word id="52" word="تأشيرات">
                    <svm_prediction>
                        <morph_feature_set diac="تَأْشِيراتٍ" lemma="تَأْشِيرta&gt;o$iyr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942151375906264">
                        <morph_feature_set diac="تَأْشِيراتٍ" lemma="تَأْشِير_1" gloss="visa;mark" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0" stem="تَأْشِير"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تاشيرات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tA$yrAt" form1="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تأشيرات" form1="تاشيرات" form2="تَأْشِير" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تاشيرات"/>
                    </tokenized>
                </word>
                <word id="53" word="رسمية">
                    <svm_prediction>
                        <morph_feature_set diac="رَسْمِيَّةٍ" lemma="رَسْمِيّrasomiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.883969018457233">
                        <morph_feature_set diac="رَسْمِيَّةً" lemma="رَسْمِيّ_1" gloss="official" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="a" enc0="0" stem="رَسْمِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رسمية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="rsmyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رسمية" form1="رسمية" form2="رَسْمِيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رسمية"/>
                    </tokenized>
                </word>
                <word id="54" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="55" word="أظهرت">
                    <svm_prediction>
                        <morph_feature_set diac="أَظْهَرَت" lemma="أَظْهَر&gt;aZohar" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8948497252865323">
                        <morph_feature_set diac="أَظْهَرَت" lemma="أَظْهَر_1" gloss="show;manifest;demonstrate" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0" stem="أَظْهَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اظهرت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AZhrt" form1="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أظهرت" form1="اظهرت" form2="أَظْهَر" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اظهرت"/>
                    </tokenized>
                </word>
                <word id="56" word="بعض">
                    <svm_prediction>
                        <morph_feature_set diac="بَعْضِ" lemma="بَعْضbaEoD" pos="noun_quant" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8142044061903386">
                        <morph_feature_set diac="بَعْضَ" lemma="بَعْض_1" gloss="some;several" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="بَعْض"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بعض"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bED" form1="ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بعض" form1="بعض" form2="بَعْض" form3="NOM" form4="JJ" form5="ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بعض"/>
                    </tokenized>
                </word>
                <word id="57" word="الجوانب">
                    <svm_prediction>
                        <morph_feature_set diac="الجَوانِبِ" lemma="جانِبjAnib" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الجَوانِبِ" lemma="جانِب_1" gloss="sides;aspects" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="جَوانِب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الجوانب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="jwAnb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الجوانب" form1="الجوانب" form2="جانِب" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="جوانب"/>
                    </tokenized>
                </word>
                <word id="58" word="المضيئة">
                    <svm_prediction>
                        <morph_feature_set diac="المُضِيئَةِ" lemma="مُضِيءmuDiy'" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8265346650184467">
                        <morph_feature_set diac="المُضِيئَةِ" lemma="مُضِيء_1" gloss="shining;bright" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مُضِيئ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المضيئة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mDy}p" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المضيئة" form1="المضيئة" form2="مُضِيء" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مضيئة"/>
                    </tokenized>
                </word>
                <word id="59" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="60" word="النظام">
                    <svm_prediction>
                        <morph_feature_set diac="النِّظامَ" lemma="نِظامniZAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8889183115798678">
                        <morph_feature_set diac="النِّظامِ" lemma="نِظام_1" gloss="regime;government" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="نِظام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="النظام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="nZAm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="النظام" form1="النظام" form2="نِظام" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نظام"/>
                    </tokenized>
                </word>
                <word id="61" word="الأمريكي">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْرِيكِيَّ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="الأَمْرِيكِيِّ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامريكي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amryky" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمريكي" form1="الامريكي" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكي"/>
                    </tokenized>
                </word>
                <word id="62" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="63" word="وعززت">
                    <svm_prediction>
                        <morph_feature_set diac="وَعَزَّزَت" lemma="عَزَّزEaz~az" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942963273173549">
                        <morph_feature_set diac="وَعَزَّزَت" lemma="عَزَّز_1" gloss="strengthen;reinforce" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0" stem="عَزَّز"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="عززت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Ezzt" form1="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="عززت" form1="عززت" form2="عَزَّز" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="عززت"/>
                    </tokenized>
                </word>
                <word id="64" word="مكانة">
                    <svm_prediction>
                        <morph_feature_set diac="مَكانَهُ" lemma="مَكانmakAn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8678620411306026">
                        <morph_feature_set diac="مَكانَةَ" lemma="مَكانَة_1" gloss="position;standing" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0" stem="مَكان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مكانة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mkAnp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مكانة" form1="مكانة" form2="مَكانَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مكانة"/>
                    </tokenized>
                </word>
                <word id="65" word="المؤسسات">
                    <svm_prediction>
                        <morph_feature_set diac="المُؤَسَّساتِ" lemma="مُؤَسَّسَةmu&amp;as~asap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8947650584943242">
                        <morph_feature_set diac="المُؤَسَّساتِ" lemma="مُؤَسَّسَة_1" gloss="institutions;organizations" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0" stem="مُؤَسَّس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المؤسسات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="m&amp;ssAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المؤسسات" form1="المؤسسات" form2="مُؤَسَّسَة" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مؤسسات"/>
                    </tokenized>
                </word>
                <word id="66" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="67" word="وفرضت">
                    <svm_prediction>
                        <morph_feature_set diac="وَفَرَضَت" lemma="فَرَضfaraD" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="p" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836150154809782">
                        <morph_feature_set diac="وَفُرِضَت" lemma="فَرَض_1" gloss="be_imposed" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="p" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0" stem="فُرِض"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="فرضت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="frDt" form1="PV_PASS+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="فرضت" form1="فرضت" form2="فَرَض" form3="VRB-PASS" form4="VBN" form5="PV_PASS+PVSUFF_SUBJ:3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="فرضت"/>
                    </tokenized>
                </word>
                <word id="68" word="احترام">
                    <svm_prediction>
                        <morph_feature_set diac="اِحْتِرامِ" lemma="ٱِحْتِرام{iHotirAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8845614767239923">
                        <morph_feature_set diac="اِحْتِرامُ" lemma="ٱِحْتِرام_1" gloss="respect;honoring" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="0" stem="ٱِحْتِرام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="احترام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AHtrAm" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="احترام" form1="احترام" form2="ٱِحْتِرام" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="احترام"/>
                    </tokenized>
                </word>
                <word id="69" word="الدستور">
                    <svm_prediction>
                        <morph_feature_set diac="الدُّسْتُورِ" lemma="دُسْتُورdusotuwr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الدُّسْتُورِ" lemma="دُسْتُور_1" gloss="constitution;statute" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="دُسْتُور"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدستور"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dstwr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدستور" form1="الدستور" form2="دُسْتُور" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دستور"/>
                    </tokenized>
                </word>
                <word id="70" word="ونصوصه">
                    <svm_prediction>
                        <morph_feature_set diac="وَنُصُوصِهِ" lemma="نَصّnaS~" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939498907769442">
                        <morph_feature_set diac="وَنُصُوصِهِ" lemma="نَصّ_1" gloss="texts" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="نُصُوص"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="نصوص"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="nSwS" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="نصوص" form1="نصوص" form2="نَصّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="نصوص"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="71" word="وروحه">
                    <svm_prediction>
                        <morph_feature_set diac="وَرَوْحَةِ" lemma="رُوحruwH" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.805857685314144">
                        <morph_feature_set diac="وَرُوحِهِ" lemma="رُوح_1" gloss="spirit;soul" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="رُوح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="روح"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="rwH" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="روح" form1="روح" form2="رُوح" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="روح"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="72" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="73" word="والاحصائيات">
                    <svm_prediction>
                        <morph_feature_set diac="وَالإِحْصائِيّاتِ" lemma="إِحْصائِيّ&lt;iHoSA}iy~" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8241233798660121">
                        <morph_feature_set diac="وَالإِحْصائِيّاتِ" lemma="إِحْصائِيّ_2" gloss="statistician" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0" stem="إِحْصائِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الاحصائيات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="AHSA}yAt" form1="ADJ+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الإحصائيات" form1="الاحصائيات" form2="إِحْصائِيّ" form3="NOM" form4="DT+JJ+#S" form5="DET+ADJ+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="احصائيات"/>
                    </tokenized>
                </word>
                <word id="74" word="الامريكية">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْرِيكِيَّةِ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8267406702887713">
                        <morph_feature_set diac="الأَمْرِيكِيَّةِ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامريكية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amrykyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمريكية" form1="الامريكية" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكية"/>
                    </tokenized>
                </word>
                <word id="75" word="الرسمية">
                    <svm_prediction>
                        <morph_feature_set diac="الرَّسْمِيَّةِ" lemma="رَسْمِيّrasomiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="الرَّسْمِيَّةِ" lemma="رَسْمِيّ_1" gloss="official" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="رَسْمِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الرسمية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="rsmyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الرسمية" form1="الرسمية" form2="رَسْمِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رسمية"/>
                    </tokenized>
                </word>
                <word id="76" word="تؤكد">
                    <svm_prediction>
                        <morph_feature_set diac="تُؤَكَّد" lemma="أَكَّد&gt;ak~ad" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="تُؤَكِّد" lemma="أَكَّد_1" gloss="affirm;assure;confirm;guarantee" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="f" num="s" stt="na" cas="na" enc0="0" stem="ؤَكِّد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تؤكد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="t&amp;kd" form1="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تؤكد" form1="تؤكد" form2="أَكَّد" form3="VRB" form4="VBP" form5="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تؤكد"/>
                    </tokenized>
                </word>
                <word id="77" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8258625130148115">
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ_1" gloss="that" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="78" word="3">
                    <svm_prediction>
                        <morph_feature_set diac="8" lemma="88" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="3" lemma="3_0" gloss="3" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="3"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="3" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="3" form1="3" form2="3" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="3"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT10">
            <segment_info>
                <preprocessed>3 مليون مهاجر دخلوا الولايات المتحدة في الفترة من 1975 الى 2015 ولم يرتكب أحدا منهم اعمال إرهابية باستثناء 6 فقط , 3 منهم من المسلمين على مدى أربعين عاما</preprocessed>
                <bpc>
                    <chunk id="0" type="LST">
                        <tok id="0" form0="3"/>
                    </chunk>
                    <chunk id="1" type="NP">
                        <tok id="0" form0="مليون"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="مهاجر"/>
                    </chunk>
                    <chunk id="3" type="VP">
                        <tok id="0" form0="دخلوا"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ولايات"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="متحدة"/>
                    </chunk>
                    <chunk id="5" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فترة"/>
                    </chunk>
                    <chunk id="7" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="1975"/>
                    </chunk>
                    <chunk id="9" type="PP">
                        <tok id="0" form0="الي"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="2015"/>
                    </chunk>
                    <chunk id="11" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="12" type="VP">
                        <tok id="0" form0="لم"/>
                        <tok id="1" form0="يرتكب"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="احدا"/>
                    </chunk>
                    <chunk id="14" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="اعمال"/>
                        <tok id="1" form0="ارهابية"/>
                    </chunk>
                    <chunk id="17" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="استثناء"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="6"/>
                    </chunk>
                    <chunk id="20" type="ADVP">
                        <tok id="0" form0="فقط"/>
                    </chunk>
                    <chunk id="21" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="22" type="VP">
                        <tok id="0" form0="3"/>
                    </chunk>
                    <chunk id="23" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="24" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="25" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="26" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مسلمين"/>
                    </chunk>
                    <chunk id="27" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="28" type="VP">
                        <tok id="0" form0="مدي"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="اربعين"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="عاما"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="3"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="مليون"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="مهاجر"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="دخلوا"/>
                    </ne>
                    <ne id="4" type="LOC">
                        <tok id="4" form0="ال+"/>
                        <tok id="4" form0="ولايات"/>
                    </ne>
                    <ne id="5" type="LOC">
                        <tok id="5" form0="ال+"/>
                        <tok id="5" form0="متحدة"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="في"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="ال+"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="فترة"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="من"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="1975"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="الي"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="2015"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="و+"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="لم"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="يرتكب"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="احدا"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="من"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="+هم"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="اعمال"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ارهابية"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="ب+"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="استثناء"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="6"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="فقط"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0=","/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="3"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="من"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="+هم"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="من"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="ال+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="مسلمين"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="علي"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="مدي"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="اربعين"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="عاما"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="3">
                    <svm_prediction>
                        <morph_feature_set diac="8" lemma="88" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="3" lemma="3_0" gloss="3" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="3"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="3" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="3" form1="3" form2="3" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="3"/>
                    </tokenized>
                </word>
                <word id="1" word="مليون">
                    <svm_prediction>
                        <morph_feature_set diac="مِلْيُونَ" lemma="مِلْيُونmiloyuwn" pos="noun_num" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8179777763390218">
                        <morph_feature_set diac="مِلْيُونِ" lemma="مِلْيُون_1" gloss="million" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="مِلْيُون"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مليون"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mlywn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مليون" form1="مليون" form2="مِلْيُون" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مليون"/>
                    </tokenized>
                </word>
                <word id="2" word="مهاجر">
                    <svm_prediction>
                        <morph_feature_set diac="مُهاجِرٍ" lemma="مُهاجِرmuhAjir" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.895576339810859">
                        <morph_feature_set diac="مُهاجِرٍ" lemma="مُهاجِر_1" gloss="emigrant" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="مُهاجِر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مهاجر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mhAjr" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مهاجر" form1="مهاجر" form2="مُهاجِر" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مهاجر"/>
                    </tokenized>
                </word>
                <word id="3" word="دخلوا">
                    <svm_prediction>
                        <morph_feature_set diac="دَخَلُوا" lemma="دَخَلdaxal" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="دَخَلُوا" lemma="دَخَل-ُ_1" gloss="enter" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="دَخَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دخلوا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dxlwA" form1="PV+PVSUFF_SUBJ:3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دخلوا" form1="دخلوا" form2="دَخَل" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دخلوا"/>
                    </tokenized>
                </word>
                <word id="4" word="الولايات">
                    <svm_prediction>
                        <morph_feature_set diac="الوِلاياتِ" lemma="وِلايَةwilAyap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8947650584943242">
                        <morph_feature_set diac="الوِلاياتِ" lemma="وِلايَة_1" gloss="state;province" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="d" cas="g" enc0="0" stem="وِلاي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الولايات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="wlAyAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الولايات" form1="الولايات" form2="وِلايَة" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ولايات"/>
                    </tokenized>
                </word>
                <word id="5" word="المتحدة">
                    <svm_prediction>
                        <morph_feature_set diac="المُتَّحِدَةِ" lemma="مُتَّحِدmut~aHid" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="المُتَّحِدَةِ" lemma="مُتَّحِد_1" gloss="united" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مُتَّحِد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المتحدة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mtHdp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المتحدة" form1="المتحدة" form2="مُتَّحِد" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="متحدة"/>
                    </tokenized>
                </word>
                <word id="6" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="7" word="الفترة">
                    <svm_prediction>
                        <morph_feature_set diac="الفَتْرَةِ" lemma="فَتْرَةfatorap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8959534546335282">
                        <morph_feature_set diac="الفَتْرَةِ" lemma="فَتْرَة_1" gloss="phase;time_period;interval" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="فَتْر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الفترة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="ftrp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الفترة" form1="الفترة" form2="فَتْرَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فترة"/>
                    </tokenized>
                </word>
                <word id="8" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="9" word="1975">
                    <svm_prediction>
                        <morph_feature_set diac="8888" lemma="88888888" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="1975" lemma="1975_0" gloss="1975" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="1975"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="1975" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="1975" form1="1975" form2="1975" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="1975"/>
                    </tokenized>
                </word>
                <word id="10" word="الى">
                    <svm_prediction>
                        <morph_feature_set diac="إِلَى" lemma="إِلَى&lt;ilaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8331090354286067">
                        <morph_feature_set diac="إِلَى" lemma="إِلَى_1" gloss="to;towards" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="إِلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aly" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إلى" form1="الي" form2="إِلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الي"/>
                    </tokenized>
                </word>
                <word id="11" word="2015">
                    <svm_prediction>
                        <morph_feature_set diac="8888" lemma="88888888" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="2015" lemma="2015_0" gloss="2015" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="2015"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="2015" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="2015" form1="2015" form2="2015" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="2015"/>
                    </tokenized>
                </word>
                <word id="12" word="ولم">
                    <svm_prediction>
                        <morph_feature_set diac="وَلِمَ" lemma="لَمّlam~" pos="part_neg" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8676338102721451">
                        <morph_feature_set diac="وَلَم" lemma="لَم_1" gloss="not" pos="part_neg" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="lm" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="لم" form1="لم" form2="لَم" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="لم"/>
                    </tokenized>
                </word>
                <word id="13" word="يرتكب">
                    <svm_prediction>
                        <morph_feature_set diac="يُرْتَكَب" lemma="ٱِرْتَكَب{irotakab" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="j" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يَرْتَكِب" lemma="ٱِرْتَكَب_1" gloss="commit;perpetrate" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="رْتَكِب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يرتكب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yrtkb" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يرتكب" form1="يرتكب" form2="ٱِرْتَكَب" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يرتكب"/>
                    </tokenized>
                </word>
                <word id="14" word="أحدا">
                    <svm_prediction>
                        <morph_feature_set diac="أَحَداً" lemma="أَحَد&gt;aHad" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8951072017397583">
                        <morph_feature_set diac="أَحَداً" lemma="أَحَد_1" gloss="one;someone" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="أَحَد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="احدا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AHdA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أحدا" form1="احدا" form2="أَحَد" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="احدا"/>
                    </tokenized>
                </word>
                <word id="15" word="منهم">
                    <svm_prediction>
                        <morph_feature_set diac="مِنهُم" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3mp_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مِنهُم" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3mp_pron" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                        <tok id="1" form0="+hm" form1="+PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP" form5="+PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="16" word="اعمال">
                    <svm_prediction>
                        <morph_feature_set diac="أَعْمالٍ" lemma="عَمَلEamal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7772978215885818">
                        <morph_feature_set diac="أَعْمالٍ" lemma="عَمَل_1" gloss="actions;activities;work" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="أَعْمال"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اعمال"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AEmAl" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أعمال" form1="اعمال" form2="عَمَل" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اعمال"/>
                    </tokenized>
                </word>
                <word id="17" word="إرهابية">
                    <svm_prediction>
                        <morph_feature_set diac="إِرْهابِيَّةٍ" lemma="إِرْهابِيّ&lt;irohAbiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946499216717394">
                        <morph_feature_set diac="إِرْهابِيَّةٍ" lemma="إِرْهابِيّ_1" gloss="terrorist" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="إِرْهابِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ارهابية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ArhAbyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="إرهابية" form1="ارهابية" form2="إِرْهابِيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ارهابية"/>
                    </tokenized>
                </word>
                <word id="18" word="باستثناء">
                    <svm_prediction>
                        <morph_feature_set diac="بِاِسْتِثْناءِ" lemma="ٱِسْتِثْناء{isotivonA'" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِاِسْتِثْناءِ" lemma="ٱِسْتِثْناء_1" gloss="exception;exclusion" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِسْتِثْناء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="استثناء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="AstvnA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="استثناء" form1="استثناء" form2="ٱِسْتِثْناء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="استثناء"/>
                    </tokenized>
                </word>
                <word id="19" word="6">
                    <svm_prediction>
                        <morph_feature_set diac="8" lemma="88" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="6" lemma="6_0" gloss="6" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="6"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="6" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="6" form1="6" form2="6" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="6"/>
                    </tokenized>
                </word>
                <word id="20" word="فقط">
                    <svm_prediction>
                        <morph_feature_set diac="فَقَط" lemma="فَقَطfaqaT" pos="adv" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941603296133013">
                        <morph_feature_set diac="فَقَط" lemma="فَقَط_1" gloss="only" pos="adv" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="فَقَط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="فقط"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fqT" form1="ADV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="فقط" form1="فقط" form2="فَقَط" form3="NOM" form4="RB" form5="ADV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="فقط"/>
                    </tokenized>
                </word>
                <word id="21" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="22" word="3">
                    <svm_prediction>
                        <morph_feature_set diac="8" lemma="88" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="3" lemma="3_0" gloss="3" pos="digit" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="3"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="3" form1="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="3" form1="3" form2="3" form3="NOM" form4="NN" form5="NOUN_NUM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="3"/>
                    </tokenized>
                </word>
                <word id="23" word="منهم">
                    <svm_prediction>
                        <morph_feature_set diac="مِنهُم" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3mp_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مِنهُم" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3mp_pron" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                        <tok id="1" form0="+hm" form1="+PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP" form5="+PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="24" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="25" word="المسلمين">
                    <svm_prediction>
                        <morph_feature_set diac="المُسْلِمِينَ" lemma="مُسْلِمmusolim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894230475774278">
                        <morph_feature_set diac="المُسْلِمِينَ" lemma="مُسْلِم_1" gloss="Muslim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0" stem="مُسْلِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المسلمين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mslmyn" form1="NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المسلمين" form1="المسلمين" form2="مُسْلِم" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مسلمين"/>
                    </tokenized>
                </word>
                <word id="26" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="27" word="مدى">
                    <svm_prediction>
                        <morph_feature_set diac="مَدَى" lemma="مَدَىmadaY" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944319152280099">
                        <morph_feature_set diac="مَدَى" lemma="مَدَى_1" gloss="extent;range" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="مَدَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مدي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mdy" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مدى" form1="مدي" form2="مَدَى" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مدي"/>
                    </tokenized>
                </word>
                <word id="28" word="أربعين">
                    <svm_prediction>
                        <morph_feature_set diac="أَرْبَعِينَ" lemma="أَرْبَع&gt;arobaE" pos="noun_num" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8245339642242379">
                        <morph_feature_set diac="أَرْبَعِينَ" lemma="أَرْبَع_1" gloss="forty;fortieth" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="g" enc0="0" stem="أَرْبَع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اربعين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ArbEyn" form1="NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أربعين" form1="اربعين" form2="أَرْبَع" form3="NOM" form4="NNS" form5="NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اربعين"/>
                    </tokenized>
                </word>
                <word id="29" word="عاما">
                    <svm_prediction>
                        <morph_feature_set diac="عاماً" lemma="عامEAm" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8951072017397583">
                        <morph_feature_set diac="عاماً" lemma="عام_1" gloss="year" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="0" stem="عام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عاما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EAmA" form1="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عاما" form1="عاما" form2="عام" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عاما"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT11">
            <segment_info>
                <preprocessed>ترامب كان يتصرف كتاجر , وحاكم عربي , وربما تعلم هذه الخصلة من أصدقائه من التجار العرب , او بالأحرى الحكام التجار الذين يجمع بعضهم بين الحكم والتجارة , سواء بصورة علنية , او من خلال شبكة أبنائهم وبناتهم واصهارهم , وما اكثرهم في بلداننا</preprocessed>
                <bpc>
                    <chunk id="0" type="NP">
                        <tok id="0" form0="ترامب"/>
                    </chunk>
                    <chunk id="1" type="VP">
                        <tok id="0" form0="كان"/>
                    </chunk>
                    <chunk id="2" type="VP">
                        <tok id="0" form0="يتصرف"/>
                    </chunk>
                    <chunk id="3" type="PP">
                        <tok id="0" form0="ك+"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="تاجر"/>
                    </chunk>
                    <chunk id="5" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="6" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="7" type="NP">
                        <tok id="0" form0="حاكم"/>
                        <tok id="1" form0="عربي"/>
                    </chunk>
                    <chunk id="8" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="9" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="10" type="ADVP">
                        <tok id="0" form0="ربما"/>
                    </chunk>
                    <chunk id="11" type="">
                        <tok id="0" form0="تعلم"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="هذه"/>
                    </chunk>
                    <chunk id="13" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="خصلة"/>
                    </chunk>
                    <chunk id="14" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="15" type="NP">
                        <tok id="0" form0="@@اصدقائه@@"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="17" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="تجار"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عرب"/>
                    </chunk>
                    <chunk id="20" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="21" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="22" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="احري"/>
                    </chunk>
                    <chunk id="24" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حكام"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="تجار"/>
                    </chunk>
                    <chunk id="26" type="WHNP">
                        <tok id="0" form0="الذين"/>
                    </chunk>
                    <chunk id="27" type="VP">
                        <tok id="0" form0="يجمع"/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="بعض"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="بين"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حكم"/>
                    </chunk>
                    <chunk id="32" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="33" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="تجارة"/>
                    </chunk>
                    <chunk id="34" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="سواء"/>
                    </chunk>
                    <chunk id="36" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="37" type="NP">
                        <tok id="0" form0="صورة"/>
                        <tok id="1" form0="علنية"/>
                    </chunk>
                    <chunk id="38" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="39" type="">
                        <tok id="0" form0="او"/>
                    </chunk>
                    <chunk id="40" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="41" type="NP">
                        <tok id="0" form0="خلال"/>
                    </chunk>
                    <chunk id="42" type="NP">
                        <tok id="0" form0="شبكة"/>
                    </chunk>
                    <chunk id="43" type="NP">
                        <tok id="0" form0="ابناء"/>
                    </chunk>
                    <chunk id="44" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="45" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="46" type="NP">
                        <tok id="0" form0="بنات"/>
                    </chunk>
                    <chunk id="47" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="48" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="49" type="NP">
                        <tok id="0" form0="اصهار"/>
                    </chunk>
                    <chunk id="50" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="51" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="52" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="53" type="WHNP">
                        <tok id="0" form0="ما"/>
                    </chunk>
                    <chunk id="54" type="ADJP">
                        <tok id="0" form0="اكثر"/>
                    </chunk>
                    <chunk id="55" type="NP">
                        <tok id="0" form0="+هم"/>
                    </chunk>
                    <chunk id="56" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="57" type="NP">
                        <tok id="0" form0="بلدان"/>
                    </chunk>
                    <chunk id="58" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="ترامب"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="كان"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="يتصرف"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="ك+"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="تاجر"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0=","/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="و+"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="حاكم"/>
                    </ne>
                    <ne id="8" type="PER">
                        <tok id="8" form0="عربي"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0=","/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="و+"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="ربما"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="تعلم"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="هذه"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="ال+"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="خصلة"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="من"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="@@اصدقائه@@"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="+ه"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="من"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ال+"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="تجار"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="ال+"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="عرب"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0=","/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="او"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="ب+"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ال+"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="احري"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="ال+"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="حكام"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="ال+"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="تجار"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="الذين"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="يجمع"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0="بعض"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="+هم"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="بين"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="ال+"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="حكم"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="و+"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="ال+"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="تجارة"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0=","/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="سواء"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="ب+"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="صورة"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="علنية"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0=","/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="او"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="من"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="خلال"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="شبكة"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="ابناء"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="+هم"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="و+"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="بنات"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="+هم"/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="و+"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="اصهار"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="+هم"/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0=","/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="و+"/>
                    </ne>
                    <ne id="63" type="">
                        <tok id="63" form0="ما"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0="اكثر"/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0="+هم"/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="في"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0="بلدان"/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="+نا"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="ترامب">
                    <svm_prediction>
                        <morph_feature_set diac="ترامب" lemma="ترامبtrAmb" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ترامب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="trAmb" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ترامب" form1="ترامب" form2="ترامب" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ترامب"/>
                    </tokenized>
                </word>
                <word id="1" word="كان">
                    <svm_prediction>
                        <morph_feature_set diac="كانَ" lemma="كانkAn" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="كانَ" lemma="كان_1" gloss="was;were" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="كان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="kAn" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كان" form1="كان" form2="كان" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كان"/>
                    </tokenized>
                </word>
                <word id="2" word="يتصرف">
                    <svm_prediction>
                        <morph_feature_set diac="يَتَصَرَّف" lemma="تَصَرَّفtaSar~af" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="يَتَصَرَّف" lemma="تَصَرَّف_1" gloss="behave" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="تَصَرَّف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يتصرف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ytSrf" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يتصرف" form1="يتصرف" form2="تَصَرَّف" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يتصرف"/>
                    </tokenized>
                </word>
                <word id="3" word="كتاجر">
                    <svm_prediction>
                        <morph_feature_set diac="كَتاجِر" lemma="تاجِرtAjir" pos="noun" prc3="0" prc2="0" prc1="ka_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89390080890063">
                        <morph_feature_set diac="كَتاجِر" lemma="تاجِر_1" gloss="merchant;businessman" pos="noun" prc3="0" prc2="0" prc1="ka_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="تاجِر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ك+"/>
                        <tok id="1" form0="تاجر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="k+" form1="PREP+"/>
                        <tok id="1" form0="tAjr" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ك+" form1="ك+" form2="كَ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="تاجر" form1="تاجر" form2="تاجِر" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ك+"/>
                        <tok id="1" form0="تاجر"/>
                    </tokenized>
                </word>
                <word id="4" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="5" word="وحاكم">
                    <svm_prediction>
                        <morph_feature_set diac="وَحاكِمَ" lemma="حاكِمHAkim" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839041898835232">
                        <morph_feature_set diac="وَحاكِمِ" lemma="حاكِم_2" gloss="ruler;governor" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="حاكِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="حاكم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="HAkm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="حاكم" form1="حاكم" form2="حاكِم" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="حاكم"/>
                    </tokenized>
                </word>
                <word id="6" word="عربي">
                    <svm_prediction>
                        <morph_feature_set diac="عَرَبِيٍّ" lemma="عَرَبِيّEarabiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894442345679612">
                        <morph_feature_set diac="عَرَبِيٍّ" lemma="عَرَبِيّ_1" gloss="Arabic;Arab" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="عَرَبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عربي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Erby" form1="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عربي" form1="عربي" form2="عَرَبِيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عربي"/>
                    </tokenized>
                </word>
                <word id="7" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="8" word="وربما">
                    <svm_prediction>
                        <morph_feature_set diac="وَرُبَّما" lemma="رُبَّماrub~amA" pos="adv" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939318940820722">
                        <morph_feature_set diac="وَرُبَّما" lemma="رُبَّما_1" gloss="perhaps;maybe" pos="adv" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="رُبَّما"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ربما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="rbmA" form1="ADV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="ربما" form1="ربما" form2="رُبَّما" form3="NOM" form4="RB" form5="ADV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ربما"/>
                    </tokenized>
                </word>
                <word id="9" word="تعلم">
                    <svm_prediction>
                        <morph_feature_set diac="تَعَلُّمِ" lemma="عَلِمEalim" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="f" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="تَعْلَم" lemma="عَلِم-َ_1" gloss="know;find_out" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="f" num="s" stt="na" cas="na" enc0="0" stem="عْلَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="تعلم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="tElm" form1="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="تعلم" form1="تعلم" form2="عَلِم" form3="VRB" form4="VBP" form5="IV3FS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="تعلم"/>
                    </tokenized>
                </word>
                <word id="10" word="هذه">
                    <svm_prediction>
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذاh`*A" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="هٰذِهِ" lemma="هٰذا_1" gloss="this;these" pos="pron_dem" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="u" enc0="0" stem="هٰذِهِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="h*h" form1="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="هذه" form1="هذه" form2="هٰذا" form3="NOM" form4="DEM" form5="DEM_PRON_F"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="هذه"/>
                    </tokenized>
                </word>
                <word id="11" word="الخصلة">
                    <svm_prediction>
                        <morph_feature_set diac="الخُصْلَة" lemma="خُصْلَةxuSolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8856549817245463">
                        <morph_feature_set diac="الخُصْلَةِ" lemma="خُصْلَة_1" gloss="bunch;cluster" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="خُصْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الخصلة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="xSlp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الخصلة" form1="الخصلة" form2="خُصْلَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="خصلة"/>
                    </tokenized>
                </word>
                <word id="12" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="13" word="أصدقائه">
                    <svm_prediction>
                        <morph_feature_set diac="أَصْدِقائِهِ" lemma="صَدِيقSadiyq" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942773079888653">
                        <morph_feature_set diac="أَصْدِقائِهِ" lemma="صَدِيق_1" gloss="friends" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="أَصْدِقائ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="@@اصدقائه@@"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="@@ASdqA}h@@" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="@@أصدقائه@@" form1="@@اصدقائه@@" form2="صَدِيق" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="@@اصدقائه@@"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="14" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="15" word="التجار">
                    <svm_prediction>
                        <morph_feature_set diac="التُّجّارِ" lemma="تاجِرtAjir" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="التُّجّارِ" lemma="تاجِر_1" gloss="merchants;businessmen" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="تُجّار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التجار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="tjAr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التجار" form1="التجار" form2="تاجِر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="تجار"/>
                    </tokenized>
                </word>
                <word id="16" word="العرب">
                    <svm_prediction>
                        <morph_feature_set diac="العَرَبِ" lemma="عَرَبEarab" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8297979948737684">
                        <morph_feature_set diac="العَرَبِ" lemma="عَرَب_1" gloss="Arabs" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عَرَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العرب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Erb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العرب" form1="العرب" form2="عَرَب" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عرب"/>
                    </tokenized>
                </word>
                <word id="17" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="18" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="19" word="بالأحرى">
                    <svm_prediction>
                        <morph_feature_set diac="بِالأَحْرَى" lemma="أَحْرَى&gt;aHoraY" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="بِالأَحْرَى" lemma="أَحْرَى_2" gloss="more;most_adequate;better;best" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="أَحْرَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="الاحري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="AHry" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الأحرى" form1="الاحري" form2="أَحْرَى" form3="NOM" form4="DT+NN" form5="DET+NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="احري"/>
                    </tokenized>
                </word>
                <word id="20" word="الحكام">
                    <svm_prediction>
                        <morph_feature_set diac="الحُكّامِ" lemma="حاكِمHAkim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8849138440518091">
                        <morph_feature_set diac="الحُكّامَ" lemma="حاكِم_2" gloss="rulers;governors" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="حُكّام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الحكام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="HkAm" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الحكام" form1="الحكام" form2="حاكِم" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حكام"/>
                    </tokenized>
                </word>
                <word id="21" word="التجار">
                    <svm_prediction>
                        <morph_feature_set diac="التُّجّارِ" lemma="تاجِرtAjir" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="التُّجّارِ" lemma="تاجِر_1" gloss="merchants;businessmen" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="تُجّار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التجار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="tjAr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التجار" form1="التجار" form2="تاجِر" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="تجار"/>
                    </tokenized>
                </word>
                <word id="22" word="الذين">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِينَ" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="الَّذِينَ" lemma="الَّذِي_1" gloss="who;whom_[pl.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="u" enc0="0" stem="الَّذِينَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*yn" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذين" form1="الذين" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذين"/>
                    </tokenized>
                </word>
                <word id="23" word="يجمع">
                    <svm_prediction>
                        <morph_feature_set diac="يُجْمَع" lemma="جَمَعjamaE" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يَجْمَع" lemma="جَمَع-َ_1" gloss="gather;assemble" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="جْمَع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يجمع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yjmE" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يجمع" form1="يجمع" form2="جَمَع" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يجمع"/>
                    </tokenized>
                </word>
                <word id="24" word="بعضهم">
                    <svm_prediction>
                        <morph_feature_set diac="بَعْضُهُم" lemma="بَعْضbaEoD" pos="noun_quant" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3mp_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.825008850607285">
                        <morph_feature_set diac="بَعْضُهُم" lemma="بَعْض_1" gloss="some;several" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3mp_poss" stem="بَعْض"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بعض"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bED" form1="ADJ+CASE_DEF_NOM"/>
                        <tok id="1" form0="+hm" form1="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بعض" form1="بعض" form2="بَعْض" form3="NOM" form4="JJ" form5="ADJ+CASE_DEF_NOM"/>
                        <tok id="1" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بعض"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="25" word="بين">
                    <svm_prediction>
                        <morph_feature_set diac="بَيْنَ" lemma="بَيْنَbayona" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8705370026304016">
                        <morph_feature_set diac="بَيِّنَ" lemma="بَيِّن_1" gloss="clear;evident;explicit" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="بَيِّن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="byn" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بين" form1="بين" form2="بَيِّن" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بين"/>
                    </tokenized>
                </word>
                <word id="26" word="الحكم">
                    <svm_prediction>
                        <morph_feature_set diac="الحُكْمِ" lemma="حُكْمHukom" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الحُكْمِ" lemma="حُكْم_1" gloss="judgment;decision" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="حُكْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الحكم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Hkm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الحكم" form1="الحكم" form2="حُكْم" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="حكم"/>
                    </tokenized>
                </word>
                <word id="27" word="والتجارة">
                    <svm_prediction>
                        <morph_feature_set diac="وَالتِّجارَةِ" lemma="تِجارَةtijArap" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940423284216443">
                        <morph_feature_set diac="وَالتِّجارَةِ" lemma="تِجارَة_1" gloss="commerce;business" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="تِجار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="التجارة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="tjArp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="التجارة" form1="التجارة" form2="تِجارَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="تجارة"/>
                    </tokenized>
                </word>
                <word id="28" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="29" word="سواء">
                    <svm_prediction>
                        <morph_feature_set diac="سَواء" lemma="سَواءsawA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8459330756272011">
                        <morph_feature_set diac="سَواء" lemma="سَواء_1" gloss="except;whether" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="سَواء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سواء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="swA'" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سواء" form1="سواء" form2="سَواء" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سواء"/>
                    </tokenized>
                </word>
                <word id="30" word="بصورة">
                    <svm_prediction>
                        <morph_feature_set diac="بِصُورَةٍ" lemma="صُورَةSuwrap" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940186055051459">
                        <morph_feature_set diac="بِصُورَةٍ" lemma="صُورَة_1" gloss="picture;image;illustration;photo" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="صُور"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="صورة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Swrp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="صورة" form1="صورة" form2="صُورَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="صورة"/>
                    </tokenized>
                </word>
                <word id="31" word="علنية">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَنِيَّةٍ" lemma="عَلَنِيّEalaniy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946499216717394">
                        <morph_feature_set diac="عَلَنِيَّةٍ" lemma="عَلَنِيّ_1" gloss="public" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="عَلَنِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علنية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Elnyp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="علنية" form1="علنية" form2="عَلَنِيّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علنية"/>
                    </tokenized>
                </word>
                <word id="32" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="33" word="او">
                    <svm_prediction>
                        <morph_feature_set diac="أُو" lemma="أُو&gt;uw" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7982692832185527">
                        <morph_feature_set diac="أَو" lemma="أَو_1" gloss="or" pos="conj" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَو"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="او"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Aw" form1="CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أو" form1="او" form2="أَو" form3="PRT" form4="CC" form5="CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="او"/>
                    </tokenized>
                </word>
                <word id="34" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="35" word="خلال">
                    <svm_prediction>
                        <morph_feature_set diac="خِلالِ" lemma="خِلالَxilAla" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.6384728576072036">
                        <morph_feature_set diac="خِلالِ" lemma="خِلالَ_1" gloss="during;through" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="خِلالِ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="خلال"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="xlAl" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="خلال" form1="خلال" form2="خِلالَ" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="خلال"/>
                    </tokenized>
                </word>
                <word id="36" word="شبكة">
                    <svm_prediction>
                        <morph_feature_set diac="شَبَكَةِ" lemma="شَبَكَة$abakap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="شَبَكَةِ" lemma="شَبَكَة_1" gloss="network;system" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="شَبَك"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="شبكة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="$bkp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="شبكة" form1="شبكة" form2="شَبَكَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="شبكة"/>
                    </tokenized>
                </word>
                <word id="37" word="أبنائهم">
                    <svm_prediction>
                        <morph_feature_set diac="أَبْنائِهِم" lemma="أَبْناء&gt;abonA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3mp_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8940020403478229">
                        <morph_feature_set diac="أَبْنائِهِم" lemma="أَبْناء_1" gloss="sons;children" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3mp_poss" stem="أَبْنائ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ابناء"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AbnA'" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+hm" form1="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أبناء" form1="ابناء" form2="أَبْناء" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ابناء"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="38" word="وبناتهم">
                    <svm_prediction>
                        <morph_feature_set diac="وَبُناتهم" lemma="بِنْتbinot" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="3mp_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836060171334222">
                        <morph_feature_set diac="وَبَناتِهِم" lemma="بِنْت_1" gloss="daughters;girls" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="g" enc0="3mp_poss" stem="بَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="بنات"/>
                        <tok id="2" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="bnAt" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                        <tok id="2" form0="+hm" form1="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="بنات" form1="بنات" form2="بِنْت" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_GEN"/>
                        <tok id="2" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="بنات"/>
                        <tok id="2" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="39" word="واصهارهم">
                    <svm_prediction>
                        <morph_feature_set diac="وَأَصْهارَهُم" lemma="صِهْرSihor" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3mp_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.81383963150937">
                        <morph_feature_set diac="وَأَصْهارِهِم" lemma="صِهْر_1" gloss="family_ties" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3mp_poss" stem="أَصْهار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اصهار"/>
                        <tok id="2" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="AShAr" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+hm" form1="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="أصهار" form1="اصهار" form2="صِهْر" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="2" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="اصهار"/>
                        <tok id="2" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="40" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="41" word="وما">
                    <svm_prediction>
                        <morph_feature_set diac="وَما" lemma="ماmA" pos="pron_rel" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.893947845645774">
                        <morph_feature_set diac="وَما" lemma="ما_1" gloss="what" pos="pron_rel" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ما"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="mA" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="ما" form1="ما" form2="ما" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ما"/>
                    </tokenized>
                </word>
                <word id="42" word="اكثرهم">
                    <svm_prediction>
                        <morph_feature_set diac="أَكْثَرُهُم" lemma="أَكْثَر&gt;akovar" pos="part" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3mp_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7552291719858164">
                        <morph_feature_set diac="أَكْثَرُهُم" lemma="أَكْثَر_1" gloss="more;most" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3mp_poss" stem="أَكْثَر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اكثر"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Akvr" form1="ADJ+CASE_DEF_NOM"/>
                        <tok id="1" form0="+hm" form1="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أكثر" form1="اكثر" form2="أَكْثَر" form3="NOM" form4="JJ" form5="ADJ+CASE_DEF_NOM"/>
                        <tok id="1" form0="+هم" form1="+هم" form2="+هُم" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اكثر"/>
                        <tok id="1" form0="+هم"/>
                    </tokenized>
                </word>
                <word id="43" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="44" word="بلداننا">
                    <svm_prediction>
                        <morph_feature_set diac="بُلْدانِنا" lemma="بَلَدbalad" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939458006110683">
                        <morph_feature_set diac="بُلْدانِنا" lemma="بَلَد_1" gloss="countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss" stem="بُلْدان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بلدان"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bldAn" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+nA" form1="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بلدان" form1="بلدان" form2="بَلَد" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بلدان"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        <out_seg id="SENT12">
            <segment_info>
                <preprocessed>الرئيس النيجيري بخاري , وهو مسلم , رد لنا الاعتبار كمسلمين عندما التزم بأصول الديمقراطية في بلده , وتصرف كموظف عادي يحترم " أولياء امره " في البرلمان , ممثلي الشعب , المنتخبين في انتخابات حرة نزيهة , اما القاضي الفيدرالي الأمريكي الذي رفض استئناف وزارة العدل باسم ترامب , وصادق على قرار زميله جيمس روبارت من مدينة سياتل , باستمرار دخول المسلمين من الدول السبع المحظورة , فقد بيض صفحة الديمقراطية الامريكية , وان كان الكثير منا لا يمكن ان ينسى جرائم امريكا في بلداننا العربية والإسلامية , ومئات الآلاف من الضحايا الذين سقطوا ضحية لها</preprocessed>
                <bpc>
                    <chunk id="0" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="نيجيري"/>
                        <tok id="4" form0="بخاري"/>
                    </chunk>
                    <chunk id="1" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="2" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="هو"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="مسلم"/>
                    </chunk>
                    <chunk id="5" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="6" type="VP">
                        <tok id="0" form0="رد"/>
                    </chunk>
                    <chunk id="7" type="PP">
                        <tok id="0" form0="ل"/>
                    </chunk>
                    <chunk id="8" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                    <chunk id="9" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اعتبار"/>
                    </chunk>
                    <chunk id="10" type="PP">
                        <tok id="0" form0="ك+"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="مسلمين"/>
                    </chunk>
                    <chunk id="12" type="NP">
                        <tok id="0" form0="عندما"/>
                    </chunk>
                    <chunk id="13" type="SBAR">
                        <tok id="0" form0="+ما"/>
                    </chunk>
                    <chunk id="14" type="VP">
                        <tok id="0" form0="التزم"/>
                    </chunk>
                    <chunk id="15" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="اصول"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ديمقراطية"/>
                    </chunk>
                    <chunk id="18" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="19" type="NP">
                        <tok id="0" form0="بلد"/>
                    </chunk>
                    <chunk id="20" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="21" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="22" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="تصرف"/>
                    </chunk>
                    <chunk id="24" type="PP">
                        <tok id="0" form0="ك+"/>
                    </chunk>
                    <chunk id="25" type="NP">
                        <tok id="0" form0="موظف"/>
                        <tok id="1" form0="عادي"/>
                    </chunk>
                    <chunk id="26" type="VP">
                        <tok id="0" form0="يحترم"/>
                    </chunk>
                    <chunk id="27" type="NP">
                        <tok id="0" form0="&quot;"/>
                        <tok id="1" form0="اولياء"/>
                    </chunk>
                    <chunk id="28" type="NP">
                        <tok id="0" form0="امر"/>
                    </chunk>
                    <chunk id="29" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="30" type="PP">
                        <tok id="0" form0="&quot;"/>
                        <tok id="1" form0="في"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="برلمان"/>
                    </chunk>
                    <chunk id="32" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="33" type="NP">
                        <tok id="0" form0="ممثلي"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعب"/>
                    </chunk>
                    <chunk id="35" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="36" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="منتخبين"/>
                    </chunk>
                    <chunk id="37" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="38" type="NP">
                        <tok id="0" form0="انتخابات"/>
                        <tok id="1" form0="حرة"/>
                        <tok id="2" form0="نزيهة"/>
                    </chunk>
                    <chunk id="39" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="40" type="NP">
                        <tok id="0" form0="اما"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="قاضي"/>
                        <tok id="3" form0="ال+"/>
                        <tok id="4" form0="فيدرالي"/>
                        <tok id="5" form0="ال+"/>
                        <tok id="6" form0="امريكي"/>
                    </chunk>
                    <chunk id="41" type="WHNP">
                        <tok id="0" form0="الذي"/>
                    </chunk>
                    <chunk id="42" type="VP">
                        <tok id="0" form0="رفض"/>
                    </chunk>
                    <chunk id="43" type="NP">
                        <tok id="0" form0="استئناف"/>
                    </chunk>
                    <chunk id="44" type="NP">
                        <tok id="0" form0="وزارة"/>
                    </chunk>
                    <chunk id="45" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدل"/>
                    </chunk>
                    <chunk id="46" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="47" type="NP">
                        <tok id="0" form0="اسم"/>
                    </chunk>
                    <chunk id="48" type="NP">
                        <tok id="0" form0="ترامب"/>
                    </chunk>
                    <chunk id="49" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="50" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="51" type="ADJP">
                        <tok id="0" form0="صادق"/>
                    </chunk>
                    <chunk id="52" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="53" type="NP">
                        <tok id="0" form0="قرار"/>
                    </chunk>
                    <chunk id="54" type="NP">
                        <tok id="0" form0="زميل"/>
                    </chunk>
                    <chunk id="55" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="56" type="NP">
                        <tok id="0" form0="جيمس"/>
                    </chunk>
                    <chunk id="57" type="NP">
                        <tok id="0" form0="روبارت"/>
                    </chunk>
                    <chunk id="58" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="59" type="NP">
                        <tok id="0" form0="مدينة"/>
                    </chunk>
                    <chunk id="60" type="NP">
                        <tok id="0" form0="سياتل"/>
                    </chunk>
                    <chunk id="61" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="62" type="PP">
                        <tok id="0" form0="ب+"/>
                    </chunk>
                    <chunk id="63" type="NP">
                        <tok id="0" form0="استمرار"/>
                    </chunk>
                    <chunk id="64" type="NP">
                        <tok id="0" form0="دخول"/>
                    </chunk>
                    <chunk id="65" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مسلمين"/>
                    </chunk>
                    <chunk id="66" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="67" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دول"/>
                    </chunk>
                    <chunk id="68" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سبع"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="محظورة"/>
                    </chunk>
                    <chunk id="69" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="70" type="">
                        <tok id="0" form0="ف+"/>
                    </chunk>
                    <chunk id="71" type="VP">
                        <tok id="0" form0="قد"/>
                        <tok id="1" form0="بيض"/>
                    </chunk>
                    <chunk id="72" type="NP">
                        <tok id="0" form0="صفحة"/>
                    </chunk>
                    <chunk id="73" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ديمقراطية"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="امريكية"/>
                    </chunk>
                    <chunk id="74" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="75" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="76" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="77" type="VP">
                        <tok id="0" form0="كان"/>
                    </chunk>
                    <chunk id="78" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="كثير"/>
                    </chunk>
                    <chunk id="79" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="80" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                    <chunk id="81" type="VP">
                        <tok id="0" form0="لا"/>
                        <tok id="1" form0="يمكن"/>
                    </chunk>
                    <chunk id="82" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="83" type="VP">
                        <tok id="0" form0="ينسي"/>
                    </chunk>
                    <chunk id="84" type="NP">
                        <tok id="0" form0="جرائم"/>
                    </chunk>
                    <chunk id="85" type="NP">
                        <tok id="0" form0="امريكا"/>
                    </chunk>
                    <chunk id="86" type="PP">
                        <tok id="0" form0="في"/>
                    </chunk>
                    <chunk id="87" type="NP">
                        <tok id="0" form0="بلدان"/>
                    </chunk>
                    <chunk id="88" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                    <chunk id="89" type="ADJP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عربية"/>
                        <tok id="2" form0="و+"/>
                        <tok id="3" form0="ال+"/>
                        <tok id="4" form0="اسلامية"/>
                    </chunk>
                    <chunk id="90" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="91" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="92" type="NP">
                        <tok id="0" form0="مئات"/>
                    </chunk>
                    <chunk id="93" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="الاف"/>
                    </chunk>
                    <chunk id="94" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="95" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ضحايا"/>
                    </chunk>
                    <chunk id="96" type="WHNP">
                        <tok id="0" form0="الذين"/>
                    </chunk>
                    <chunk id="97" type="VP">
                        <tok id="0" form0="سقطوا"/>
                    </chunk>
                    <chunk id="98" type="NP">
                        <tok id="0" form0="ضحية"/>
                    </chunk>
                    <chunk id="99" type="PP">
                        <tok id="0" form0="ل"/>
                    </chunk>
                    <chunk id="100" type="NP">
                        <tok id="0" form0="+ها"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="ال+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="رئيس"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ال+"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="نيجيري"/>
                    </ne>
                    <ne id="4" type="PER">
                        <tok id="4" form0="بخاري"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0=","/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="و+"/>
                    </ne>
                    <ne id="7" type="">
                        <tok id="7" form0="هو"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="مسلم"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0=","/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="رد"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="ل"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0="+نا"/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="ال+"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="اعتبار"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="ك+"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="مسلمين"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="عندما"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="+ما"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="التزم"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0="ب+"/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="اصول"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="ال+"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="ديمقراطية"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="في"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="بلد"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="+ه"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0=","/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="و+"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0="تصرف"/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="ك+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="موظف"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="عادي"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="يحترم"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="&quot;"/>
                    </ne>
                    <ne id="35" type="PER">
                        <tok id="35" form0="اولياء"/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="امر"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="+ه"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="&quot;"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="في"/>
                    </ne>
                    <ne id="40" type="ORG">
                        <tok id="40" form0="ال+"/>
                        <tok id="40" form0="برلمان"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0=","/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="ممثلي"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="ال+"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="شعب"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0=","/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="ال+"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="منتخبين"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="في"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="انتخابات"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="حرة"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="نزيهة"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0=","/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0="اما"/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="ال+"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="قاضي"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="ال+"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="فيدرالي"/>
                    </ne>
                    <ne id="58" type="LOC">
                        <tok id="58" form0="ال+"/>
                        <tok id="58" form0="امريكي"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="الذي"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="رفض"/>
                    </ne>
                    <ne id="61" type="">
                        <tok id="61" form0="استئناف"/>
                    </ne>
                    <ne id="62" type="ORG">
                        <tok id="62" form0="وزارة"/>
                        <tok id="62" form0="ال+"/>
                    </ne>
                    <ne id="63" type="ORG">
                        <tok id="63" form0="عدل"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0="ب+"/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0="اسم"/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="ترامب"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0=","/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="و+"/>
                    </ne>
                    <ne id="69" type="">
                        <tok id="69" form0="صادق"/>
                    </ne>
                    <ne id="70" type="">
                        <tok id="70" form0="علي"/>
                    </ne>
                    <ne id="71" type="">
                        <tok id="71" form0="قرار"/>
                    </ne>
                    <ne id="72" type="">
                        <tok id="72" form0="زميل"/>
                    </ne>
                    <ne id="73" type="">
                        <tok id="73" form0="+ه"/>
                    </ne>
                    <ne id="74" type="PER">
                        <tok id="74" form0="جيمس"/>
                        <tok id="74" form0="روبارت"/>
                    </ne>
                    <ne id="75" type="">
                        <tok id="75" form0="من"/>
                    </ne>
                    <ne id="76" type="">
                        <tok id="76" form0="مدينة"/>
                    </ne>
                    <ne id="77" type="LOC">
                        <tok id="77" form0="سياتل"/>
                    </ne>
                    <ne id="78" type="">
                        <tok id="78" form0=","/>
                    </ne>
                    <ne id="79" type="">
                        <tok id="79" form0="ب+"/>
                    </ne>
                    <ne id="80" type="">
                        <tok id="80" form0="استمرار"/>
                    </ne>
                    <ne id="81" type="">
                        <tok id="81" form0="دخول"/>
                    </ne>
                    <ne id="82" type="">
                        <tok id="82" form0="ال+"/>
                    </ne>
                    <ne id="83" type="">
                        <tok id="83" form0="مسلمين"/>
                    </ne>
                    <ne id="84" type="">
                        <tok id="84" form0="من"/>
                    </ne>
                    <ne id="85" type="">
                        <tok id="85" form0="ال+"/>
                    </ne>
                    <ne id="86" type="">
                        <tok id="86" form0="دول"/>
                    </ne>
                    <ne id="87" type="">
                        <tok id="87" form0="ال+"/>
                    </ne>
                    <ne id="88" type="">
                        <tok id="88" form0="سبع"/>
                    </ne>
                    <ne id="89" type="">
                        <tok id="89" form0="ال+"/>
                    </ne>
                    <ne id="90" type="">
                        <tok id="90" form0="محظورة"/>
                    </ne>
                    <ne id="91" type="">
                        <tok id="91" form0=","/>
                    </ne>
                    <ne id="92" type="">
                        <tok id="92" form0="ف+"/>
                    </ne>
                    <ne id="93" type="">
                        <tok id="93" form0="قد"/>
                    </ne>
                    <ne id="94" type="">
                        <tok id="94" form0="بيض"/>
                    </ne>
                    <ne id="95" type="">
                        <tok id="95" form0="صفحة"/>
                    </ne>
                    <ne id="96" type="ORG">
                        <tok id="96" form0="ال+"/>
                        <tok id="96" form0="ديمقراطية"/>
                    </ne>
                    <ne id="97" type="LOC">
                        <tok id="97" form0="ال+"/>
                        <tok id="97" form0="امريكية"/>
                    </ne>
                    <ne id="98" type="">
                        <tok id="98" form0=","/>
                    </ne>
                    <ne id="99" type="">
                        <tok id="99" form0="و+"/>
                    </ne>
                    <ne id="100" type="">
                        <tok id="100" form0="ان"/>
                    </ne>
                    <ne id="101" type="">
                        <tok id="101" form0="كان"/>
                    </ne>
                    <ne id="102" type="">
                        <tok id="102" form0="ال+"/>
                    </ne>
                    <ne id="103" type="">
                        <tok id="103" form0="كثير"/>
                    </ne>
                    <ne id="104" type="">
                        <tok id="104" form0="من"/>
                    </ne>
                    <ne id="105" type="">
                        <tok id="105" form0="+نا"/>
                    </ne>
                    <ne id="106" type="">
                        <tok id="106" form0="لا"/>
                    </ne>
                    <ne id="107" type="">
                        <tok id="107" form0="يمكن"/>
                    </ne>
                    <ne id="108" type="">
                        <tok id="108" form0="ان"/>
                    </ne>
                    <ne id="109" type="">
                        <tok id="109" form0="ينسي"/>
                    </ne>
                    <ne id="110" type="">
                        <tok id="110" form0="جرائم"/>
                    </ne>
                    <ne id="111" type="LOC">
                        <tok id="111" form0="امريكا"/>
                    </ne>
                    <ne id="112" type="">
                        <tok id="112" form0="في"/>
                    </ne>
                    <ne id="113" type="">
                        <tok id="113" form0="بلدان"/>
                    </ne>
                    <ne id="114" type="">
                        <tok id="114" form0="+نا"/>
                    </ne>
                    <ne id="115" type="">
                        <tok id="115" form0="ال+"/>
                    </ne>
                    <ne id="116" type="">
                        <tok id="116" form0="عربية"/>
                    </ne>
                    <ne id="117" type="">
                        <tok id="117" form0="و+"/>
                    </ne>
                    <ne id="118" type="PER">
                        <tok id="118" form0="ال+"/>
                        <tok id="118" form0="اسلامية"/>
                    </ne>
                    <ne id="119" type="">
                        <tok id="119" form0=","/>
                    </ne>
                    <ne id="120" type="">
                        <tok id="120" form0="و+"/>
                    </ne>
                    <ne id="121" type="">
                        <tok id="121" form0="مئات"/>
                    </ne>
                    <ne id="122" type="">
                        <tok id="122" form0="ال+"/>
                    </ne>
                    <ne id="123" type="">
                        <tok id="123" form0="الاف"/>
                    </ne>
                    <ne id="124" type="">
                        <tok id="124" form0="من"/>
                    </ne>
                    <ne id="125" type="">
                        <tok id="125" form0="ال+"/>
                    </ne>
                    <ne id="126" type="">
                        <tok id="126" form0="ضحايا"/>
                    </ne>
                    <ne id="127" type="">
                        <tok id="127" form0="الذين"/>
                    </ne>
                    <ne id="128" type="">
                        <tok id="128" form0="سقطوا"/>
                    </ne>
                    <ne id="129" type="">
                        <tok id="129" form0="ضحية"/>
                    </ne>
                    <ne id="130" type="">
                        <tok id="130" form0="ل"/>
                    </ne>
                    <ne id="131" type="">
                        <tok id="131" form0="+ها"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="الرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="الرَّئِيسُ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950630275921179">
                        <morph_feature_set diac="الرَّئِيسُ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="r}ys" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="1" word="النيجيري">
                    <svm_prediction>
                        <morph_feature_set diac="النَّيْجِيرِيُّ" lemma="نَيْجِيرِيّnayojiyriy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944564568979746">
                        <morph_feature_set diac="النَّيْجِيرِيُّ" lemma="نَيْجِيرِيّ_1" gloss="Nigerian" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="نَيْجِيرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="النيجيري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="nyjyry" form1="ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="النيجيري" form1="النيجيري" form2="نَيْجِيرِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نيجيري"/>
                    </tokenized>
                </word>
                <word id="2" word="بخاري">
                    <svm_prediction>
                        <morph_feature_set diac="بُخارِيّ" lemma="بُخارِيّbuxAriy~" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8998215129572901">
                        <morph_feature_set diac="بُخارِيّ" lemma="بُخارِيّ_1" gloss="Bukhari" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="بُخارِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بخاري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bxAry" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بخاري" form1="بخاري" form2="بُخارِيّ" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بخاري"/>
                    </tokenized>
                </word>
                <word id="3" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="4" word="وهو">
                    <svm_prediction>
                        <morph_feature_set diac="وَهُوَ" lemma="هُوَhuwa" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939703415048932">
                        <morph_feature_set diac="وَهُوَ" lemma="هُوَ_1" gloss="it;he" pos="pron" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="هُوَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هو"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="hw" form1="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="هو" form1="هو" form2="هُوَ" form3="NOM" form4="PRP" form5="PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="هو"/>
                    </tokenized>
                </word>
                <word id="5" word="مسلم">
                    <svm_prediction>
                        <morph_feature_set diac="مُسْلِمٍ" lemma="مُسْلِمmusolim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840070570614899">
                        <morph_feature_set diac="مُسْلِمٌ" lemma="مُسْلِم_1" gloss="Muslim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="n" enc0="0" stem="مُسْلِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مسلم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mslm" form1="NOUN+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مسلم" form1="مسلم" form2="مُسْلِم" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مسلم"/>
                    </tokenized>
                </word>
                <word id="6" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="7" word="رد">
                    <svm_prediction>
                        <morph_feature_set diac="رَدَّ" lemma="رَدّrad~" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="i" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7959204726931325">
                        <morph_feature_set diac="رَدَّ" lemma="رَدّ-ُ_1" gloss="answer;reply;return" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="رَدّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="rd" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رد" form1="رد" form2="رَدّ" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رد"/>
                    </tokenized>
                </word>
                <word id="8" word="لنا">
                    <svm_prediction>
                        <morph_feature_set diac="لَنا" lemma="لِli" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="1p_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="لَنا" lemma="لِ_1" gloss="to;for_+_us_(we_have)" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="1p_pron" stem="لَنا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l" form1="PREP"/>
                        <tok id="1" form0="+nA" form1="+PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل" form1="ل" form2="لِ" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP" form5="+PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="9" word="الاعتبار">
                    <svm_prediction>
                        <morph_feature_set diac="الاِعْتِبارِ" lemma="ٱِعْتِبار{iEotibAr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8849138440518091">
                        <morph_feature_set diac="الاِعْتِبارَ" lemma="ٱِعْتِبار_1" gloss="consideration;regard" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="ٱِعْتِبار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاعتبار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AEtbAr" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الاعتبار" form1="الاعتبار" form2="ٱِعْتِبار" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اعتبار"/>
                    </tokenized>
                </word>
                <word id="10" word="كمسلمين">
                    <svm_prediction>
                        <morph_feature_set diac="كَمُسَلَّمَيْنِ" lemma="مُسْلِمmusolim" pos="noun" prc3="0" prc2="0" prc1="ka_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8841291673133848">
                        <morph_feature_set diac="كَمُسْلِمِينَ" lemma="مُسْلِم_1" gloss="Muslim" pos="noun" prc3="0" prc2="0" prc1="ka_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="a" enc0="0" stem="مُسْلِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ك+"/>
                        <tok id="1" form0="مسلمين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="k+" form1="PREP+"/>
                        <tok id="1" form0="mslmyn" form1="NOUN+NSUFF_MASC_PL_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ك+" form1="ك+" form2="كَ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="مسلمين" form1="مسلمين" form2="مُسْلِم" form3="NOM" form4="NNS" form5="NOUN+NSUFF_MASC_PL_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ك+"/>
                        <tok id="1" form0="مسلمين"/>
                    </tokenized>
                </word>
                <word id="11" word="عندما">
                    <svm_prediction>
                        <morph_feature_set diac="عَنْدَماً" lemma="عِنْدEinod" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="mA_sub"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7845319921457895">
                        <morph_feature_set diac="عِنْدَما" lemma="عِنْد_1" gloss="when" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="mA_sub" stem="عِنْدَما"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عندما"/>
                        <tok id="1" form0="+ما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EndmA" form1="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+mA" form1="+SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عندما" form1="عندما" form2="عِنْد" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+ما" form1="+ما" form2="+ما" form3="+PRT" form4="+AN" form5="+SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عندما"/>
                        <tok id="1" form0="+ما"/>
                    </tokenized>
                </word>
                <word id="12" word="التزم">
                    <svm_prediction>
                        <morph_feature_set diac="اِلْتَزَمَ" lemma="ٱِلْتَزَم{ilotazam" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="اِلْتَزَمَ" lemma="ٱِلْتَزَم_1" gloss="be_committed;maintain;preserve" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="ٱِلْتَزَم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التزم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Altzm" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التزم" form1="التزم" form2="ٱِلْتَزَم" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="التزم"/>
                    </tokenized>
                </word>
                <word id="13" word="بأصول">
                    <svm_prediction>
                        <morph_feature_set diac="بِأُصُولِ" lemma="أَصْل&gt;aSol" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِأُصُولِ" lemma="أَصْل_1" gloss="origins;principles" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="أُصُول"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="اصول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="ASwl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="أصول" form1="اصول" form2="أَصْل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="اصول"/>
                    </tokenized>
                </word>
                <word id="14" word="الديمقراطية">
                    <svm_prediction>
                        <morph_feature_set diac="الدِّيمُقراطِيَّةِ" lemma="دِيمُوقراطِيّdiymuwqrATiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="الدِّيمُقراطِيَّةِ" lemma="دِيمُوقراطِيّ_1" gloss="democratic" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="دِيمُقراطِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الديمقراطية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dymqrATyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الديمقراطية" form1="الديمقراطية" form2="دِيمُوقراطِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ديمقراطية"/>
                    </tokenized>
                </word>
                <word id="15" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="16" word="بلده">
                    <svm_prediction>
                        <morph_feature_set diac="بَلْدَةِ" lemma="بَلَدbalad" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839788350798833">
                        <morph_feature_set diac="بَلَدِهِ" lemma="بَلَد_1" gloss="country" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="بَلَد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بلد"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bld" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بلد" form1="بلد" form2="بَلَد" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بلد"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="17" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="18" word="وتصرف">
                    <svm_prediction>
                        <morph_feature_set diac="وَتَصَرُّفِ" lemma="تَصَرُّفtaSar~uf" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="c" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.7259244866384575">
                        <morph_feature_set diac="وَتَصَرُّفِ" lemma="تَصَرُّف_1" gloss="behavior;conduct;disposal" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="تَصَرُّف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="تصرف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="tSrf" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="تصرف" form1="تصرف" form2="تَصَرُّف" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="تصرف"/>
                    </tokenized>
                </word>
                <word id="19" word="كموظف">
                    <svm_prediction>
                        <morph_feature_set diac="كَمُوَظَّفِ" lemma="مُوَظَّفmuwaZ~af" pos="noun" prc3="0" prc2="0" prc1="ka_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8836236047871376">
                        <morph_feature_set diac="كَمُوَظَّفٍ" lemma="مُوَظَّف_1" gloss="employee" pos="noun" prc3="0" prc2="0" prc1="ka_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="مُوَظَّف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ك+"/>
                        <tok id="1" form0="موظف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="k+" form1="PREP+"/>
                        <tok id="1" form0="mwZf" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ك+" form1="ك+" form2="كَ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="موظف" form1="موظف" form2="مُوَظَّف" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ك+"/>
                        <tok id="1" form0="موظف"/>
                    </tokenized>
                </word>
                <word id="20" word="عادي">
                    <svm_prediction>
                        <morph_feature_set diac="عادِيٍّ" lemma="عادِيّEAdiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894442345679612">
                        <morph_feature_set diac="عادِيٍّ" lemma="عادِيّ_1" gloss="ordinary;regular;normal" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="عادِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="عادي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="EAdy" form1="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="عادي" form1="عادي" form2="عادِيّ" form3="NOM" form4="JJ" form5="ADJ+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="عادي"/>
                    </tokenized>
                </word>
                <word id="21" word="يحترم">
                    <svm_prediction>
                        <morph_feature_set diac="يَحْتَرِم" lemma="ٱِحْتَرَم{iHotaram" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="يَحْتَرِم" lemma="ٱِحْتَرَم_1" gloss="respect;revere" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="حْتَرِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يحترم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="yHtrm" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يحترم" form1="يحترم" form2="ٱِحْتَرَم" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يحترم"/>
                    </tokenized>
                </word>
                <word id="22" word="&quot;">
                    <svm_prediction>
                        <morph_feature_set diac="&quot;" lemma="&quot;&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="&quot;" lemma="&quot;_0" gloss="&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="&quot;" form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="&quot;" form1="&quot;" form2="&quot;" form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                </word>
                <word id="23" word="أولياء">
                    <svm_prediction>
                        <morph_feature_set diac="أَوْلِياءِ" lemma="وَلِيّwaliy~" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="أَوْلِياءِ" lemma="وَلِيّ_1" gloss="responsible;guardian" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="أَوْلِياء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اولياء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AwlyA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أولياء" form1="اولياء" form2="وَلِيّ" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اولياء"/>
                    </tokenized>
                </word>
                <word id="24" word="امره">
                    <svm_prediction>
                        <morph_feature_set diac="أَمْرَهُ" lemma="أَمْر&gt;amor" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8242988476991315">
                        <morph_feature_set diac="أَمْرَهُ" lemma="أَمْر_1" gloss="matter;issue" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="3ms_poss" stem="أَمْر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="امر"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Amr" form1="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أمر" form1="امر" form2="أَمْر" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="امر"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="25" word="&quot;">
                    <svm_prediction>
                        <morph_feature_set diac="&quot;" lemma="&quot;&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="&quot;" lemma="&quot;_0" gloss="&quot;" pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="&quot;" form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="&quot;" form1="&quot;" form2="&quot;" form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="&quot;"/>
                    </tokenized>
                </word>
                <word id="26" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="27" word="البرلمان">
                    <svm_prediction>
                        <morph_feature_set diac="البَرْلَمانِ" lemma="بَرْلَمانbarolamAn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="البَرْلَمانِ" lemma="بَرْلَمان_1" gloss="parliament" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="بَرْلَمان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="البرلمان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="brlmAn" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="البرلمان" form1="البرلمان" form2="بَرْلَمان" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="برلمان"/>
                    </tokenized>
                </word>
                <word id="28" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="29" word="ممثلي">
                    <svm_prediction>
                        <morph_feature_set diac="مُمَثِّلِي" lemma="مُمَثِّلmumav~il" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939155334676488">
                        <morph_feature_set diac="مُمَثِّلِي" lemma="مُمَثِّل_1" gloss="representative;delegate" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="c" cas="a" enc0="0" stem="مُمَثِّل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ممثلي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mmvly" form1="NOUN+NSUFF_MASC_PL_ACC_POSS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ممثلي" form1="ممثلي" form2="مُمَثِّل" form3="NOM" form4="NNS" form5="NOUN+NSUFF_MASC_PL_ACC_POSS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ممثلي"/>
                    </tokenized>
                </word>
                <word id="30" word="الشعب">
                    <svm_prediction>
                        <morph_feature_set diac="الشَّعْبِ" lemma="شَعْب$aEob" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الشَّعْبِ" lemma="شَعْب_1" gloss="people;nation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شَعْب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشعب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$Eb" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشعب" form1="الشعب" form2="شَعْب" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شعب"/>
                    </tokenized>
                </word>
                <word id="31" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="32" word="المنتخبين">
                    <svm_prediction>
                        <morph_feature_set diac="المُنْتَخَبَيْنِ" lemma="مُنْتَخَبmunotaxab" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939329166574673">
                        <morph_feature_set diac="المُنْتَخَبَيْنِ" lemma="مُنْتَخَب_1" gloss="elected_candidate;elect" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="d" stt="d" cas="a" enc0="0" stem="مُنْتَخَب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المنتخبين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mntxbyn" form1="NOUN+NSUFF_MASC_DU_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المنتخبين" form1="المنتخبين" form2="مُنْتَخَب" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_MASC_DU_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="منتخبين"/>
                    </tokenized>
                </word>
                <word id="33" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="34" word="انتخابات">
                    <svm_prediction>
                        <morph_feature_set diac="اِنْتِخاباتٌ" lemma="ٱِنْتِخاب{inotixAb" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839166646816445">
                        <morph_feature_set diac="اِنْتِخاباتٍ" lemma="ٱِنْتِخاب_1" gloss="election;selection" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="i" cas="g" enc0="0" stem="ٱِنْتِخاب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="انتخابات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AntxAbAt" form1="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="انتخابات" form1="انتخابات" form2="ٱِنْتِخاب" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="انتخابات"/>
                    </tokenized>
                </word>
                <word id="35" word="حرة">
                    <svm_prediction>
                        <morph_feature_set diac="حُرَّةٌ" lemma="حُرّHur~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8843514487627575">
                        <morph_feature_set diac="حُرَّةٍ" lemma="حُرّ_1" gloss="free;independent" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="حُرّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حرة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Hrp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حرة" form1="حرة" form2="حُرّ" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حرة"/>
                    </tokenized>
                </word>
                <word id="36" word="نزيهة">
                    <svm_prediction>
                        <morph_feature_set diac="نَزِيهَةً" lemma="نَزِيهnaziyh" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8843514487627575">
                        <morph_feature_set diac="نَزِيهَةٍ" lemma="نَزِيه_1" gloss="blameless;righteous;fair;impartial" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="نَزِيه"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نزيهة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nzyhp" form1="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نزيهة" form1="نزيهة" form2="نَزِيه" form3="NOM" form4="JJ" form5="ADJ+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نزيهة"/>
                    </tokenized>
                </word>
                <word id="37" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="38" word="اما">
                    <svm_prediction>
                        <morph_feature_set diac="أَمّا" lemma="أَمّا&gt;am~A" pos="part_focus" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8241679626190229">
                        <morph_feature_set diac="أَمّا" lemma="أَمّا_1" gloss="as_for;concerning" pos="part_focus" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَمّا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="اما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AmA" form1="FOCUS_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أما" form1="اما" form2="أَمّا" form3="PRT" form4="RP" form5="FOCUS_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="اما"/>
                    </tokenized>
                </word>
                <word id="39" word="القاضي">
                    <svm_prediction>
                        <morph_feature_set diac="القاضِي" lemma="قاضِيqADiy" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="القاضِي" lemma="قاضِي_2" gloss="judge;magistrate" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="قاضِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="القاضي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="qADy" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="القاضي" form1="القاضي" form2="قاضِي" form3="NOM" form4="DT+NN" form5="DET+NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="قاضي"/>
                    </tokenized>
                </word>
                <word id="40" word="الفيدرالي">
                    <svm_prediction>
                        <morph_feature_set diac="الفِيدِرالِيّ" lemma="فِيدِرالِيّfiydirAliy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8941157464597336">
                        <morph_feature_set diac="الفِيدِرالِيّ" lemma="فِيدِرالِيّ_1" gloss="Federal" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="فِيدِرالِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الفيدرالي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="fydrAly" form1="ADJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الفيدرالي" form1="الفيدرالي" form2="فِيدِرالِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="فيدرالي"/>
                    </tokenized>
                </word>
                <word id="41" word="الأمريكي">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْرِيكِيَّ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943008256937558">
                        <morph_feature_set diac="الأَمْرِيكِيَّ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامريكي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amryky" form1="ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمريكي" form1="الامريكي" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكي"/>
                    </tokenized>
                </word>
                <word id="42" word="الذي">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="الَّذِي" lemma="الَّذِي_1" gloss="which;who;whom" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="الَّذِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*y" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذي" form1="الذي" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذي"/>
                    </tokenized>
                </word>
                <word id="43" word="رفض">
                    <svm_prediction>
                        <morph_feature_set diac="رَفَضَ" lemma="رَفَضrafaD" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="رَفَضَ" lemma="رَفَض-ُ_1" gloss="reject;refuse" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="رَفَض"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="رفض"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="rfD" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="رفض" form1="رفض" form2="رَفَض" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="رفض"/>
                    </tokenized>
                </word>
                <word id="44" word="استئناف">
                    <svm_prediction>
                        <morph_feature_set diac="اِسْتِئْنافِ" lemma="ٱِسْتِئْناف{isoti}onAf" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8866756788017508">
                        <morph_feature_set diac="اِسْتِئْنافَ" lemma="ٱِسْتِئْناف_1" gloss="resumption;appeal" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="ٱِسْتِئْناف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="استئناف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ast}nAf" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="استئناف" form1="استئناف" form2="ٱِسْتِئْناف" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="استئناف"/>
                    </tokenized>
                </word>
                <word id="45" word="وزارة">
                    <svm_prediction>
                        <morph_feature_set diac="وِزارَةِ" lemma="وِزارَةwizArap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="وِزارَةِ" lemma="وِزارَة_1" gloss="ministry" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="وِزار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="وزارة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="wzArp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="وزارة" form1="وزارة" form2="وِزارَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="وزارة"/>
                    </tokenized>
                </word>
                <word id="46" word="العدل">
                    <svm_prediction>
                        <morph_feature_set diac="العَدْلِ" lemma="عَدْلEadol" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="العَدْلِ" lemma="عَدْل_1" gloss="justice;fairness" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عَدْل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العدل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Edl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العدل" form1="العدل" form2="عَدْل" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عدل"/>
                    </tokenized>
                </word>
                <word id="47" word="باسم">
                    <svm_prediction>
                        <morph_feature_set diac="بِاِسْمِ" lemma="ٱِسْم{isom" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944153510832757">
                        <morph_feature_set diac="بِاِسْمِ" lemma="ٱِسْم_1" gloss="name" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِسْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="اسم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="Asm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="اسم" form1="اسم" form2="ٱِسْم" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="اسم"/>
                    </tokenized>
                </word>
                <word id="48" word="ترامب">
                    <svm_prediction>
                        <morph_feature_set diac="ترامب" lemma="ترامبtrAmb" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="i" gen="f" num="s" stt="na" cas="g" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ترامب"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="trAmb" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ترامب" form1="ترامب" form2="ترامب" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ترامب"/>
                    </tokenized>
                </word>
                <word id="49" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="50" word="وصادق">
                    <svm_prediction>
                        <morph_feature_set diac="وَصادِقٍ" lemma="صادَقSAdaq" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8084112396819613">
                        <morph_feature_set diac="وَصادِقٍ" lemma="صادِق_1" gloss="veracious;truthful" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="صادِق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="صادق"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="SAdq" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="صادق" form1="صادق" form2="صادِق" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="صادق"/>
                    </tokenized>
                </word>
                <word id="51" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="52" word="قرار">
                    <svm_prediction>
                        <morph_feature_set diac="قَرارِ" lemma="قَرارqarAr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="قَرارِ" lemma="قَرار_1" gloss="decision;resolution" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="قَرار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="قرار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="qrAr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="قرار" form1="قرار" form2="قَرار" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="قرار"/>
                    </tokenized>
                </word>
                <word id="53" word="زميله">
                    <svm_prediction>
                        <morph_feature_set diac="زَمِيلُهُ" lemma="زَمِيلzamiyl" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839788350798833">
                        <morph_feature_set diac="زَمِيلِهِ" lemma="زَمِيل_1" gloss="colleague;associate;companion" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="زَمِيل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="زميل"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="zmyl" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="زميل" form1="زميل" form2="زَمِيل" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="زميل"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="54" word="جيمس">
                    <svm_prediction>
                        <morph_feature_set diac="جيمس" lemma="جيمسjyms" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="جيمس" lemma="جيمس_1" gloss="James" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="جيمس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جيمس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jyms" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جيمس" form1="جيمس" form2="جيمس" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جيمس"/>
                    </tokenized>
                </word>
                <word id="55" word="روبارت">
                    <svm_prediction>
                        <morph_feature_set diac="روبارت" lemma="روبارتrwbArt" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="na" vox="na" mod="na" gen="m" num="s" stt="na" cas="u" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="روبارت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="rwbArt" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="روبارت" form1="روبارت" form2="روبارت" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="روبارت"/>
                    </tokenized>
                </word>
                <word id="56" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="57" word="مدينة">
                    <svm_prediction>
                        <morph_feature_set diac="مَدِينَةِ" lemma="مَدِينَةmadiynap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8952524013582929">
                        <morph_feature_set diac="مَدِينَةِ" lemma="مَدِينَة_1" gloss="city" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="مَدِين"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مدينة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mdynp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مدينة" form1="مدينة" form2="مَدِينَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مدينة"/>
                    </tokenized>
                </word>
                <word id="58" word="سياتل">
                    <svm_prediction>
                        <morph_feature_set diac="سِياتِل" lemma="سِياتِلsiyAtil" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="سِياتِل" lemma="سِياتِل_1" gloss="Seattle" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="سِياتِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سياتل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="syAtl" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سياتل" form1="سياتل" form2="سِياتِل" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سياتل"/>
                    </tokenized>
                </word>
                <word id="59" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="60" word="باستمرار">
                    <svm_prediction>
                        <morph_feature_set diac="بِاِسْتِمْرارٍ" lemma="ٱِسْتِمْرار{isotimorAr" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8841168781742939">
                        <morph_feature_set diac="بِاِسْتِمْرارِ" lemma="ٱِسْتِمْرار_1" gloss="continuation;continuity" pos="noun" prc3="0" prc2="0" prc1="bi_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="ٱِسْتِمْرار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="استمرار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="b+" form1="PREP+"/>
                        <tok id="1" form0="AstmrAr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ب+" form1="ب+" form2="بِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="استمرار" form1="استمرار" form2="ٱِسْتِمْرار" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ب+"/>
                        <tok id="1" form0="استمرار"/>
                    </tokenized>
                </word>
                <word id="61" word="دخول">
                    <svm_prediction>
                        <morph_feature_set diac="دُخُولِ" lemma="دُخُولduxuwl" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="دُخُولِ" lemma="دُخُول_1" gloss="entrance;penetration" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="دُخُول"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="دخول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="dxwl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="دخول" form1="دخول" form2="دُخُول" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="دخول"/>
                    </tokenized>
                </word>
                <word id="62" word="المسلمين">
                    <svm_prediction>
                        <morph_feature_set diac="المُسْلِمِينَ" lemma="مُسْلِمmusolim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.894230475774278">
                        <morph_feature_set diac="المُسْلِمِينَ" lemma="مُسْلِم_1" gloss="Muslim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="d" cas="g" enc0="0" stem="مُسْلِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المسلمين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mslmyn" form1="NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المسلمين" form1="المسلمين" form2="مُسْلِم" form3="NOM" form4="DT+NNS" form5="DET+NOUN+NSUFF_MASC_PL_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="مسلمين"/>
                    </tokenized>
                </word>
                <word id="63" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="64" word="الدول">
                    <svm_prediction>
                        <morph_feature_set diac="الدُّوَلِ" lemma="دَوْلَةdawolap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الدُّوَلِ" lemma="دَوْلَة_1" gloss="states;countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="دُوَل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الدول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dwl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الدول" form1="الدول" form2="دَوْلَة" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="دول"/>
                    </tokenized>
                </word>
                <word id="65" word="السبع">
                    <svm_prediction>
                        <morph_feature_set diac="السَّبْعِ" lemma="سَبْعsaboE" pos="noun_num" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8297979948737684">
                        <morph_feature_set diac="السَّبْعِ" lemma="سَبْع_1" gloss="lion;predatory_beast" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="سَبْع"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السبع"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="sbE" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السبع" form1="السبع" form2="سَبْع" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سبع"/>
                    </tokenized>
                </word>
                <word id="66" word="المحظورة">
                    <svm_prediction>
                        <morph_feature_set diac="المَحْظُورَةِ" lemma="مَحْظُورmaHoZuwr" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="المَحْظُورَةِ" lemma="مَحْظُور_1" gloss="banned;prohibited;forbidden" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مَحْظُور"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المحظورة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mHZwrp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المحظورة" form1="المحظورة" form2="مَحْظُور" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="محظورة"/>
                    </tokenized>
                </word>
                <word id="67" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="68" word="فقد">
                    <svm_prediction>
                        <morph_feature_set diac="فَقَدَ" lemma="قَدْqado" pos="part_verb" prc3="0" prc2="fa_conn" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8210293179728595">
                        <morph_feature_set diac="فَقَد" lemma="قَدْ_1" gloss="(has;have)" pos="part_verb" prc3="0" prc2="fa_conj" prc1="0" prc0="na" per="na" asp="i" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="قَد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="قد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="f+" form1="CONJ+"/>
                        <tok id="1" form0="qd" form1="VERB_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ف+" form1="ف+" form2="فَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="قد" form1="قد" form2="قَدْ" form3="PRT" form4="RP" form5="VERB_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ف+"/>
                        <tok id="1" form0="قد"/>
                    </tokenized>
                </word>
                <word id="69" word="بيض">
                    <svm_prediction>
                        <morph_feature_set diac="بِيضٍ" lemma="بَيْضbayoD" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.885277866901877">
                        <morph_feature_set diac="بَيْضٍ" lemma="بَيْض_1" gloss="eggs" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="g" enc0="0" stem="بَيْض"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بيض"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="byD" form1="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بيض" form1="بيض" form2="بَيْض" form3="NOM" form4="NN" form5="NOUN+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بيض"/>
                    </tokenized>
                </word>
                <word id="70" word="صفحة">
                    <svm_prediction>
                        <morph_feature_set diac="صَفْحَةً" lemma="صَفْحَةSafoHap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8849539284493109">
                        <morph_feature_set diac="صَفْحَةِ" lemma="صَفْحَة_1" gloss="page;leaf" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="0" stem="صَفْح"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="صفحة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="SfHp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="صفحة" form1="صفحة" form2="صَفْحَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="صفحة"/>
                    </tokenized>
                </word>
                <word id="71" word="الديمقراطية">
                    <svm_prediction>
                        <morph_feature_set diac="الدِّيمُقراطِيَّةِ" lemma="دِيمُوقراطِيّdiymuwqrATiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="الدِّيمُقراطِيَّةِ" lemma="دِيمُوقراطِيّ_1" gloss="democratic" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="دِيمُقراطِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الديمقراطية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="dymqrATyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الديمقراطية" form1="الديمقراطية" form2="دِيمُوقراطِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ديمقراطية"/>
                    </tokenized>
                </word>
                <word id="72" word="الامريكية">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْرِيكِيَّةِ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8267406702887713">
                        <morph_feature_set diac="الأَمْرِيكِيَّةِ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامريكية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amrykyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمريكية" form1="الامريكية" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكية"/>
                    </tokenized>
                </word>
                <word id="73" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="74" word="وان">
                    <svm_prediction>
                        <morph_feature_set diac="وَأَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.81393677270044">
                        <morph_feature_set diac="وَأَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                </word>
                <word id="75" word="كان">
                    <svm_prediction>
                        <morph_feature_set diac="كانَ" lemma="كانkAn" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="كانَ" lemma="كان_1" gloss="was;were" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="كان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="kAn" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كان" form1="كان" form2="كان" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كان"/>
                    </tokenized>
                </word>
                <word id="76" word="الكثير">
                    <svm_prediction>
                        <morph_feature_set diac="الكَثِيرُ" lemma="كَثِيرkaviyr" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8256442379770365">
                        <morph_feature_set diac="الكَثِيرُ" lemma="كَثِير_1" gloss="many;much;numerous" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="كَثِير"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الكثير"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="kvyr" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الكثير" form1="الكثير" form2="كَثِير" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="كثير"/>
                    </tokenized>
                </word>
                <word id="77" word="منا">
                    <svm_prediction>
                        <morph_feature_set diac="مِنّا" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="1p_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مِنّا" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="1p_pron" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                        <tok id="1" form0="+nA" form1="+PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP" form5="+PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="78" word="لا">
                    <svm_prediction>
                        <morph_feature_set diac="لا" lemma="لاlA" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="لا" lemma="لا_1" gloss="no;not" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="lA" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="لا" form1="لا" form2="لا" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                </word>
                <word id="79" word="يمكن">
                    <svm_prediction>
                        <morph_feature_set diac="يُمَكِّن" lemma="أَمْكَن&gt;amokan" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8453274094899743">
                        <morph_feature_set diac="يُمْكِن" lemma="أَمْكَن_1" gloss="be_possible;make_possible_for" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="مْكِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يمكن"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ymkn" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يمكن" form1="يمكن" form2="أَمْكَن" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يمكن"/>
                    </tokenized>
                </word>
                <word id="80" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8155640401058297">
                        <morph_feature_set diac="أَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="81" word="ينسى">
                    <svm_prediction>
                        <morph_feature_set diac="يَنْسَى" lemma="نَسِيnasiy" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="يَنْسَى" lemma="نَسِي-َ_1" gloss="forget" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="نْسَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ينسي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ynsy" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ينسى" form1="ينسي" form2="نَسِي" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ينسي"/>
                    </tokenized>
                </word>
                <word id="82" word="جرائم">
                    <svm_prediction>
                        <morph_feature_set diac="جَرائِمَ" lemma="جَرِيمَةjariymap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8969741517107328">
                        <morph_feature_set diac="جَرائِمَ" lemma="جَرِيمَة_1" gloss="crimes" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="0" stem="جَرائِم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jrA}m" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جرائم" form1="جرائم" form2="جَرِيمَة" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جرائم"/>
                    </tokenized>
                </word>
                <word id="83" word="امريكا">
                    <svm_prediction>
                        <morph_feature_set diac="أَمْرِيكا" lemma="أَمْرِيكا&gt;amoriykA" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="أَمْرِيكا" lemma="أَمْرِيكا_1" gloss="America" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="أَمْرِيكا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="امريكا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="AmrykA" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أمريكا" form1="امريكا" form2="أَمْرِيكا" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="امريكا"/>
                    </tokenized>
                </word>
                <word id="84" word="في">
                    <svm_prediction>
                        <morph_feature_set diac="فِي" lemma="فِيfiy" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="فِي" lemma="فِي_1" gloss="in" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="فِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="في"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="fy" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="في" form1="في" form2="فِي" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="في"/>
                    </tokenized>
                </word>
                <word id="85" word="بلداننا">
                    <svm_prediction>
                        <morph_feature_set diac="بُلْدانِنا" lemma="بَلَدbalad" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939458006110683">
                        <morph_feature_set diac="بُلْدانِنا" lemma="بَلَد_1" gloss="countries" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="1p_poss" stem="بُلْدان"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بلدان"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="bldAn" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+nA" form1="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بلدان" form1="بلدان" form2="بَلَد" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بلدان"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
                <word id="86" word="العربية">
                    <svm_prediction>
                        <morph_feature_set diac="العَرَبِيَّةِ" lemma="عَرَبِيّEarabiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="العَرَبِيَّةِ" lemma="عَرَبِيّ_1" gloss="Arabic;Arab" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="عَرَبِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العربية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Erbyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العربية" form1="العربية" form2="عَرَبِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عربية"/>
                    </tokenized>
                </word>
                <word id="87" word="والإسلامية">
                    <svm_prediction>
                        <morph_feature_set diac="وَالإِسْلامِيَّةِ" lemma="إِسْلامِيّ&lt;isolAmiy~" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89402085509488">
                        <morph_feature_set diac="وَالإِسْلامِيَّةِ" lemma="إِسْلامِيّ_1" gloss="Islamic;Islamist;Muslim" pos="adj" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="إِسْلامِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الاسلامية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="AslAmyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الإسلامية" form1="الاسلامية" form2="إِسْلامِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="اسلامية"/>
                    </tokenized>
                </word>
                <word id="88" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="89" word="ومئات">
                    <svm_prediction>
                        <morph_feature_set diac="وَمِئاتٌ" lemma="مِئَةmi}ap" pos="noun_num" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8141886590707959">
                        <morph_feature_set diac="وَمِئاتُ" lemma="مِئَة_1" gloss="hundreds" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="p" stt="c" cas="n" enc0="0" stem="مِئ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مئات"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="m}At" form1="NOUN+NSUFF_FEM_PL+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="مئات" form1="مئات" form2="مِئَة" form3="NOM" form4="NNS" form5="NOUN+NSUFF_FEM_PL+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="مئات"/>
                    </tokenized>
                </word>
                <word id="90" word="الآلاف">
                    <svm_prediction>
                        <morph_feature_set diac="الأُلّافِ" lemma="أَلْف&gt;alof" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8847645546831359">
                        <morph_feature_set diac="الآلافُ" lemma="أَلْف_1" gloss="thousands" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="آلاف"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الالاف"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AlAf" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الآلاف" form1="الالاف" form2="أَلْف" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="الاف"/>
                    </tokenized>
                </word>
                <word id="91" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="92" word="الضحايا">
                    <svm_prediction>
                        <morph_feature_set diac="الضَّحايا" lemma="ضَحِيَّةDaHiy~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943368191769413">
                        <morph_feature_set diac="الضَّحايا" lemma="ضَحِيَّة_1" gloss="victims" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="ضَحايا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الضحايا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="DHAyA" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الضحايا" form1="الضحايا" form2="ضَحِيَّة" form3="NOM" form4="DT+NN" form5="DET+NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ضحايا"/>
                    </tokenized>
                </word>
                <word id="93" word="الذين">
                    <svm_prediction>
                        <morph_feature_set diac="الَّذِينَ" lemma="الَّذِيAl~a*iy" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="الَّذِينَ" lemma="الَّذِي_1" gloss="who;whom_[pl.]" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="p" stt="i" cas="u" enc0="0" stem="الَّذِينَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الذين"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al*yn" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الذين" form1="الذين" form2="الَّذِي" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="الذين"/>
                    </tokenized>
                </word>
                <word id="94" word="سقطوا">
                    <svm_prediction>
                        <morph_feature_set diac="سَقَطُوا" lemma="سَقَطsaqaT" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="سَقَطُوا" lemma="سَقَط-ُ_1" gloss="fall;drop" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="سَقَط"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="سقطوا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="sqTwA" form1="PV+PVSUFF_SUBJ:3MP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="سقطوا" form1="سقطوا" form2="سَقَط" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="سقطوا"/>
                    </tokenized>
                </word>
                <word id="95" word="ضحية">
                    <svm_prediction>
                        <morph_feature_set diac="ضَحِيَّةَ" lemma="ضَحِيَّةDaHiy~ap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942991902109341">
                        <morph_feature_set diac="ضَحِيَّةَ" lemma="ضَحِيَّة_1" gloss="victim" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0" stem="ضَحِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ضحية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="DHyp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ضحية" form1="ضحية" form2="ضَحِيَّة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ضحية"/>
                    </tokenized>
                </word>
                <word id="96" word="لها">
                    <svm_prediction>
                        <morph_feature_set diac="لَها" lemma="لِli" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8942873284255194">
                        <morph_feature_set diac="لَها" lemma="لِ_1" gloss="to;for_+_it;them;her_(it;she_has,_they_have)" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="3fs_pron" stem="لَها"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l" form1="PREP"/>
                        <tok id="1" form0="+hA" form1="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل" form1="ل" form2="لِ" form3="PRT" form4="IN" form5="PREP"/>
                        <tok id="1" form0="+ها" form1="+ها" form2="+ها" form3="+NOM" form4="+PRP" form5="+PRON_3FS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل"/>
                        <tok id="1" form0="+ها"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        
        <out_seg id="SENT13">
            <segment_info>
                <preprocessed>نتمنى للرئيس النيجيري والامريكي الشفاء العاجل , الأول من ازمته الصحية , والثاني من جنونه العقلي , وعنصريته المتأصلة , وان كنا نعتقد ان حالة الأخير مستعصية على العلاج والشفاء التام , ولذلك لا نستبعد ان يغادر البيت الأبيض مطرودا , وتولي نائبه مايك بينس , على غرار ما حدث للرئيس الأمريكي السابق ريتشارد نيكسون</preprocessed>
                <bpc>
                    <chunk id="0" type="VP">
                        <tok id="0" form0="نتمني"/>
                    </chunk>
                    <chunk id="1" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="نيجيري"/>
                    </chunk>
                    <chunk id="3" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="4" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكي"/>
                    </chunk>
                    <chunk id="5" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شفاء"/>
                    </chunk>
                    <chunk id="6" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عاجل"/>
                    </chunk>
                    <chunk id="7" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="8" type="ADJP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اول"/>
                    </chunk>
                    <chunk id="9" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="10" type="NP">
                        <tok id="0" form0="ازمة"/>
                    </chunk>
                    <chunk id="11" type="NP">
                        <tok id="0" form0="+ه"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="صحية"/>
                    </chunk>
                    <chunk id="12" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="13" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="14" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ثاني"/>
                    </chunk>
                    <chunk id="15" type="PP">
                        <tok id="0" form0="من"/>
                    </chunk>
                    <chunk id="16" type="NP">
                        <tok id="0" form0="جنون"/>
                    </chunk>
                    <chunk id="17" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="18" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عقلي"/>
                    </chunk>
                    <chunk id="19" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="20" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="21" type="NP">
                        <tok id="0" form0="عنصرية"/>
                    </chunk>
                    <chunk id="22" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="23" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="متاصلة"/>
                    </chunk>
                    <chunk id="24" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="25" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="26" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="27" type="VP">
                        <tok id="0" form0="كنا"/>
                    </chunk>
                    <chunk id="28" type="VP">
                        <tok id="0" form0="نعتقد"/>
                    </chunk>
                    <chunk id="29" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="30" type="NP">
                        <tok id="0" form0="حالة"/>
                    </chunk>
                    <chunk id="31" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اخير"/>
                    </chunk>
                    <chunk id="32" type="NP">
                        <tok id="0" form0="مستعصية"/>
                    </chunk>
                    <chunk id="33" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="34" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="علاج"/>
                        <tok id="2" form0="و+"/>
                        <tok id="3" form0="ال+"/>
                        <tok id="4" form0="شفاء"/>
                    </chunk>
                    <chunk id="35" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="تام"/>
                    </chunk>
                    <chunk id="36" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="37" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="38" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="39" type="NP">
                        <tok id="0" form0="ذلك"/>
                    </chunk>
                    <chunk id="40" type="VP">
                        <tok id="0" form0="لا"/>
                        <tok id="1" form0="نستبعد"/>
                    </chunk>
                    <chunk id="41" type="SBAR">
                        <tok id="0" form0="ان"/>
                    </chunk>
                    <chunk id="42" type="VP">
                        <tok id="0" form0="يغادر"/>
                    </chunk>
                    <chunk id="43" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="بيت"/>
                    </chunk>
                    <chunk id="44" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ابيض"/>
                    </chunk>
                    <chunk id="45" type="ADJP">
                        <tok id="0" form0="مطرودا"/>
                    </chunk>
                    <chunk id="46" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="47" type="">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="48" type="VP">
                        <tok id="0" form0="تولي"/>
                    </chunk>
                    <chunk id="49" type="NP">
                        <tok id="0" form0="نائب"/>
                    </chunk>
                    <chunk id="50" type="NP">
                        <tok id="0" form0="+ه"/>
                    </chunk>
                    <chunk id="51" type="NP">
                        <tok id="0" form0="مايك"/>
                        <tok id="1" form0="بينس"/>
                    </chunk>
                    <chunk id="52" type="">
                        <tok id="0" form0=","/>
                    </chunk>
                    <chunk id="53" type="PP">
                        <tok id="0" form0="علي"/>
                    </chunk>
                    <chunk id="54" type="NP">
                        <tok id="0" form0="غرار"/>
                    </chunk>
                    <chunk id="55" type="WHNP">
                        <tok id="0" form0="ما"/>
                    </chunk>
                    <chunk id="56" type="VP">
                        <tok id="0" form0="حدث"/>
                    </chunk>
                    <chunk id="57" type="PP">
                        <tok id="0" form0="ل+"/>
                    </chunk>
                    <chunk id="58" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="رئيس"/>
                        <tok id="2" form0="ال+"/>
                        <tok id="3" form0="امريكي"/>
                        <tok id="4" form0="ال+"/>
                        <tok id="5" form0="سابق"/>
                    </chunk>
                    <chunk id="59" type="NP">
                        <tok id="0" form0="ريتشارد"/>
                    </chunk>
                    <chunk id="60" type="NP">
                        <tok id="0" form0="نيكسون"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="نتمني"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="ل+"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ال+"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="رئيس"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="ال+"/>
                    </ne>
                    <ne id="5" type="">
                        <tok id="5" form0="نيجيري"/>
                    </ne>
                    <ne id="6" type="">
                        <tok id="6" form0="و+"/>
                    </ne>
                    <ne id="7" type="LOC">
                        <tok id="7" form0="ال+"/>
                        <tok id="7" form0="امريكي"/>
                    </ne>
                    <ne id="8" type="">
                        <tok id="8" form0="ال+"/>
                    </ne>
                    <ne id="9" type="">
                        <tok id="9" form0="شفاء"/>
                    </ne>
                    <ne id="10" type="">
                        <tok id="10" form0="ال+"/>
                    </ne>
                    <ne id="11" type="">
                        <tok id="11" form0="عاجل"/>
                    </ne>
                    <ne id="12" type="">
                        <tok id="12" form0=","/>
                    </ne>
                    <ne id="13" type="">
                        <tok id="13" form0="ال+"/>
                    </ne>
                    <ne id="14" type="">
                        <tok id="14" form0="اول"/>
                    </ne>
                    <ne id="15" type="">
                        <tok id="15" form0="من"/>
                    </ne>
                    <ne id="16" type="">
                        <tok id="16" form0="ازمة"/>
                    </ne>
                    <ne id="17" type="">
                        <tok id="17" form0="+ه"/>
                    </ne>
                    <ne id="18" type="">
                        <tok id="18" form0="ال+"/>
                    </ne>
                    <ne id="19" type="">
                        <tok id="19" form0="صحية"/>
                    </ne>
                    <ne id="20" type="">
                        <tok id="20" form0=","/>
                    </ne>
                    <ne id="21" type="">
                        <tok id="21" form0="و+"/>
                    </ne>
                    <ne id="22" type="">
                        <tok id="22" form0="ال+"/>
                    </ne>
                    <ne id="23" type="">
                        <tok id="23" form0="ثاني"/>
                    </ne>
                    <ne id="24" type="">
                        <tok id="24" form0="من"/>
                    </ne>
                    <ne id="25" type="">
                        <tok id="25" form0="جنون"/>
                    </ne>
                    <ne id="26" type="">
                        <tok id="26" form0="+ه"/>
                    </ne>
                    <ne id="27" type="">
                        <tok id="27" form0="ال+"/>
                    </ne>
                    <ne id="28" type="">
                        <tok id="28" form0="عقلي"/>
                    </ne>
                    <ne id="29" type="">
                        <tok id="29" form0=","/>
                    </ne>
                    <ne id="30" type="">
                        <tok id="30" form0="و+"/>
                    </ne>
                    <ne id="31" type="">
                        <tok id="31" form0="عنصرية"/>
                    </ne>
                    <ne id="32" type="">
                        <tok id="32" form0="+ه"/>
                    </ne>
                    <ne id="33" type="">
                        <tok id="33" form0="ال+"/>
                    </ne>
                    <ne id="34" type="">
                        <tok id="34" form0="متاصلة"/>
                    </ne>
                    <ne id="35" type="">
                        <tok id="35" form0=","/>
                    </ne>
                    <ne id="36" type="">
                        <tok id="36" form0="و+"/>
                    </ne>
                    <ne id="37" type="">
                        <tok id="37" form0="ان"/>
                    </ne>
                    <ne id="38" type="">
                        <tok id="38" form0="كنا"/>
                    </ne>
                    <ne id="39" type="">
                        <tok id="39" form0="نعتقد"/>
                    </ne>
                    <ne id="40" type="">
                        <tok id="40" form0="ان"/>
                    </ne>
                    <ne id="41" type="">
                        <tok id="41" form0="حالة"/>
                    </ne>
                    <ne id="42" type="">
                        <tok id="42" form0="ال+"/>
                    </ne>
                    <ne id="43" type="">
                        <tok id="43" form0="اخير"/>
                    </ne>
                    <ne id="44" type="">
                        <tok id="44" form0="مستعصية"/>
                    </ne>
                    <ne id="45" type="">
                        <tok id="45" form0="علي"/>
                    </ne>
                    <ne id="46" type="">
                        <tok id="46" form0="ال+"/>
                    </ne>
                    <ne id="47" type="">
                        <tok id="47" form0="علاج"/>
                    </ne>
                    <ne id="48" type="">
                        <tok id="48" form0="و+"/>
                    </ne>
                    <ne id="49" type="">
                        <tok id="49" form0="ال+"/>
                    </ne>
                    <ne id="50" type="">
                        <tok id="50" form0="شفاء"/>
                    </ne>
                    <ne id="51" type="">
                        <tok id="51" form0="ال+"/>
                    </ne>
                    <ne id="52" type="">
                        <tok id="52" form0="تام"/>
                    </ne>
                    <ne id="53" type="">
                        <tok id="53" form0=","/>
                    </ne>
                    <ne id="54" type="">
                        <tok id="54" form0="و+"/>
                    </ne>
                    <ne id="55" type="">
                        <tok id="55" form0="ل+"/>
                    </ne>
                    <ne id="56" type="">
                        <tok id="56" form0="ذلك"/>
                    </ne>
                    <ne id="57" type="">
                        <tok id="57" form0="لا"/>
                    </ne>
                    <ne id="58" type="">
                        <tok id="58" form0="نستبعد"/>
                    </ne>
                    <ne id="59" type="">
                        <tok id="59" form0="ان"/>
                    </ne>
                    <ne id="60" type="">
                        <tok id="60" form0="يغادر"/>
                    </ne>
                    <ne id="61" type="LOC">
                        <tok id="61" form0="ال+"/>
                        <tok id="61" form0="بيت"/>
                    </ne>
                    <ne id="62" type="">
                        <tok id="62" form0="ال+"/>
                    </ne>
                    <ne id="63" type="">
                        <tok id="63" form0="ابيض"/>
                    </ne>
                    <ne id="64" type="">
                        <tok id="64" form0="مطرودا"/>
                    </ne>
                    <ne id="65" type="">
                        <tok id="65" form0=","/>
                    </ne>
                    <ne id="66" type="">
                        <tok id="66" form0="و+"/>
                    </ne>
                    <ne id="67" type="">
                        <tok id="67" form0="تولي"/>
                    </ne>
                    <ne id="68" type="">
                        <tok id="68" form0="نائب"/>
                    </ne>
                    <ne id="69" type="">
                        <tok id="69" form0="+ه"/>
                    </ne>
                    <ne id="70" type="PER">
                        <tok id="70" form0="مايك"/>
                        <tok id="70" form0="بينس"/>
                    </ne>
                    <ne id="71" type="">
                        <tok id="71" form0=","/>
                    </ne>
                    <ne id="72" type="">
                        <tok id="72" form0="علي"/>
                    </ne>
                    <ne id="73" type="">
                        <tok id="73" form0="غرار"/>
                    </ne>
                    <ne id="74" type="">
                        <tok id="74" form0="ما"/>
                    </ne>
                    <ne id="75" type="">
                        <tok id="75" form0="حدث"/>
                    </ne>
                    <ne id="76" type="">
                        <tok id="76" form0="ل+"/>
                    </ne>
                    <ne id="77" type="">
                        <tok id="77" form0="ال+"/>
                    </ne>
                    <ne id="78" type="">
                        <tok id="78" form0="رئيس"/>
                    </ne>
                    <ne id="79" type="LOC">
                        <tok id="79" form0="ال+"/>
                        <tok id="79" form0="امريكي"/>
                    </ne>
                    <ne id="80" type="">
                        <tok id="80" form0="ال+"/>
                    </ne>
                    <ne id="81" type="">
                        <tok id="81" form0="سابق"/>
                    </ne>
                    <ne id="82" type="PER">
                        <tok id="82" form0="ريتشارد"/>
                        <tok id="82" form0="نيكسون"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="نتمنى">
                    <svm_prediction>
                        <morph_feature_set diac="نَتَمَنَّى" lemma="تَمَنَّىtaman~aY" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="نَتَمَنَّى" lemma="تَمَنَّى_1" gloss="desire;wish_for;hope" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="u" gen="m" num="p" stt="na" cas="na" enc0="0" stem="تَمَنَّى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نتمني"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ntmny" form1="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نتمنى" form1="نتمني" form2="تَمَنَّى" form3="VRB" form4="VBP" form5="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نتمني"/>
                    </tokenized>
                </word>
                <word id="1" word="للرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="لِلرَّئِيسِ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944374375687777">
                        <morph_feature_set diac="لِلرَّئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="2" word="النيجيري">
                    <svm_prediction>
                        <morph_feature_set diac="النَّيْجِيرِيِّ" lemma="نَيْجِيرِيّnayojiyriy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="النَّيْجِيرِيِّ" lemma="نَيْجِيرِيّ_1" gloss="Nigerian" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="نَيْجِيرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="النيجيري"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="nyjyry" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="النيجيري" form1="النيجيري" form2="نَيْجِيرِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="نيجيري"/>
                    </tokenized>
                </word>
                <word id="3" word="والامريكي">
                    <svm_prediction>
                        <morph_feature_set diac="وَالأَمْرِيكِيُّ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8242636721992672">
                        <morph_feature_set diac="وَالأَمْرِيكِيُّ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الامريكي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="Amryky" form1="NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الأمريكي" form1="الامريكي" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="امريكي"/>
                    </tokenized>
                </word>
                <word id="4" word="الشفاء">
                    <svm_prediction>
                        <morph_feature_set diac="الشِّفاءِ" lemma="شِفاء$ifA'" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="الشِّفاءِ" lemma="شِفاء_1" gloss="cure;remedy;medication" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شِفاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الشفاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="$fA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الشفاء" form1="الشفاء" form2="شِفاء" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="شفاء"/>
                    </tokenized>
                </word>
                <word id="5" word="العاجل">
                    <svm_prediction>
                        <morph_feature_set diac="العاجِلِ" lemma="عاجِلEAjil" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8297979948737684">
                        <morph_feature_set diac="العاجِلِ" lemma="عاجِل_1" gloss="urgent;speedy" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عاجِل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العاجل"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="EAjl" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العاجل" form1="العاجل" form2="عاجِل" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عاجل"/>
                    </tokenized>
                </word>
                <word id="6" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="7" word="الأول">
                    <svm_prediction>
                        <morph_feature_set diac="الأَوَّلُ" lemma="أَوَّل&gt;aw~al" pos="adj_num" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.825037667282893">
                        <morph_feature_set diac="الأَوَّلُ" lemma="أَوَّل_2" gloss="first" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="n" enc0="0" stem="أَوَّل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاول"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Awl" form1="ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأول" form1="الاول" form2="أَوَّل" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_NOM"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اول"/>
                    </tokenized>
                </word>
                <word id="8" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="9" word="ازمته">
                    <svm_prediction>
                        <morph_feature_set diac="أَزْمَتِهِ" lemma="أَزْمَة&gt;azomap" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8242368816837278">
                        <morph_feature_set diac="أَزْمَتِهِ" lemma="أَزْمَة_1" gloss="crisis" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss" stem="أَزْم"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ازمة"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Azmp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أزمة" form1="ازمة" form2="أَزْمَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ازمة"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="10" word="الصحية">
                    <svm_prediction>
                        <morph_feature_set diac="الصِّحِّيَّةِ" lemma="صِحِّيّSiH~iy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.89652034891024">
                        <morph_feature_set diac="الصِّحِّيَّةِ" lemma="صِحِّيّ_1" gloss="health;healthy;sanitary" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="صِحِّيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الصحية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="SHyp" form1="ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الصحية" form1="الصحية" form2="صِحِّيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="صحية"/>
                    </tokenized>
                </word>
                <word id="11" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="12" word="والثاني">
                    <svm_prediction>
                        <morph_feature_set diac="وَالثّانِي" lemma="ثانِيvAniy" pos="adj_num" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8245276244728953">
                        <morph_feature_set diac="وَالثّانِي" lemma="ثانِي_2" gloss="Second" pos="noun_prop" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="u" enc0="0" stem="ثانِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الثاني"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="vAny" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الثاني" form1="الثاني" form2="ثانِي" form3="PROP" form4="DT+NNP" form5="DET+NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="ثاني"/>
                    </tokenized>
                </word>
                <word id="13" word="من">
                    <svm_prediction>
                        <morph_feature_set diac="مِن" lemma="مِنmin" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="مِن" lemma="مِن_1" gloss="from" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="مِن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="من"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mn" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="من" form1="من" form2="مِن" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="من"/>
                    </tokenized>
                </word>
                <word id="14" word="جنونه">
                    <svm_prediction>
                        <morph_feature_set diac="جُنُونَهُ" lemma="جُنُونjunuwn" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8839788350798833">
                        <morph_feature_set diac="جُنُونِهِ" lemma="جُنُون_1" gloss="madness;insanity" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="3ms_poss" stem="جُنُون"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="جنون"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="jnwn" form1="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="جنون" form1="جنون" form2="جُنُون" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="جنون"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="15" word="العقلي">
                    <svm_prediction>
                        <morph_feature_set diac="العَقْلِيُّ" lemma="عَقْلِيّEaqoliy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8854770597545845">
                        <morph_feature_set diac="العَقْلِيِّ" lemma="عَقْلِيّ_1" gloss="mental;intellectual" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عَقْلِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العقلي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Eqly" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العقلي" form1="العقلي" form2="عَقْلِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="عقلي"/>
                    </tokenized>
                </word>
                <word id="16" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="17" word="وعنصريته">
                    <svm_prediction>
                        <morph_feature_set diac="وَعُنْصُرِيَّتِهِ" lemma="عُنْصُرِيّEunoSuriy~" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8777801294363411">
                        <morph_feature_set diac="وَعُنْصُرِيَّتِهِ" lemma="عُنْصُرِيَّة_1" gloss="racism" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="g" enc0="3ms_poss" stem="عُنْصُرِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="عنصرية"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="EnSryp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="2" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="عنصرية" form1="عنصرية" form2="عُنْصُرِيَّة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                        <tok id="2" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="عنصرية"/>
                        <tok id="2" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="18" word="المتأصلة">
                    <svm_prediction>
                        <morph_feature_set diac="المُتَآصِلَةُ" lemma="مُتَآصِلmuta|Sil" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8695163055531967">
                        <morph_feature_set diac="المُتَأَصِّلَةِ" lemma="مُتَأَصِّل_1" gloss="deep-rooted" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="d" cas="g" enc0="0" stem="مُتَأَصِّل"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="المتاصلة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="mtASlp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="المتأصلة" form1="المتاصلة" form2="مُتَأَصِّل" form3="NOM" form4="DT+NN" form5="DET+NOUN+NSUFF_FEM_SG+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="متاصلة"/>
                    </tokenized>
                </word>
                <word id="19" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="20" word="وان">
                    <svm_prediction>
                        <morph_feature_set diac="وَأَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.81393677270044">
                        <morph_feature_set diac="وَأَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="wa_conj" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ان"/>
                    </tokenized>
                </word>
                <word id="21" word="كنا">
                    <svm_prediction>
                        <morph_feature_set diac="كُنّا" lemma="كانkAn" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939586845549484">
                        <morph_feature_set diac="كُنّا" lemma="كان_1" gloss="was;were" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="p" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0" stem="كُن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="كنا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="knA" form1="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="كنا" form1="كنا" form2="كان" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="كنا"/>
                    </tokenized>
                </word>
                <word id="22" word="نعتقد">
                    <svm_prediction>
                        <morph_feature_set diac="نَعْتَقِد" lemma="ٱِعْتَقَد{iEotaqad" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.855625882398956">
                        <morph_feature_set diac="نَعْتَقِد" lemma="ٱِعْتَقَد_1" gloss="believe" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="u" gen="m" num="p" stt="na" cas="na" enc0="0" stem="عْتَقِد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نعتقد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nEtqd" form1="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نعتقد" form1="نعتقد" form2="ٱِعْتَقَد" form3="VRB" form4="VBP" form5="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نعتقد"/>
                    </tokenized>
                </word>
                <word id="23" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ&gt;an~a" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8258625130148115">
                        <morph_feature_set diac="أَنَّ" lemma="أَنَّ_1" gloss="that" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَنَّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنَّ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="24" word="حالة">
                    <svm_prediction>
                        <morph_feature_set diac="حالَةَ" lemma="حالHAl" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8781605140395845">
                        <morph_feature_set diac="حالَةَ" lemma="حالَة_1" gloss="condition;case;situation" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="c" cas="a" enc0="0" stem="حال"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حالة"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="HAlp" form1="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حالة" form1="حالة" form2="حالَة" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حالة"/>
                    </tokenized>
                </word>
                <word id="25" word="الأخير">
                    <svm_prediction>
                        <morph_feature_set diac="الأَخِيرِ" lemma="أَخِير&gt;axiyr" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="الأَخِيرِ" lemma="أَخِير_1" gloss="last;latest;recent;latter" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَخِير"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الاخير"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Axyr" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأخير" form1="الاخير" form2="أَخِير" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="اخير"/>
                    </tokenized>
                </word>
                <word id="26" word="مستعصية">
                    <svm_prediction>
                        <morph_feature_set diac="مُسْتَعْصِيَةٍ" lemma="مُسْتَعْصِيmusotaEoSiy" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8250767280827742">
                        <morph_feature_set diac="مُسْتَعْصِيَةٍ" lemma="مُسْتَعْصِي_1" gloss="difficult;incurable" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="f" num="s" stt="i" cas="g" enc0="0" stem="مُسْتَعْصِي"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مستعصية"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mstESyp" form1="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مستعصية" form1="مستعصية" form2="مُسْتَعْصِي" form3="NOM" form4="NN" form5="NOUN+NSUFF_FEM_SG+CASE_INDEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مستعصية"/>
                    </tokenized>
                </word>
                <word id="27" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="28" word="العلاج">
                    <svm_prediction>
                        <morph_feature_set diac="العِلاجِ" lemma="عِلاجEilAj" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8992167844888498">
                        <morph_feature_set diac="العِلاجِ" lemma="عِلاج_1" gloss="medical_treatment;therapy;processing" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="عِلاج"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="العلاج"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="ElAj" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="العلاج" form1="العلاج" form2="عِلاج" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="علاج"/>
                    </tokenized>
                </word>
                <word id="29" word="والشفاء">
                    <svm_prediction>
                        <morph_feature_set diac="وَالشِّفاءَ" lemma="شِفاء$ifA'" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8840377328850475">
                        <morph_feature_set diac="وَالشِّفاءِ" lemma="شِفاء_1" gloss="cure;remedy;medication" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="شِفاء"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الشفاء"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="$fA'" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الشفاء" form1="الشفاء" form2="شِفاء" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="شفاء"/>
                    </tokenized>
                </word>
                <word id="30" word="التام">
                    <svm_prediction>
                        <morph_feature_set diac="التّامِّ" lemma="تامّtAm~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8297979948737684">
                        <morph_feature_set diac="التّامِّ" lemma="تامّ_1" gloss="complete;concluded" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="تامّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="التام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="tAm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="التام" form1="التام" form2="تامّ" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="تام"/>
                    </tokenized>
                </word>
                <word id="31" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="32" word="ولذلك">
                    <svm_prediction>
                        <morph_feature_set diac="وَلِذٰلِكَ" lemma="ذٰلِكَ*`lika" pos="pron_dem" prc3="0" prc2="wa_conj" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8939071486460922">
                        <morph_feature_set diac="وَلِذٰلِكَ" lemma="ذٰلِكَ_1" gloss="that" pos="pron_dem" prc3="0" prc2="wa_conj" prc1="li_prep" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ذٰلِكَ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ل+"/>
                        <tok id="2" form0="ذلك"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="l+" form1="PREP+"/>
                        <tok id="2" form0="*lk" form1="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="2" form0="ذلك" form1="ذلك" form2="ذٰلِكَ" form3="NOM" form4="DEM" form5="DEM_PRON_MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ل+"/>
                        <tok id="2" form0="ذلك"/>
                    </tokenized>
                </word>
                <word id="33" word="لا">
                    <svm_prediction>
                        <morph_feature_set diac="لا" lemma="لاlA" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="لا" lemma="لا_1" gloss="no;not" pos="part_neg" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="لا"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="lA" form1="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="لا" form1="لا" form2="لا" form3="PRT" form4="RP" form5="NEG_PART"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="لا"/>
                    </tokenized>
                </word>
                <word id="34" word="نستبعد">
                    <svm_prediction>
                        <morph_feature_set diac="نَسْتَبْعِد" lemma="ٱِسْتَبْعَد{isotaboEad" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="i" gen="m" num="p" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="نَسْتَبْعِد" lemma="ٱِسْتَبْعَد_1" gloss="rule_out;reject" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="1" asp="i" vox="a" mod="u" gen="m" num="p" stt="na" cas="na" enc0="0" stem="سْتَبْعِد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نستبعد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nstbEd" form1="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نستبعد" form1="نستبعد" form2="ٱِسْتَبْعَد" form3="VRB" form4="VBP" form5="IV1P+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نستبعد"/>
                    </tokenized>
                </word>
                <word id="35" word="ان">
                    <svm_prediction>
                        <morph_feature_set diac="أَنَّ" lemma="أَنْ&gt;ano" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8155640401058297">
                        <morph_feature_set diac="أَن" lemma="أَنْ_1" gloss="to" pos="conj_sub" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="أَن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="An" form1="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="أن" form1="ان" form2="أَنْ" form3="PRT" form4="AN" form5="SUB_CONJ"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ان"/>
                    </tokenized>
                </word>
                <word id="36" word="يغادر">
                    <svm_prediction>
                        <morph_feature_set diac="يُغادِر" lemma="غادَرgAdar" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="s" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="يُغادِر" lemma="غادَر_1" gloss="leave;depart" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="i" vox="a" mod="u" gen="m" num="s" stt="na" cas="na" enc0="0" stem="غادِر"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="يغادر"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ygAdr" form1="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="يغادر" form1="يغادر" form2="غادَر" form3="VRB" form4="VBP" form5="IV3MS+IV"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="يغادر"/>
                    </tokenized>
                </word>
                <word id="37" word="البيت">
                    <svm_prediction>
                        <morph_feature_set diac="البَيْتِ" lemma="بَيْتbayot" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8849138440518091">
                        <morph_feature_set diac="البَيْتَ" lemma="بَيْت_3" gloss="house" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="بَيْت"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="البيت"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="byt" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="البيت" form1="البيت" form2="بَيْت" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="بيت"/>
                    </tokenized>
                </word>
                <word id="38" word="الأبيض">
                    <svm_prediction>
                        <morph_feature_set diac="الأَبْيَضِ" lemma="أَبْيَض&gt;aboyaD" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8154950544367279">
                        <morph_feature_set diac="الأَبْيَضَ" lemma="أَبْيَض_1" gloss="white" pos="noun" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="a" enc0="0" stem="أَبْيَض"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الابيض"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="AbyD" form1="NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأبيض" form1="الابيض" form2="أَبْيَض" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_ACC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ابيض"/>
                    </tokenized>
                </word>
                <word id="39" word="مطرودا">
                    <svm_prediction>
                        <morph_feature_set diac="مطرودا" lemma="مطروداmTrwdA" pos="adj" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="a" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مطرودا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mTrwdA" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مطرودا" form1="مطرودا" form2="مطرودا" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مطرودا"/>
                    </tokenized>
                </word>
                <word id="40" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="41" word="وتولي">
                    <svm_prediction>
                        <morph_feature_set diac="وَتَوَلَّى" lemma="تَوَلَّىtawal~aY" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8950153762285171">
                        <morph_feature_set diac="وَتَوَلَّى" lemma="تَوَلَّى_1" gloss="take_charge_of;be_in_charge_of;seize_control_of" pos="verb" prc3="0" prc2="wa_conj" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="تَوَلَّى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="تولي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="twly" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="تولى" form1="تولي" form2="تَوَلَّى" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="تولي"/>
                    </tokenized>
                </word>
                <word id="42" word="نائبه">
                    <svm_prediction>
                        <morph_feature_set diac="نائِبُهُ" lemma="نائِبnA}ib" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3ms_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.893981385012648">
                        <morph_feature_set diac="نائِبُهُ" lemma="نائِب_1" gloss="deputy;delegate;vice-" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="n" enc0="3ms_poss" stem="نائِب"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نائب"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nA}b" form1="NOUN+CASE_DEF_NOM"/>
                        <tok id="1" form0="+h" form1="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نائب" form1="نائب" form2="نائِب" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_NOM"/>
                        <tok id="1" form0="+ه" form1="+ه" form2="+هُ" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نائب"/>
                        <tok id="1" form0="+ه"/>
                    </tokenized>
                </word>
                <word id="43" word="مايك">
                    <svm_prediction>
                        <morph_feature_set diac="مايك" lemma="مايكmAyk" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="مايك" lemma="مايك_1" gloss="Mike" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="مايك"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="مايك"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mAyk" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="مايك" form1="مايك" form2="مايك" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="مايك"/>
                    </tokenized>
                </word>
                <word id="44" word="بينس">
                    <svm_prediction>
                        <morph_feature_set diac="بينس" lemma="بينسbyns" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="na" cas="u" enc0="3d_poss"/>
                    </svm_prediction>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بينس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="byns" form1="NOUN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بينس" form1="بينس" form2="بينس" form3="NOM" form4="NN" form5="NOUN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بينس"/>
                    </tokenized>
                </word>
                <word id="45" word=",">
                    <svm_prediction>
                        <morph_feature_set diac="," lemma=",," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="," lemma=",_0" gloss="," pos="punc" prc3="na" prc2="na" prc1="na" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="na"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0=","/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="," form1="PUNC"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="," form1="," form2="," form3="PNX" form4="PUNC" form5="PUNC"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0=","/>
                    </tokenized>
                </word>
                <word id="46" word="على">
                    <svm_prediction>
                        <morph_feature_set diac="عَلَى" lemma="عَلَىEalaY" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.9028887140500753">
                        <morph_feature_set diac="عَلَى" lemma="عَلَى_1" gloss="on;above" pos="prep" prc3="0" prc2="0" prc1="0" prc0="na" per="na" asp="na" vox="na" mod="na" gen="na" num="na" stt="na" cas="na" enc0="0" stem="عَلَى"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Ely" form1="PREP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="على" form1="علي" form2="عَلَى" form3="PRT" form4="IN" form5="PREP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="علي"/>
                    </tokenized>
                </word>
                <word id="47" word="غرار">
                    <svm_prediction>
                        <morph_feature_set diac="غِرارِ" lemma="غِرارgirAr" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8976950388630852">
                        <morph_feature_set diac="غِرارِ" lemma="غِرار_1" gloss="manner;way;haste" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="g" enc0="0" stem="غِرار"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="غرار"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="grAr" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="غرار" form1="غرار" form2="غِرار" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="غرار"/>
                    </tokenized>
                </word>
                <word id="48" word="ما">
                    <svm_prediction>
                        <morph_feature_set diac="ما" lemma="ماmA" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8946084067761285">
                        <morph_feature_set diac="ما" lemma="ما_1" gloss="what" pos="pron_rel" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="ما"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="mA" form1="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ما" form1="ما" form2="ما" form3="NOM" form4="WP" form5="REL_PRON"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ما"/>
                    </tokenized>
                </word>
                <word id="49" word="حدث">
                    <svm_prediction>
                        <morph_feature_set diac="حَدَثَ" lemma="حَدَثHadav" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8955176478607276">
                        <morph_feature_set diac="حَدَثَ" lemma="حَدَث-ُ_1" gloss="happen;take_place" pos="verb" prc3="0" prc2="0" prc1="0" prc0="0" per="3" asp="p" vox="a" mod="i" gen="m" num="s" stt="na" cas="na" enc0="0" stem="حَدَث"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="حدث"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Hdv" form1="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="حدث" form1="حدث" form2="حَدَث" form3="VRB" form4="VBD" form5="PV+PVSUFF_SUBJ:3MS"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="حدث"/>
                    </tokenized>
                </word>
                <word id="50" word="للرئيس">
                    <svm_prediction>
                        <morph_feature_set diac="لِلرَّئِيسِ" lemma="رَئِيسra}iys" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8944374375687777">
                        <morph_feature_set diac="لِلرَّئِيسِ" lemma="رَئِيس_1" gloss="president;head;chairman" pos="noun" prc3="0" prc2="0" prc1="li_prep" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="رَئِيس"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="الرئيس"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="l+" form1="PREP+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="r}ys" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ل+" form1="ل+" form2="لِ+" form3="PRT+" form4="IN+" form5="PREP+"/>
                        <tok id="1" form0="الرئيس" form1="الرئيس" form2="رَئِيس" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ل+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="رئيس"/>
                    </tokenized>
                </word>
                <word id="51" word="الأمريكي">
                    <svm_prediction>
                        <morph_feature_set diac="الأَمْرِيكِيِّ" lemma="أَمْرِيكِيّ&gt;amoriykiy~" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="الأَمْرِيكِيِّ" lemma="أَمْرِيكِيّ_1" gloss="American" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَمْرِيكِيّ"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="الامريكي"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="Amryky" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="الأمريكي" form1="الامريكي" form2="أَمْرِيكِيّ" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="امريكي"/>
                    </tokenized>
                </word>
                <word id="52" word="السابق">
                    <svm_prediction>
                        <morph_feature_set diac="السّابِقِ" lemma="سابِقsAbiq" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8957755326635665">
                        <morph_feature_set diac="السّابِقِ" lemma="سابِق_1" gloss="former;previous;preceding" pos="adj" prc3="0" prc2="0" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="سابِق"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="السابق"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="Al+" form1="DET+"/>
                        <tok id="1" form0="sAbq" form1="ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="السابق" form1="السابق" form2="سابِق" form3="NOM" form4="DT+JJ" form5="DET+ADJ+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="سابق"/>
                    </tokenized>
                </word>
                <word id="53" word="ريتشارد">
                    <svm_prediction>
                        <morph_feature_set diac="رِيتْشارْد" lemma="رِيتْشارْدriyto$Arod" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="رِيتْشارْد" lemma="رِيتْشارْد_1" gloss="Richard" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="رِيتْشارْد"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="ريتشارد"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="ryt$Ard" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="ريتشارد" form1="ريتشارد" form2="رِيتْشارْد" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="ريتشارد"/>
                    </tokenized>
                </word>
                <word id="54" word="نيكسون">
                    <svm_prediction>
                        <morph_feature_set diac="نِيكْسُون" lemma="نِيكْسُونniykosuwn" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="1.0">
                        <morph_feature_set diac="نِيكْسُون" lemma="نِيكْسُون_1" gloss="Nixon" pos="noun_prop" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="i" cas="u" enc0="0" stem="نِيكْسُون"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="نيكسون"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="nykswn" form1="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="نيكسون" form1="نيكسون" form2="نِيكْسُون" form3="PROP" form4="NNP" form5="NOUN_PROP"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="نيكسون"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        
        <out_seg id="SENT14">
            <segment_info>
                <preprocessed>والأيام بيننا</preprocessed>
                <bpc>
                    <chunk id="0" type="S">
                        <tok id="0" form0="و+"/>
                    </chunk>
                    <chunk id="1" type="NP">
                        <tok id="0" form0="ال+"/>
                        <tok id="1" form0="ايام"/>
                    </chunk>
                    <chunk id="2" type="NP">
                        <tok id="0" form0="بين"/>
                    </chunk>
                    <chunk id="3" type="NP">
                        <tok id="0" form0="+نا"/>
                    </chunk>
                </bpc>
                <ner>
                    <ne id="0" type="">
                        <tok id="0" form0="و+"/>
                    </ne>
                    <ne id="1" type="">
                        <tok id="1" form0="ال+"/>
                    </ne>
                    <ne id="2" type="">
                        <tok id="2" form0="ايام"/>
                    </ne>
                    <ne id="3" type="">
                        <tok id="3" form0="بين"/>
                    </ne>
                    <ne id="4" type="">
                        <tok id="4" form0="+نا"/>
                    </ne>
                </ner>
            </segment_info>
            <word_info>
                <word id="0" word="والأيام">
                    <svm_prediction>
                        <morph_feature_set diac="وَالأَيّامِ" lemma="يَوْمyawom" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8943362057940295">
                        <morph_feature_set diac="وَالأَيّامِ" lemma="يَوْم_1" gloss="days" pos="noun" prc3="0" prc2="wa_conj" prc1="0" prc0="Al_det" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="d" cas="g" enc0="0" stem="أَيّام"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="الايام"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="w+" form1="CONJ+"/>
                        <tok id="1" form0="Al+" form1="DET+"/>
                        <tok id="2" form0="AyAm" form1="NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="و+" form1="و+" form2="وَ+" form3="PRT+" form4="CC+" form5="CONJ+"/>
                        <tok id="1" form0="الأيام" form1="الايام" form2="يَوْم" form3="NOM" form4="DT+NN" form5="DET+NOUN+CASE_DEF_GEN"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="و+"/>
                        <tok id="1" form0="ال+"/>
                        <tok id="2" form0="ايام"/>
                    </tokenized>
                </word>
                <word id="1" word="بيننا">
                    <svm_prediction>
                        <morph_feature_set diac="بَيْنَنا" lemma="بَيْنَbayona" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="1p_poss"/>
                    </svm_prediction>
                    <analysis rank="0" score="0.8674914728891431">
                        <morph_feature_set diac="بَيِّنَنا" lemma="بَيِّن_1" gloss="clear;evident;explicit" pos="noun" prc3="0" prc2="0" prc1="0" prc0="0" per="na" asp="na" vox="na" mod="na" gen="m" num="s" stt="c" cas="a" enc0="1p_poss" stem="بَيِّن"/>
                    </analysis>
                    <tokenized scheme="ATB">
                        <tok id="0" form0="بين"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                    <tokenized scheme="D3_BWPOS">
                        <tok id="0" form0="byn" form1="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+nA" form1="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="ATB4MT">
                        <tok id="0" form0="بين" form1="بين" form2="بَيِّن" form3="NOM" form4="NN" form5="NOUN+CASE_DEF_ACC"/>
                        <tok id="1" form0="+نا" form1="+نا" form2="+نا" form3="+NOM" form4="+PRP$" form5="+POSS_PRON_1P"/>
                    </tokenized>
                    <tokenized scheme="MyD3">
                        <tok id="0" form0="بين"/>
                        <tok id="1" form0="+نا"/>
                    </tokenized>
                </word>
            </word_info>
        </out_seg>
        
    </out_doc>
</madamira_output>
